{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"telecom_custome_nmtlr.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMyABR26ERPkmWNhTs445Xt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"v-kOcpXpzIjL","executionInfo":{"status":"ok","timestamp":1603556478241,"user_tz":-60,"elapsed":99964,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}},"outputId":"caeef99e-367d-41c6-eb04-fa98f0df6d5c","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install pysurvival\n","!pip install lifelines\n","!pip install osqp==0.5\n","!pip install scikit-survival\n","!pip install pycox"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pysurvival\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/dd/d7bf69b6e1e0d1cd243b39577867c15d092404d5bc7afef3ae135b50717f/pysurvival-0.1.2.tar.gz (4.7MB)\n","\u001b[K     |████████████████████████████████| 4.8MB 12.3MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from pysurvival) (3.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pysurvival) (1.18.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pysurvival) (1.1.2)\n","Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (from pysurvival) (19.3.1)\n","Collecting progressbar\n","  Downloading https://files.pythonhosted.org/packages/a3/a6/b8e451f6cff1c99b4747a2f7235aa904d2d49e8e1464e0b798272aa84358/progressbar-2.5.tar.gz\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.6/dist-packages (from pysurvival) (0.14.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pysurvival) (0.22.2.post1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pysurvival) (1.4.1)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from pysurvival) (0.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pysurvival) (1.6.0+cu101)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pysurvival) (2.8.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pysurvival) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pysurvival) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pysurvival) (0.10.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pysurvival) (2018.9)\n","Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow->pysurvival) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pysurvival) (0.16.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->pysurvival) (0.16.0)\n","Building wheels for collected packages: pysurvival, progressbar\n","  Building wheel for pysurvival (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pysurvival: filename=pysurvival-0.1.2-cp36-cp36m-linux_x86_64.whl size=3774954 sha256=f5018b417c5958ef42489744e4424c97a5be8848e39d50b03cd2229edd2e28a7\n","  Stored in directory: /root/.cache/pip/wheels/6c/23/e8/6feb0c4432219666bdd5d33828d7d9f429c4726f34c6fa8061\n","  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for progressbar: filename=progressbar-2.5-cp36-none-any.whl size=12076 sha256=a3215a658c689334c829b1fe42ac8880ebc38e640b7c4c695d3a81b467e58e00\n","  Stored in directory: /root/.cache/pip/wheels/c0/e9/6b/ea01090205e285175842339aa3b491adeb4015206cda272ff0\n","Successfully built pysurvival progressbar\n","Installing collected packages: progressbar, pysurvival\n","Successfully installed progressbar-2.5 pysurvival-0.1.2\n","Collecting lifelines\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/8b/239479f5c4317fe92ccc9e8690b60fa6d4613125eae2c03062356b4c32dd/lifelines-0.25.5-py3-none-any.whl (345kB)\n","\u001b[K     |████████████████████████████████| 348kB 10.5MB/s \n","\u001b[?25hRequirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.6/dist-packages (from lifelines) (1.3)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from lifelines) (1.18.5)\n","Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.6/dist-packages (from lifelines) (3.2.2)\n","Requirement already satisfied: patsy>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from lifelines) (0.5.1)\n","Collecting autograd-gamma>=0.3\n","  Downloading https://files.pythonhosted.org/packages/85/ae/7f2031ea76140444b2453fa139041e5afd4a09fc5300cfefeb1103291f80/autograd-gamma-0.5.0.tar.gz\n","Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from lifelines) (1.1.2)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from lifelines) (1.4.1)\n","Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from autograd>=1.3->lifelines) (0.16.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->lifelines) (2.8.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->lifelines) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->lifelines) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->lifelines) (1.2.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.0->lifelines) (1.15.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->lifelines) (2018.9)\n","Building wheels for collected packages: autograd-gamma\n","  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-cp36-none-any.whl size=4035 sha256=1904649e8527ae5535b65f86e241672220dd0c6251c618d51082516f03f28e09\n","  Stored in directory: /root/.cache/pip/wheels/dc/68/dc/91321c55fba449755524481854f5be70d41912b8f886f908bb\n","Successfully built autograd-gamma\n","Installing collected packages: autograd-gamma, lifelines\n","Successfully installed autograd-gamma-0.5.0 lifelines-0.25.5\n","Collecting osqp==0.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/01/8becb29b0d38e0c40eab9e3d54aa8138fa62a010d519caf65e9210021bd3/osqp-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (147kB)\n","\u001b[K     |████████████████████████████████| 153kB 8.4MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from osqp==0.5) (0.16.0)\n","Requirement already satisfied: scipy>=0.13.2 in /usr/local/lib/python3.6/dist-packages (from osqp==0.5) (1.4.1)\n","Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from osqp==0.5) (1.18.5)\n","Installing collected packages: osqp\n","  Found existing installation: osqp 0.6.1\n","    Uninstalling osqp-0.6.1:\n","      Successfully uninstalled osqp-0.6.1\n","Successfully installed osqp-0.5.0\n","Collecting scikit-survival\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4d/07/10e960674a7d9660f1b19d206ce37afabba0f443d6c72bcc8945d617d890/scikit-survival-0.14.0.tar.gz (2.3MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 11.6MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cvxopt in /usr/local/lib/python3.6/dist-packages (from scikit-survival) (1.2.5)\n","Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.6/dist-packages (from scikit-survival) (1.1.2)\n","Requirement already satisfied: scipy!=1.3.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from scikit-survival) (1.4.1)\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from scikit-survival) (2.7.1)\n","Requirement already satisfied: cvxpy>=1.0 in /usr/local/lib/python3.6/dist-packages (from scikit-survival) (1.0.31)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-survival) (1.18.5)\n","Requirement already satisfied: scikit-learn<0.24,>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from scikit-survival) (0.22.2.post1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from scikit-survival) (0.16.0)\n","Requirement already satisfied: osqp!=0.6.0,!=0.6.1 in /usr/local/lib/python3.6/dist-packages (from scikit-survival) (0.5.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->scikit-survival) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->scikit-survival) (2018.9)\n","Requirement already satisfied: scs>=1.1.3 in /usr/local/lib/python3.6/dist-packages (from cvxpy>=1.0->scikit-survival) (2.1.2)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from cvxpy>=1.0->scikit-survival) (0.70.10)\n","Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.6/dist-packages (from cvxpy>=1.0->scikit-survival) (2.0.7.post1)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from osqp!=0.6.0,!=0.6.1->scikit-survival) (0.16.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.21->scikit-survival) (1.15.0)\n","Requirement already satisfied: dill>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from multiprocess->cvxpy>=1.0->scikit-survival) (0.3.2)\n","Building wheels for collected packages: scikit-survival\n","  Building wheel for scikit-survival (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for scikit-survival: filename=scikit_survival-0.14.0-cp36-cp36m-linux_x86_64.whl size=4120461 sha256=c96163fa13849a6afc06b995a086076a42ac4f0a01916ab7b15b1682ed707386\n","  Stored in directory: /root/.cache/pip/wheels/f4/af/94/be84d2dc68a947ad2859b1608f1d57a4328465a0b00b0fb4ac\n","Successfully built scikit-survival\n","Installing collected packages: scikit-survival\n","Successfully installed scikit-survival-0.14.0\n","Collecting pycox\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/33/8166da2d22ff30305aa0c10e0c6124ef5d3b60b5b0418387bb805bd6b751/pycox-0.2.1-py3-none-any.whl (73kB)\n","\u001b[K     |████████████████████████████████| 81kB 7.3MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.6/dist-packages (from pycox) (0.22.2.post1)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.6/dist-packages (from pycox) (2.10.0)\n","Collecting torchtuples>=0.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/70/93eb42c0a46ef94b3885b8e5611a8019d00522a9ab7343d4ca25033afd44/torchtuples-0.2.0-py3-none-any.whl (41kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.0MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.6/dist-packages (from pycox) (2.23.0)\n","Requirement already satisfied: numba>=0.44 in /usr/local/lib/python3.6/dist-packages (from pycox) (0.48.0)\n","Requirement already satisfied: feather-format>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from pycox) (0.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.2->pycox) (0.16.0)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.2->pycox) (1.4.1)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.2->pycox) (1.18.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py>=2.9.0->pycox) (1.15.0)\n","Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.6/dist-packages (from torchtuples>=0.2.0->pycox) (3.2.2)\n","Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.6/dist-packages (from torchtuples>=0.2.0->pycox) (1.1.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pycox) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pycox) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pycox) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pycox) (1.24.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.44->pycox) (50.3.0)\n","Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.44->pycox) (0.31.0)\n","Requirement already satisfied: pyarrow>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from feather-format>=0.4.0->pycox) (0.14.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (1.2.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (0.10.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->torchtuples>=0.2.0->pycox) (2018.9)\n","Installing collected packages: torchtuples, pycox\n","Successfully installed pycox-0.2.1 torchtuples-0.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QSURVSvakAf9","executionInfo":{"status":"ok","timestamp":1603556522122,"user_tz":-60,"elapsed":27601,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}},"outputId":"5d9f98be-79e9-4383-934c-56355018d682","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":91}},"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as opt\n","import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","from lifelines.utils import concordance_index# as c_index\n","from sksurv.metrics import brier_score, integrated_brier_score, concordance_index_censored as ci_scikit\n","%pylab inline\n","from google.colab import files\n","uploaded = files.upload()\n","torch.cuda.set_device(0)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Populating the interactive namespace from numpy and matplotlib\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-cafee9e7-80b4-438c-b41c-40020d20034f\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-cafee9e7-80b4-438c-b41c-40020d20034f\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving telecom.csv to telecom.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1L2RCoJs0bTW"},"source":["#https://stackoverflow.com/questions/48152674/how-to-check-if-pytorch-is-using-the-gpu\n","torch.cuda.is_available()\n","seed = 7\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","#np.random.seed(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W519QtL3psLT","executionInfo":{"status":"ok","timestamp":1603556527365,"user_tz":-60,"elapsed":570,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}},"outputId":"fe923bc1-cf7e-4ddb-d61d-d155cb9f5957","colab":{"base_uri":"https://localhost:8080/","height":575}},"source":["import io \n","df = pd.read_csv(io.BytesIO(uploaded['telecom.csv']))\n","ids = df[['customerID']]\n","df.drop(columns=['customerID'], inplace=True)\n","df"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>gender</th>\n","      <th>SeniorCitizen</th>\n","      <th>Partner</th>\n","      <th>Dependents</th>\n","      <th>tenure</th>\n","      <th>PhoneService</th>\n","      <th>MultipleLines</th>\n","      <th>InternetService</th>\n","      <th>OnlineSecurity</th>\n","      <th>OnlineBackup</th>\n","      <th>DeviceProtection</th>\n","      <th>TechSupport</th>\n","      <th>StreamingTV</th>\n","      <th>StreamingMovies</th>\n","      <th>Contract</th>\n","      <th>PaperlessBilling</th>\n","      <th>PaymentMethod</th>\n","      <th>MonthlyCharges</th>\n","      <th>TotalCharges</th>\n","      <th>Churn</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>1</td>\n","      <td>No</td>\n","      <td>No phone service</td>\n","      <td>DSL</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Electronic check</td>\n","      <td>29.85</td>\n","      <td>29.85</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>34</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>One year</td>\n","      <td>No</td>\n","      <td>Mailed check</td>\n","      <td>56.95</td>\n","      <td>1889.5</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>2</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Mailed check</td>\n","      <td>53.85</td>\n","      <td>108.15</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>45</td>\n","      <td>No</td>\n","      <td>No phone service</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>One year</td>\n","      <td>No</td>\n","      <td>Bank transfer (automatic)</td>\n","      <td>42.30</td>\n","      <td>1840.75</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>2</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Fiber optic</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Electronic check</td>\n","      <td>70.70</td>\n","      <td>151.65</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7038</th>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>24</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>One year</td>\n","      <td>Yes</td>\n","      <td>Mailed check</td>\n","      <td>84.80</td>\n","      <td>1990.5</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>7039</th>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>72</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Fiber optic</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>One year</td>\n","      <td>Yes</td>\n","      <td>Credit card (automatic)</td>\n","      <td>103.20</td>\n","      <td>7362.9</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>7040</th>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>11</td>\n","      <td>No</td>\n","      <td>No phone service</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Electronic check</td>\n","      <td>29.60</td>\n","      <td>346.45</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>7041</th>\n","      <td>Male</td>\n","      <td>1</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>4</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Fiber optic</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Mailed check</td>\n","      <td>74.40</td>\n","      <td>306.6</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>7042</th>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>66</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Fiber optic</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Two year</td>\n","      <td>Yes</td>\n","      <td>Bank transfer (automatic)</td>\n","      <td>105.65</td>\n","      <td>6844.5</td>\n","      <td>No</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7043 rows × 20 columns</p>\n","</div>"],"text/plain":["      gender  SeniorCitizen Partner  ... MonthlyCharges  TotalCharges Churn\n","0     Female              0     Yes  ...          29.85         29.85    No\n","1       Male              0      No  ...          56.95        1889.5    No\n","2       Male              0      No  ...          53.85        108.15   Yes\n","3       Male              0      No  ...          42.30       1840.75    No\n","4     Female              0      No  ...          70.70        151.65   Yes\n","...      ...            ...     ...  ...            ...           ...   ...\n","7038    Male              0     Yes  ...          84.80        1990.5    No\n","7039  Female              0     Yes  ...         103.20        7362.9    No\n","7040  Female              0     Yes  ...          29.60        346.45    No\n","7041    Male              1     Yes  ...          74.40         306.6   Yes\n","7042    Male              0      No  ...         105.65        6844.5    No\n","\n","[7043 rows x 20 columns]"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"SGEOSjVAp5xR","executionInfo":{"status":"ok","timestamp":1603556532236,"user_tz":-60,"elapsed":584,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}},"outputId":"77d43cf3-97e7-471b-b974-a7bc91c26ae7","colab":{"base_uri":"https://localhost:8080/","height":215}},"source":["l = []\n","for j, i in enumerate(df['TotalCharges']):\n","    try:\n","        float(i)\n","    except ValueError:\n","        print(j, '_________', i)\n","        l.append(j)\n","df.drop(l, inplace = True ) \n","df['TotalCharges'] = df['TotalCharges'].astype(float)\n","df = df.reset_index( drop = True )"],"execution_count":3,"outputs":[{"output_type":"stream","text":["488 _________  \n","753 _________  \n","936 _________  \n","1082 _________  \n","1340 _________  \n","3331 _________  \n","3826 _________  \n","4380 _________  \n","5218 _________  \n","6670 _________  \n","6754 _________  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5LtxvBK4p8Kx","executionInfo":{"status":"ok","timestamp":1603556534488,"user_tz":-60,"elapsed":584,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}}},"source":["binary = ['gender', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Churn']\n","categorical = ['MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaymentMethod']\n","numerical = ['tenure', 'SeniorCitizen', 'MonthlyCharges', 'TotalCharges']\n","df = pd.get_dummies(df, columns=binary, drop_first=True)\n","df = pd.get_dummies(df, columns=categorical)\n","# Creating the time and event columns\n","time_column = 'tenure'\n","event_column = 'Churn_Yes'\n"," \n","# Extracting the features\n","features = np.setdiff1d(df.columns, [time_column, event_column] ).tolist()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"AOWiazMGp_Mi","executionInfo":{"status":"ok","timestamp":1603556537387,"user_tz":-60,"elapsed":654,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}},"outputId":"31c4f7fc-522e-4b24-a4a1-2c29b1e861c4","colab":{"base_uri":"https://localhost:8080/","height":233}},"source":["from sklearn.model_selection import train_test_split\n","\n","index_train, index_test = train_test_split(range(df.shape[0]), test_size=0.3, random_state=0, stratify=df['Churn_Yes'])\n","\n","tmp_data_train = df.loc[index_train].reset_index( drop = True )\n","data_test  = df.loc[index_test].reset_index( drop = True )\n","\n","index_train, index_valid = train_test_split(tmp_data_train.index, test_size=0.2, random_state=0, stratify=tmp_data_train['Churn_Yes'])\n","data_train = tmp_data_train.loc[index_train].reset_index( drop = True )\n","data_valid = tmp_data_train.loc[index_valid].reset_index( drop = True )\n","\n"," \n","# Creating the X, T and E inputs\n","X_train, X_valid, X_test = data_train[features], data_valid[features], data_test[features]\n","T_train, T_valid, T_test = data_train[time_column], data_valid[time_column], data_test[time_column]\n","E_train, E_valid, E_test = data_train[event_column], data_valid[event_column], data_test[event_column]\n"," \n","scaler = MinMaxScaler(feature_range=(0, 1))\n","scaled_train = scaler.fit_transform(X_train[['MonthlyCharges', 'TotalCharges']])\n","scaled_valid = scaler.fit_transform(X_valid[['MonthlyCharges', 'TotalCharges']])\n","scaled_test = scaler.transform(X_test[['MonthlyCharges', 'TotalCharges']])\n","X_train[['MonthlyCharges', 'TotalCharges']], X_valid[['MonthlyCharges', 'TotalCharges']], X_test[['MonthlyCharges', 'TotalCharges']] = scaled_train, scaled_valid, scaled_test\n","\n","X_train.shape, X_valid.shape, X_test.shape"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  isetter(loc, value[:, i].tolist())\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["((3937, 39), (985, 39), (2110, 39))"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"MK1c6BRFzkor","executionInfo":{"status":"ok","timestamp":1603556568719,"user_tz":-60,"elapsed":27662,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}},"outputId":"4dad1caa-e9a3-43d8-a75f-bc7578149b7a","colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["from pysurvival.models.multi_task import LinearMultiTaskModel\n","from pysurvival.utils.metrics import concordance_index as pys_concordance_index, brier_score as pys_brier_score, integrated_brier_score as pys_integrated_brier_score\n","lmtlr = LinearMultiTaskModel(bins=73)\n","lmtlr.fit(X_train, T_train, E_train, lr=1e-3, init_method='glorot_uniform', num_epochs=5000, is_min_time_zero=False, extra_pct_time=0.1)\n","train_c_index = pys_concordance_index(lmtlr, X_train, T_train, E_train)\n","test_c_index = pys_concordance_index(lmtlr, X_test, T_test, E_test)\n"," \n","#train_brier = pys_brier_score(lmtlr, X_train, T_train, E_train)\n","#test_brier = pys_brier_score(lmtlr, X_test, T_test, E_test)\n","train_ibs = pys_integrated_brier_score(lmtlr, X_train, T_train, E_train)\n","test_ibs = pys_integrated_brier_score(lmtlr, X_test, T_test, E_test)\n"," \n","train_c_index, test_c_index, train_ibs, test_ibs"],"execution_count":6,"outputs":[{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["(0.7248451176995934,\n"," 0.7211596454764917,\n"," 0.013113921571190902,\n"," 0.01978458000022089)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"IMC5BbuVa1vf","executionInfo":{"status":"ok","timestamp":1603558414190,"user_tz":-60,"elapsed":2523,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}},"outputId":"2c8819b9-0c71-4d4b-e505-ded107197e13","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["_, density, _ = lmtlr.predict(X_test)\n","density.shape"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2110, 73)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"_aygiOIQhXV3","executionInfo":{"status":"ok","timestamp":1603559454590,"user_tz":-60,"elapsed":4714,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}},"outputId":"ba33b9e0-ea5f-4520-c7d6-c8e8273707a4","colab":{"base_uri":"https://localhost:8080/","height":359}},"source":["np.sum(lmtlr.predict_density(X_test), 0)"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([137.08400951,  42.32604809,  43.26968826,  44.48546536,\n","        37.54334853,  22.88456148,  58.65161933,  30.88983019,\n","        26.33068696,  18.93537865,  31.2423731 ,  21.27268117,\n","        17.88238195,  44.49782209,  14.76093601,  14.52470522,\n","        15.58466734,  25.59105254,  17.17661573,  36.43080711,\n","        10.61628253,  19.12327846,  27.84382856,   9.71480281,\n","        13.21223606,   9.68313167,   9.23907   ,  18.84791704,\n","        17.2728752 ,  32.99119332,  20.29140072,  13.33145356,\n","        14.10056529,  20.95411001,  18.22571434,  30.42642622,\n","        11.86464848,  12.46450346,   9.91589678,  14.14856271,\n","         8.07817704,  22.64771516,  15.86431039,  19.60957353,\n","        17.51862866,  10.7752992 ,   6.77465728,   9.76354503,\n","        28.51897128,  12.57336368,  11.37237794,  12.97857254,\n","        24.23914176,   9.49867392,   5.62211897,   6.37732547,\n","         4.48367111,   5.57456766,   4.81281486,  12.01222021,\n","        13.21940437,  16.4449363 ,   8.96311567,  10.9154279 ,\n","        23.81050806, 102.83711051,  28.73323047, 102.81585331,\n","        22.10194303,  77.49952545, 105.07393077,  43.19188331,\n","       269.66482929])"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"X0l9z-wTlqaK","executionInfo":{"status":"ok","timestamp":1603240736392,"user_tz":-60,"elapsed":556,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}},"outputId":"9b99b92e-8653-4bc8-dfc6-b212b4f97aac","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["ci_scikit(E_test.astype(np.bool), T_test, lmtlr.predict_risk(X_test))[0], concordance_index(T_test, -lmtlr.predict_risk(X_test), E_test.astype(np.bool))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.8271766820113978, 0.8271766820113978)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"1W2Liw6Skx25","executionInfo":{"status":"error","timestamp":1603243738086,"user_tz":-60,"elapsed":632,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}},"outputId":"7222475f-fd90-47fa-a2ec-137a2f1a1a3f","colab":{"base_uri":"https://localhost:8080/","height":352}},"source":["from pycox.evaluation import EvalSurv\n","ev = EvalSurv(pd.DataFrame(lmtlr.predict_survival(X_test.values).T), T_test.values, E_test.values, censor_surv='km')\n","ev.concordance_td(), ev.integrated_brier_score(lmtlr.times) "],"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-83836be793c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpycox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvalSurv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvalSurv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlmtlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_survival\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcensor_surv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'km'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcordance_td\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrated_brier_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlmtlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pycox'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"1p1wO4MPoheK","executionInfo":{"status":"ok","timestamp":1603240365667,"user_tz":-60,"elapsed":3565,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}},"outputId":"05299a37-fdb1-43c8-a848-09a271c838cb","colab":{"base_uri":"https://localhost:8080/","height":283}},"source":["sk_brier = []\n","times, pys_brier = pys_brier_score(lmtlr, X_test, T_test, E_test)\n"," \n","for j, i in enumerate(times):\n","    _, score = brier_score(np.asarray(list(zip(E_train.astype(np.bool), T_train)), dtype='|bool, i4'), \n","                           np.asarray(list(zip(E_test.astype(np.bool), T_test)), dtype='|bool, i4'), lmtlr.predict_survival(X_test)[:,j], i)     #    lmtlr.predict_survival(X_test.iloc[[0]])\n","    sk_brier.append(score[0])\n"," \n","fig, ax = plt.subplots(figsize=(8, 4))\n"," \n","plt.plot(lmtlr.times[:np.argmax(lmtlr.times>max(T_train))], sk_brier, color='red', label='sk_brier', lw=2)\n","plt.plot(times, pys_brier, color='blue', label='pysurvival', lw=2)\n"," \n","#ci_scikit(E_test.astype(np.bool), T_test, lmtlr.predict_risk(X_test))[0], concordance_index(T_test, -lmtlr.predict_risk(X_test), E_test.astype(np.bool))\n","ibs = np.trapz(sk_brier, times)/max(T_train)\n"," \n","# Show everything\n","title = \"IBS: \"+str(ibs)\n","plt.legend(fontsize=12)\n","plt.title(title, fontsize=15)\n","plt.ylim(0, 1.05)\n","plt.show()\n","# the probability that an individual within the population will survive longer than time t."],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"FGBjNq_2TSS0","executionInfo":{"status":"ok","timestamp":1602464474988,"user_tz":-60,"elapsed":77758,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}},"outputId":"56ad4d2c-b33b-4bd2-8eca-bc45d362be86","colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["from pysurvival.models.multi_task import NeuralMultiTaskModel\n","n_mtlr = NeuralMultiTaskModel(structure=[{'activation': 'LeakyReLU', 'num_units': 150}, {'activation': 'LeakyReLU', 'num_units': 250}, {'activation': 'LeakyReLU', 'num_units': 300}], bins=73)\n","n_mtlr.fit(X_train, T_train, E_train, lr=1e-4, init_method='glorot_uniform', num_epochs=1000)\n","\n","train_c_index = pys_concordance_index(n_mtlr, X_train, T_train, E_train)\n","test_c_index = pys_concordance_index(n_mtlr, X_test, T_test, E_test)\n"," \n","train_ibs = pys_integrated_brier_score(n_mtlr, X_train, T_train, E_train)\n","test_ibs = pys_integrated_brier_score(n_mtlr, X_test, T_test, E_test)\n","\n","train_c_index, test_c_index, train_ibs, test_ibs"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["(0.8973604543847077,\n"," 0.862671051559757,\n"," 0.01718606263781717,\n"," 0.03164171857308528)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"ko-wLMJNTptf"},"source":["sk_brier = []\n","times, pys_brier = pys_brier_score(lmtlr, X_test, T_test, E_test)\n"," \n","for j, i in enumerate(times):\n","    _, score = brier_score(np.asarray(list(zip(E_train.astype(np.bool), T_train)), dtype='|bool, i4'), \n","                           np.asarray(list(zip(E_test.astype(np.bool), T_test)), dtype='|bool, i4'), n_mtlr.predict_survival(X_test)[:,j], i)     #    lmtlr.predict_survival(X_test.iloc[[0]])\n","    sk_brier.append(score[0])\n"," \n","fig, ax = plt.subplots(figsize=(8, 4))\n"," \n","plt.plot(n_mtlr.times[:np.argmax(n_mtlr.times>max(T_train))], sk_brier, color='red', label='sk_brier', lw=2)\n","plt.plot(times, pys_brier, color='blue', label='pysurvival', lw=2)\n"," \n","#ci_scikit(E_test.astype(np.bool), T_test, lmtlr.predict_risk(X_test))[0], concordance_index(T_test, -lmtlr.predict_risk(X_test), E_test.astype(np.bool))\n","ibs = np.trapz(sk_brier, times)/max(T_train)\n"," \n","# Show everything\n","title = \"IBS: \"+str(ibs)\n","plt.legend(fontsize=12)\n","plt.title(title, fontsize=15)\n","plt.ylim(0, 1.05)\n","plt.show()\n","# the probability that an individual within the population will survive longer than time t."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xMo7Lnt5r4nb","executionInfo":{"status":"ok","timestamp":1602463200221,"user_tz":-60,"elapsed":2779,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}},"outputId":"46d53fc1-84da-4893-9d31-1b9d2f477f48","colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["'''class LR(nn.Module):\n","    def __init__(self, input_size, num_time_bins):\n","        super().__init__()\n","        self.input_size, self.num_time_bins = input_size, num_time_bins\n","        self.fc = torch.nn.Linear(self.input_size, self.num_time_bins-1)\n","        self.register_buffer(\"G\",\n","                             torch.tril(torch.ones(self.num_time_bins-1, self.num_time_bins, requires_grad=True)))\n","        self.reset_parameters()\n"," \n","    def forward(self, x):\n","        out = self.fc(x)\n","        return torch.matmul(out, self.G)\n"," \n","    def reset_parameters(self):\n","        \"\"\"Resets the model parameters.\"\"\"\n","        #nn.init.xavier_normal_(self.fc.weight)\n","        nn.init.xavier_uniform_(self.fc.weight)\n"," \n","class SURV_DATA(Dataset):\n","    def __init__(self, x, t, e, num_time_bins):\n","        self.x, self.t, self.e = x.astype(np.float32), t.astype(np.float32), e.astype(np.float32)  # x:2D numpy arr, (t.e):1D numpy arr\n","        self.num_time_bins = num_time_bins\n","        self.masks = self.__process_labels()\n"," \n","    def __process_labels(self):\n","        mask = np.zeros([self.x.shape[0], self.num_time_bins])  # for the first loss function\n","        for i in range(self.x.shape[0]):\n","            if self.e[i] != 0:  # not censored\n","                mask[i, int(self.t[i])] = 1\n","            else:  # label[i,2]==0: censored\n","                mask[i, int(self.t[i] + 1):] = 1  # fill 1 until from the censoring time (to get 1 - \\sum F)\n","        return mask\n"," \n","    def __len__(self):\n","        return len(self.e)\n"," \n","    def __getitem__(self, idx):\n","        return self.x[idx], self.masks[idx]\n"," \n"," \n","class MTLR():\n","    def __init__(self, model, input_size, num_time_bins, train_load, test_load):\n","        self.train_load = train_load\n","        self.test_load = test_load\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.model = model(input_size, num_time_bins).to(self.device)\n"," \n","    def masked_logsumexp(self, x, mask, dim=-1):\n","        max_val, _ = (x * mask).max(dim=dim)\n","        max_val = torch.clamp_min(max_val, 0)\n","        return torch.log(torch.sum(torch.exp(x - max_val.unsqueeze(dim)) * mask, dim=dim)) + max_val\n"," \n","    def norm_diff(self, W):\n","        \"\"\" Special norm function for the last layer of the MTLR \"\"\"\n","        dims=len(W.shape)\n","        if dims==1:\n","            diff = W[1:]-W[:-1]\n","        elif dims==2:\n","            diff = W[1:, :]-W[:-1, :]\n","        return torch.sum(diff*diff)\n"," \n","    def mtlr_neg_log_likelihood(self, logits, target, l2_reg, l2_smooth, average=False):\n","        censored = target.sum(dim=1) > 1\n","        if censored.any():\n","            nll_censored = self.masked_logsumexp(logits[censored], target[censored]).sum()\n","        else:\n","            nll_censored = 0.\n","        if (~censored).any():\n","            nll_uncensored = (logits[~censored] * target[~censored]).sum()\n","        else:\n","            nll_uncensored = 0.\n"," \n","        # the normalising constant\n","        norm = torch.logsumexp(logits, dim=1).sum()\n","        nll_total = -(nll_censored + nll_uncensored - norm)\n","        if average:\n","            nll_total = nll_total / target.size(0)\n"," \n","        nb_set_parameters = len(list(self.model.parameters()))\n","        for i, w in enumerate(self.model.parameters()):\n","            nll_total += l2_reg*torch.sum(w*w)/2.\n","            \n","            if i >= nb_set_parameters - 2:\n","                nll_total += l2_smooth*self.norm_diff(w)\n","        return nll_total\n"," \n","    def train_model(self, lr, l2_reg, l2_smooth):\n","        self.model.train()\n","        sum_loss = 0\n","        optim = Adam(self.model.parameters(), lr=lr)\n","        for i, xy in enumerate(self.train_load):\n","            x, y = xy\n","            x, y = x.to(self.device), y.to(self.device)\n","            batch = y.shape[0]\n","            output = self.model(x)\n","            loss = self.mtlr_neg_log_likelihood(output, y, l2_reg, l2_smooth)\n","            optim.zero_grad()\n","            loss.backward()\n","            optim.step()\n","            sum_loss += loss.item()\n","        return sum_loss / (i + 1)\n"," \n","    def eval_model(self, l2_reg, l2_smooth):\n","        self.model.eval()\n","        sum_loss = 0\n","        correct = 0\n","        for i, xy in enumerate(self.test_load):\n","            x, y = xy\n","            x, y = x.to(self.device), y.to(self.device)\n","            output = self.model(x)\n","            loss = self.mtlr_neg_log_likelihood(output, y, l2_reg, l2_smooth)\n","            sum_loss += loss.item()\n","        return sum_loss / (i + 1)\n"," \n","    def fit(self, epoch, lr, l2_reg=1e-2, l2_smooth=1e-2, eval=True):\n","        for i in range(epoch):\n","            print('##### EPOCH '+str(i) + ' #####')\n","            train_loss = self.train_model(lr, l2_reg, l2_smooth)\n","            print('train loss : ' ,train_loss)\n","            if (eval) or (i==epoch-1):\n","                test_loss = self.eval_model(l2_reg, l2_smooth)\n","                print('test loss : ' ,test_loss)\n","            #print('\\n')\n"," \n","    def predict_survival(self, x):\n","        x = torch.tensor(x.astype(np.float32)).to(self.device)\n","        with torch.no_grad():\n","            output = self.model(x)\n","        G = torch.tril(torch.ones(output.size(1), output.size(1))).to(self.device)\n","        density = torch.softmax(output, dim=1)\n","        return torch.matmul(density, G)'''\n"," \n","'''class LR(nn.Module):\n","    def __init__(self, input_size, num_time_bins):\n","        super().__init__()\n","        self.input_size, self.num_time_bins = input_size, num_time_bins\n","        self.fc = torch.nn.Linear(self.input_size, self.num_time_bins)\n","        self.reset_parameters()\n"," \n","    def forward(self, x):\n","        out = self.fc(x)\n","        return out\n"," \n","    def reset_parameters(self):\n","        self.fc.weight = nn.init.xavier_normal_(self.fc.weight)\n","        self.fc.bias = nn.init.constant_(self.fc.bias, 0.001)\n"," \n","    def reset_parameters(self):\n","        \"\"\"Resets the model parameters.\"\"\"\n","        #nn.init.xavier_normal_(self.fc.weight)\n","        nn.init.xavier_uniform_(self.fc.weight)\n","        nn.init.xavier_uniform_(self.fc.bias)\n"," \n","    \n"," \n"," \n","class CENSORED_SURV_DATA(Dataset):\n","    def __init__(self, X_cens, Y_cens):\n","        self.X_cens, self.Y_cens = X_cens.astype(np.float32), Y_cens.astype(np.float32)\n"," \n","    def __len__(self):\n","        return len(self.X_cens)\n"," \n","    def __getitem__(self, idx):\n","        return self.X_cens[idx], self.Y_cens[idx]\n"," \n","class UNCENSORED_SURV_DATA(Dataset):\n","    def __init__(self, X_uncens, Y_uncens):\n","        self.X_uncens, self.Y_uncens = X_uncens.astype(np.float32), Y_uncens.astype(np.float32)\n"," \n","    def __len__(self):\n","        return len(self.X_uncens)\n"," \n","    def __getitem__(self, idx):\n","        return self.X_uncens[idx], self.Y_uncens[idx]\n"," \n","class MTLR():\n","    def __init__(self, model, input_size, num_time_bins):\n","        self.input_size, self.num_time_bins = input_size, num_time_bins\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.model = model(self.input_size, self.num_time_bins).to(self.device)\n","        self.triangle = torch.FloatTensor(np.tri(self.num_time_bins, self.num_time_bins + 1, dtype=np.float32))\n"," \n","    def process_data(self, x, t, e):\n","        Y_cens, Y_uncens = [], []\n","        X_cens, X_uncens = [], []\n","        for i in range(x.shape[0]):\n","            if e[i] != 0:  # not censored\n","                tmp = np.zeros((self.num_time_bins + 1))\n","                tmp[int(t[i])] = 1\n","                X_uncens.append(x[i,:]), Y_uncens.append(tmp)\n","            else:  # label[i,2]==0: censored\n","                tmp = np.zeros((self.num_time_bins + 1))\n","                tmp[int(t[i] + 1):] = 1  # fill 1 until from the censoring time (to get 1 - \\sum F)\n","                X_cens.append(x[i,:]), Y_cens.append(tmp)\n","        return np.asarray(X_uncens), np.asarray(Y_uncens), np.asarray(X_cens), np.asarray(Y_cens)\n"," \n","    def norm_diff(self, W):\n","        \"\"\" Special norm function for the last layer of the MTLR \"\"\"\n","        dims=len(W.shape)\n","        if dims==1:\n","            diff = W[1:]-W[:-1]\n","        elif dims==2:\n","            diff = W[1:, :]-W[:-1, :]\n","        return torch.sum(diff*diff)\n"," \n","    def loss_function(self, X_cens, X_uncens, Y_cens, Y_uncens, l2_reg, l2_smooth):\n","        \n","        # Likelihood Calculations -- Uncensored\n","        score_uncens = self.model(X_uncens)\n","        phi_uncens = torch.exp( torch.mm(score_uncens, self.triangle) )\n","        reduc_phi_uncens = torch.sum(phi_uncens*Y_uncens, dim = 1)\n"," \n","        # Likelihood Calculations -- Censored\n","        score_cens = self.model(X_cens)\n","        phi_cens = torch.exp( torch.mm(score_cens, self.triangle) )\n","        reduc_phi_cens = torch.sum( phi_cens*Y_cens, dim = 1)\n"," \n","        # Likelihood Calculations -- Normalization\n","        z_uncens = torch.exp( torch.mm(score_uncens, self.triangle) )\n","        reduc_z_uncens = torch.sum( z_uncens, dim = 1)\n"," \n","        z_cens = torch.exp( torch.mm(score_cens, self.triangle) )\n","        reduc_z_cens = torch.sum( z_cens, dim = 1)\n"," \n","        # MTLR cost function\n","        loss = - (\n","                    torch.sum( torch.log(reduc_phi_uncens) ) \\\n","                  + torch.sum( torch.log(reduc_phi_cens) )  \\\n"," \n","                  - torch.sum( torch.log(reduc_z_uncens) ) \\\n","                  - torch.sum( torch.log(reduc_z_cens) ) \n","                 )\n"," \n","        # Adding the regularized loss\n","        nb_set_parameters = len(list(self.model.parameters()))\n","        for i, w in enumerate(self.model.parameters()):\n","            loss += l2_reg*torch.sum(w*w)/2.\n","            \n","            if i >= nb_set_parameters - 2:\n","                loss += l2_smooth*self.norm_diff(w)\n","                \n","        return loss\n"," \n","    def train_model(self, uncens_train_load, cens_train_load, lr, l2_reg, l2_smooth):\n","        self.model.train()\n","        sum_loss = 0\n","        optim = Adam(self.model.parameters(), lr=lr)\n","        for i, (uncens, cens) in enumerate(zip(uncens_train_load, cens_train_load)):\n","            X_uncens, Y_uncens = uncens\n","            X_cens, Y_cens = cens\n","            X_uncens, Y_uncens, X_cens, Y_cens = X_uncens.to(self.device), Y_uncens.to(self.device), X_cens.to(self.device), Y_cens.to(self.device)\n","            loss = self.loss_function(X_cens, X_uncens, Y_cens, Y_uncens, l2_reg, l2_smooth)\n","            optim.zero_grad()\n","            loss.backward()\n","            optim.step()\n","            sum_loss += loss.item()\n","        return sum_loss / (i + 1)\n"," \n","    def eval_model(self, uncens_test_load, cens_test_load, l2_reg, l2_smooth):\n","        self.model.eval()\n","        sum_loss = 0\n","        for i, (uncens, cens) in enumerate(zip(uncens_test_load, cens_test_load)):\n","            X_uncens, Y_uncens = uncens\n","            X_cens, Y_cens = cens\n","            X_uncens, Y_uncens, X_cens, Y_cens = X_uncens.to(self.device), Y_uncens.to(self.device), X_cens.to(self.device), Y_cens.to(self.device)\n","            loss = self.loss_function(X_cens, X_uncens, Y_cens, Y_uncens, l2_reg, l2_smooth)\n","            sum_loss += loss.item()\n","        return sum_loss / (i + 1)\n"," \n","    def fit(self, X_train, T_train, E_train, epoch, lr, batch_size, X_test=None, T_test=None, E_test=None, l2_reg=1e-2, l2_smooth=1e-2):\n"," \n","        X_train_uncens, Y_train_uncens, X_train_cens, Y_train_cens = self.process_data(X_train, T_train, E_train)\n","        X_test_uncens, Y_test_uncens, X_test_cens, Y_test_cens = self.process_data(X_test, T_test, E_test)\n"," \n","        uncens_train_load = DataLoader(UNCENSORED_SURV_DATA(X_train_uncens, Y_train_uncens), batch_size=batch_size, shuffle=True)  # DATALOADER obj\n","        uncens_test_load = DataLoader(UNCENSORED_SURV_DATA(X_test_uncens, Y_test_uncens), batch_size=batch_size, shuffle=True)  # DATALOADER obj\n","        cens_train_load = DataLoader(CENSORED_SURV_DATA(X_train_cens, Y_train_cens), batch_size=batch_size, shuffle=True)  # DATALOADER obj\n","        cens_test_load = DataLoader(CENSORED_SURV_DATA(X_test_cens, Y_test_cens), batch_size=batch_size, shuffle=True)  # DATALOADER obj\n"," \n","        for i in range(epoch):\n","            print('##### EPOCH '+str(i) + ' #####')\n","            train_loss = self.train_model(uncens_train_load, cens_train_load, lr, l2_reg, l2_smooth)\n","            print('train loss : ' ,train_loss)\n","            if X_test is not None:\n","                test_loss = self.eval_model(uncens_test_load, cens_test_load, l2_reg, l2_smooth)\n","                print('test loss : ' ,test_loss)\n","            #print('\\n')\n"," \n","    def predict_survival(self, x):\n","        x = torch.tensor(x.astype(np.float32)).to(self.device)\n","        with torch.no_grad():\n","            output = self.model(x).data.numpy()\n","        \n","        Triangle1 = np.tri(self.num_time_bins , self.num_time_bins + 1 )\n","        Triangle2 = np.tri(self.num_time_bins + 1, self.num_time_bins + 1)\n","        phi = np.exp( np.dot(output, Triangle1) )\n","        div = np.repeat(np.sum(phi, 1).reshape(-1, 1), phi.shape[1], axis=1)\n","        density = (phi/div)\n","        return np.dot(density, Triangle2)'''\n"," \n","class LRMultiTask(nn.Module):\n","    def __init__(self, input_size, num_time_bins):\n","        super().__init__()\n","        self.input_size, self.num_time_bins = input_size, num_time_bins\n","        self.fc = torch.nn.Linear(self.input_size, self.num_time_bins - 1)\n","        self.reset_parameters()\n"," \n","    def forward(self, x):\n","        out = self.fc(x)\n","        return out\n"," \n","    def reset_parameters(self):\n","        self.fc.weight = nn.init.xavier_normal_(self.fc.weight)\n","        self.fc.bias = nn.init.constant_(self.fc.bias, 0.001)\n"," \n"," \n"," \n","class NNModel(nn.Module):\n","    def __init__(self, input_shape, units=None, factors=None, dropout=None):\n","        super().__init__()\n","        self.input_shape = input_shape\n","        self.units = units\n","        self.factors = factors\n","        self.network = nn.ModuleList()\n","        if self.factors:\n","            self.units = self.input_shape * np.asarray(self.factors)\n","        if self.units is not None:\n","            self.dropout = np.zeros_like(self.units) if dropout is None else dropout\n","            for i, j in zip(self.units, self.dropout):\n","              block = self.__build_block__(input_shape, i, p=j)\n","              self.network.extend(block)\n","              input_shape = i\n","        self.reset_parameters()\n","    \n","    def __build_block__(self, input_shape, units, p, norm=False):\n","        block = []\n","        block.append(nn.Linear(input_shape, units, bias=not norm))\n","        if norm:\n","            block.append(nn.BatchNorm1d(units))\n","        block.append(nn.LeakyReLU())\n","        if p > 0:\n","            block.append(nn.Dropout(p))\n","        return block\n"," \n","    def forward(self, x):\n","        for layer in self.network:\n","          tmp = layer(x)\n","          x = tmp\n","        return x\n"," \n","    def reset_parameters(self):\n","        for layer in self.network:\n","            if isinstance(layer, nn.Linear):\n","                nn.init.xavier_uniform_(layer.weight)\n"," \n","class NN_Multi_Task(nn.Module):\n","    def __init__(self, input_shape, num_time_bins, units=None, factors=None, dropout=None):\n","        super(NN_Multi_Task, self).__init__()\n","        self.nn_model = NNModel(input_shape, units, factors, dropout)\n","        self.mtlr = LRMultiTask(self.nn_model.units[-1], num_time_bins)\n"," \n","    def forward(self, x):\n","        x = self.nn_model(x)\n","        x = self.mtlr(x)\n","        return x\n"," \n","class CENSORED_SURV_DATA(Dataset):\n","    def __init__(self, X_cens, Y_cens):\n","        self.X_cens, self.Y_cens = X_cens.astype(np.float32), Y_cens.astype(np.float32)\n"," \n","    def __len__(self):\n","        return len(self.X_cens)\n"," \n","    def __getitem__(self, idx):\n","        return self.X_cens[idx], self.Y_cens[idx]\n"," \n","class UNCENSORED_SURV_DATA(Dataset):\n","    def __init__(self, X_uncens, Y_uncens):\n","        self.X_uncens, self.Y_uncens = X_uncens.astype(np.float32), Y_uncens.astype(np.float32)\n"," \n","    def __len__(self):\n","        return len(self.X_uncens)\n"," \n","    def __getitem__(self, idx):\n","        return self.X_uncens[idx], self.Y_uncens[idx]\n"," \n","class MTLR():\n","    def __init__(self, model, input_size, num_time_bins):\n","        self.input_size, self.num_time_bins = input_size, num_time_bins\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.model = model#.to(self.device) #builded model\n","        self.triangle = torch.FloatTensor(np.tri(self.num_time_bins - 1, self.num_time_bins, dtype=np.float32))\n","        self.times = None\n","        self.losses = {'Epoch': [], 'Train': [], 'Test': []}\n"," \n","    def _process_data(self, x, t, e):\n","        Y_cens, Y_uncens = [], []\n","        X_cens, X_uncens = [], []\n","        for i in range(x.shape[0]):\n","            if e[i] != 0:  # not censored\n","                tmp = np.zeros((self.num_time_bins))\n","                tmp[int(t[i]) - 1] = 1\n","                X_uncens.append(x[i,:]), Y_uncens.append(tmp)\n","            else:  # label[i,2]==0: censored\n","                tmp = np.zeros((self.num_time_bins))\n","                tmp[int(t[i]) - 1:] = 1  # fill 1 until from the censoring time (to get 1 - \\sum F)\n","                X_cens.append(x[i,:]), Y_cens.append(tmp)\n","        return torch.FloatTensor(np.asarray(X_uncens)), torch.FloatTensor(np.asarray(Y_uncens)), torch.FloatTensor(np.asarray(X_cens)), torch.FloatTensor(np.asarray(Y_cens))\n"," \n","    def process_data(self, data, time, event):\n","        bin_idxs = np.digitize(time, self.times)\n","        Y_cens, Y_uncens = [], []\n","        X_cens, X_uncens = [], []\n","        for i, e in enumerate(event):\n","            bin_idx = bin_idxs[i]\n","            tmp = np.zeros((self.num_time_bins))\n","            if e == 1: #not censored              \n","                tmp[bin_idx] = 1\n","                X_uncens.append(data[i,:]), Y_uncens.append(tmp)\n","            else:\n","                tmp[bin_idx:] = 1\n","                X_cens.append(data[i,:]), Y_cens.append(tmp)\n","        return torch.FloatTensor(np.asarray(X_uncens)), torch.FloatTensor(np.asarray(Y_uncens)), torch.FloatTensor(np.asarray(X_cens)), torch.FloatTensor(np.asarray(Y_cens))\n"," \n","    def norm_diff(self, W):\n","            \"\"\" Special norm function for the last layer of the MTLR \"\"\"\n","            dims=len(W.shape)\n","            if dims==1:\n","                diff = W[1:]-W[:-1]\n","            elif dims==2:\n","                diff = W[1:, :]-W[:-1, :]\n","            return torch.sum(diff*diff)\n"," \n","    def loss_function(self, X_cens, X_uncens, Y_cens, Y_uncens, l2_reg, l2_smooth):\n","        \n","        # Likelihood Calculations -- Uncensored\n","        score_uncens = self.model(X_uncens)\n","        phi_uncens = torch.exp( torch.mm(score_uncens, self.triangle) )\n","        reduc_phi_uncens = torch.sum(phi_uncens*Y_uncens, dim = 1)\n"," \n","        # Likelihood Calculations -- Censored\n","        score_cens = self.model(X_cens)\n","        phi_cens = torch.exp( torch.mm(score_cens, self.triangle) )\n","        reduc_phi_cens = torch.sum( phi_cens*Y_cens, dim = 1)\n"," \n","        # Likelihood Calculations -- Normalization\n","        z_uncens = torch.exp( torch.mm(score_uncens, self.triangle) )\n","        reduc_z_uncens = torch.sum( z_uncens, dim = 1)\n"," \n","        z_cens = torch.exp( torch.mm(score_cens, self.triangle) )\n","        reduc_z_cens = torch.sum( z_cens, dim = 1)\n"," \n","        # MTLR cost function\n","        loss = - (\n","                    torch.sum( torch.log(reduc_phi_uncens) ) \\\n","                  + torch.sum( torch.log(reduc_phi_cens) )  \\\n"," \n","                  - torch.sum( torch.log(reduc_z_uncens) ) \\\n","                  - torch.sum( torch.log(reduc_z_cens) ) \n","                 )\n"," \n","        # Adding the regularized loss\n","        nb_set_parameters = len(list(self.model.parameters()))\n","        for i, w in enumerate(self.model.parameters()):\n","            loss += l2_reg*torch.sum(w*w)/2.\n","            \n","            if i >= nb_set_parameters - 2:\n","                loss += l2_smooth*self.norm_diff(w)\n","                \n","        return loss\n"," \n","    def train_model(self, optim, X_cens, X_uncens, Y_cens, Y_uncens, lr, l2_reg, l2_smooth):\n","        optim.zero_grad()\n","        self.model = self.model.train()\n","        loss = self.loss_function(X_cens, X_uncens, Y_cens, Y_uncens, l2_reg, l2_smooth)\n","        loss.backward()\n","        optim.step()\n","        return loss.item()\n"," \n","    def eval_model(self, X_cens, X_uncens, Y_cens, Y_uncens, l2_reg, l2_smooth):\n","        self.model = self.model.eval()\n","        loss = self.loss_function(X_cens, X_uncens, Y_cens, Y_uncens, l2_reg, l2_smooth)\n","        return loss.item()\n"," \n","    def fit(self, X_train, T_train, E_train, epoch, lr, batch_size, X_test=None, T_test=None, E_test=None, l2_reg=1e-2, l2_smooth=1e-2, is_min_time_zero = False, extra_pct_time = 0., eval=True):\n","        min_t = 0 if is_min_time_zero else min(T_train)\n","        max_t = max(T_train)*(1+extra_pct_time)\n","        self.times = np.linspace(min_t, max_t, self.num_time_bins)\n","        X_train_uncens, Y_train_uncens, X_train_cens, Y_train_cens = self.process_data(X_train, T_train, E_train)\n","        X_test_uncens, Y_test_uncens, X_test_cens, Y_test_cens = self.process_data(X_test, T_test, E_test)\n"," \n","        '''X_train_cens, X_train_uncens, Y_train_cens, Y_train_uncens = lmtlr.compute_XY(X_train, T_train, E_train, is_min_time_zero, extra_pct_time)\n","        if X_test is not None:\n","            X_test_cens, X_test_uncens, Y_test_cens, Y_test_uncens = lmtlr.compute_XY(X_test, T_test, E_test, is_min_time_zero, extra_pct_time)'''\n"," \n","        '''\"\"\"print(np.array_equal(tmp_X_cens.data.numpy(),X_cens))\n","        print(np.array_equal(tmp_X_uncens.data.numpy(),X_uncens))\n","        print(np.array_equal(tmp_Y_cens.data.numpy(),Y_cens))\n","        print(np.array_equal(tmp_Y_uncens.data.numpy(),Y_uncens))\"\"\"\n"," \n","        \"\"\"print(np.where(tmp_Y_cens.data.numpy() - Y_cens.data.numpy()))\n","        print(np.where(tmp_Y_uncens.data.numpy() - Y_uncens.data.numpy()))\"\"\"\n"," \n","        X_test_uncens, Y_test_uncens, X_test_cens, Y_test_cens = self.process_data(X_test, T_test, E_test)\n","        X_cens, X_uncens, Y_cens, Y_uncens = X_test_cens.to(self.device), X_test_uncens.to(self.device), Y_test_cens.to(self.device), Y_test_uncens.to(self.device)'''\n"," \n","        #optim = opt.Adam(self.model.parameters(), lr=lr)\n","        optim = opt.SGD(self.model.parameters(), lr=lr, momentum=0.9, nesterov=True)\n","        scheduler = opt.lr_scheduler.ReduceLROnPlateau(optim, mode='min', factor=0.5, patience=15, verbose=True)\n","\n","        eval_score = ''\n","        for i in range(epoch):\n","            #print(optim.param_groups[0]['lr'])\n","            print('##### EPOCH '+str(i) + ' #####')\n","            train_loss = self.train_model(optim, X_train_cens, X_train_uncens, Y_train_cens, Y_train_uncens, lr, l2_reg, l2_smooth)\n","            print('train loss : ' ,train_loss)\n","            if np.isnan(train_loss) or np.isinf(train_loss):\n","                print('Stop training')\n","                break\n","            self.losses['Epoch'].append(i), self.losses['Train'].append(train_loss)\n","            if X_test is not None:\n","                test_loss = self.eval_model(X_test_cens, X_test_uncens, Y_test_cens, Y_test_uncens, l2_reg, l2_smooth)\n","                #metric = self.c_index(X_test, T_test, E_test)\n","                if eval:\n","                    _, eval_score = self.b_index(X_train, T_train, E_train, X_test, T_test, E_test, plot=False)\n","                print('test loss : ' ,test_loss, ' _______ Metric : ', eval_score)\n","                self.losses['Test'].append(test_loss)\n","                if scheduler is not None:\n","                    scheduler.step(test_loss)\n"," \n","    def predict(self, x):\n","        x = torch.tensor(x.astype(np.float32))#.to(self.device)\n","        with torch.no_grad():\n","            output = self.model(x).data.numpy()\n","        \n","        Triangle1 = np.tri(self.num_time_bins - 1, self.num_time_bins)\n","        Triangle2 = np.tri(self.num_time_bins, self.num_time_bins)\n","        phi = np.exp( np.dot(output, Triangle1) )\n","        div = np.repeat(np.sum(phi, 1).reshape(-1, 1), phi.shape[1], axis=1)\n","        density = (phi/div)\n","        survival = np.dot(density, Triangle2)\n","        hazard = density[:, :-1]/survival[:, 1:]\n","        return hazard, density, survival\n"," \n","    def c_index(self, x, t, e):\n","        hazard, density, survival = self.predict(x)\n","        cumulative_hazard = np.cumsum(hazard, 1)\n","        risk = np.sum(cumulative_hazard, 1)\n","        res = ci_scikit(e.astype(np.bool), t, risk)[0]\n","        return res\n"," \n","    def b_index(self, X_train, T_train, E_train, X_test, T_test, E_test, plot=True):\n","        time_idx = self.times[:np.argmax(self.times>max(T_train))] #don't keep times index that are beyond max(T_train)\n","        train_e_t = np.asarray(list(zip(E_train.astype(np.bool), T_train)), dtype='|bool, i4') #concat event and time\n","        test_e_t = np.asarray(list(zip(E_test.astype(np.bool), T_test)), dtype='|bool, i4')\n","        _, _, survival = self.predict(X_test)\n","        brier_res = []\n","        for j, i in enumerate(time_idx):\n","            _, score = brier_score(train_e_t, test_e_t, survival[:,j], i)\n","            brier_res.append(score[0])\n","        ibs = np.trapz(brier_res, time_idx)/max(T_train)\n","        if plot:\n","            figure = self.plot_brier_curve(time_idx, brier_res, ibs)\n","            return brier_res, ibs, figure\n","        else:\n","            return brier_res, ibs\n"," \n","    def plot_brier_curve(self, time_axis, score, ibs):\n","        fig, ax = plt.subplots(figsize=(8, 4))\n","        plt.plot(time_axis, score, color='blue', label='Brier score / time', lw=2)\n","        title = \"Integrated Brier Score: \" + str(ibs)\n","        plt.legend(fontsize=12)\n","        plt.title(title, fontsize=15)\n","        plt.ylim(0, 1.05)\n","        return plt\n","        \n","# the probability that an individual within the population will survive longer than time t. \n"," \n"," \n","'''class LR(nn.Module):\n","    def __init__(self, input_size, num_time_bins):\n","        super().__init__()\n","        self.input_size, self.num_time_bins = input_size, num_time_bins\n","        self.fc = torch.nn.Linear(self.input_size, self.num_time_bins)\n","        self.reset_parameters()\n"," \n","    def forward(self, x):\n","        out = self.fc(x)\n","        return out\n"," \n","    def reset_parameters(self):\n","        self.fc.weight = nn.init.xavier_normal_(self.fc.weight)\n","        self.fc.bias = nn.init.constant_(self.fc.bias, 0.001)\n"," \n","class MTLR():\n","    def __init__(self, model, input_size, num_time_bins):\n","        self.input_size, self.num_time_bins = input_size, num_time_bins\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.model = model(self.input_size, self.num_time_bins).to(self.device)\n","        self.triangle = torch.FloatTensor(np.tri(self.num_time_bins, self.num_time_bins + 1, dtype=np.float32))\n","        self.times = None\n"," \n","    def process_data(self, x, t, e):\n","        Y_cens, Y_uncens = [], []\n","        X_cens, X_uncens = [], []\n","        for i in range(x.shape[0]):\n","            if e[i] != 0:  # not censored\n","                tmp = np.zeros((self.num_time_bins + 1))\n","                tmp[int(t[i])] = 1\n","                X_uncens.append(x[i,:]), Y_uncens.append(tmp)\n","            else:  # label[i,2]==0: censored\n","                tmp = np.zeros((self.num_time_bins + 1))\n","                tmp[int(t[i] + 1):] = 1  # fill 1 until from the censoring time (to get 1 - \\sum F)\n","                X_cens.append(x[i,:]), Y_cens.append(tmp)\n","        return torch.FloatTensor(np.asarray(X_uncens)), torch.FloatTensor(np.asarray(Y_uncens)), torch.FloatTensor(np.asarray(X_cens)), torch.FloatTensor(np.asarray(Y_cens))\n"," \n","    def norm_diff(self, W):\n","        \"\"\" Special norm function for the last layer of the MTLR \"\"\"\n","        dims=len(W.shape)\n","        if dims==1:\n","            diff = W[1:]-W[:-1]\n","        elif dims==2:\n","            diff = W[1:, :]-W[:-1, :]\n","        return torch.sum(diff*diff)\n"," \n","    def loss_function(self, X_cens, X_uncens, Y_cens, Y_uncens, l2_reg, l2_smooth):\n","        \n","        # Likelihood Calculations -- Uncensored\n","        score_uncens = self.model(X_uncens)\n","        phi_uncens = torch.exp( torch.mm(score_uncens, self.triangle) )\n","        reduc_phi_uncens = torch.sum(phi_uncens*Y_uncens, dim = 1)\n"," \n","        # Likelihood Calculations -- Censored\n","        score_cens = self.model(X_cens)\n","        phi_cens = torch.exp( torch.mm(score_cens, self.triangle) )\n","        reduc_phi_cens = torch.sum( phi_cens*Y_cens, dim = 1)\n"," \n","        # Likelihood Calculations -- Normalization\n","        z_uncens = torch.exp( torch.mm(score_uncens, self.triangle) )\n","        reduc_z_uncens = torch.sum( z_uncens, dim = 1)\n"," \n","        z_cens = torch.exp( torch.mm(score_cens, self.triangle) )\n","        reduc_z_cens = torch.sum( z_cens, dim = 1)\n"," \n","        # MTLR cost function\n","        loss = - (\n","                    torch.sum( torch.log(reduc_phi_uncens) ) \\\n","                  + torch.sum( torch.log(reduc_phi_cens) )  \\\n"," \n","                  - torch.sum( torch.log(reduc_z_uncens) ) \\\n","                  - torch.sum( torch.log(reduc_z_cens) ) \n","                 )\n"," \n","        # Adding the regularized loss\n","        nb_set_parameters = len(list(self.model.parameters()))\n","        for i, w in enumerate(self.model.parameters()):\n","            loss += l2_reg*torch.sum(w*w)/2.\n","            \n","            if i >= nb_set_parameters - 2:\n","                loss += l2_smooth*self.norm_diff(w)\n","                \n","        return loss\n"," \n","    def train_model(self, optim, X_cens, X_uncens, Y_cens, Y_uncens, lr, l2_reg, l2_smooth):\n","        self.model.train()\n","        optim.step()\n","        optim.zero_grad()\n","        loss = self.loss_function(X_cens, X_uncens, Y_cens, Y_uncens, l2_reg, l2_smooth)\n","        loss.backward()\n","        return loss.item()\n"," \n","    def eval_model(self, X_cens, X_uncens, Y_cens, Y_uncens, l2_reg, l2_smooth):\n","        self.model.eval()\n","        loss = self.loss_function(X_cens, X_uncens, Y_cens, Y_uncens, l2_reg, l2_smooth)\n","        return loss.item()\n"," \n","    def fit(self, X_train, T_train, E_train, epoch, lr, batch_size, X_test=None, T_test=None, E_test=None, l2_reg=1e-2, l2_smooth=1e-2, is_min_time_zero = False, extra_pct_time = 0.):\n","        min_t = 0 if is_min_time_zero else min(T_train)\n","        max_t = max(T_train)*(1+extra_pct_time)\n","        self.times = np.linspace(min_t, max_t, self.num_time_bins+1)\n","        X_cens, X_uncens, Y_cens, Y_uncens = lmtlr.compute_XY(X_train, T_train, E_train, is_min_time_zero, extra_pct_time)\n","        X_cens, X_uncens, Y_cens, Y_uncens = X_cens.to(self.device), X_uncens.to(self.device), Y_cens.to(self.device), Y_uncens.to(self.device)\n"," \n","        optim = Adam(self.model.parameters(), lr=lr)\n","        for i in range(epoch):\n","            print('##### EPOCH '+str(i) + ' #####')\n","            train_loss = self.train_model(optim, X_cens, X_uncens, Y_cens, Y_uncens, lr, l2_reg, l2_smooth)\n","            print('train loss : ' ,train_loss)\n","            if X_test is not None:\n","                test_loss = self.eval_model(X_cens, X_uncens, Y_cens, Y_uncens, l2_reg, l2_smooth)\n","                print('test loss : ' ,test_loss)\n","            #print('\\n')\n"," \n","    def predict_survival(self, x):\n","        x = torch.tensor(x.astype(np.float32)).to(self.device)\n","        with torch.no_grad():\n","            output = self.model(x).data.numpy()\n","        \n","        Triangle1 = np.tri(self.num_time_bins , self.num_time_bins + 1 )\n","        Triangle2 = np.tri(self.num_time_bins + 1, self.num_time_bins + 1)\n","        phi = np.exp( np.dot(output, Triangle1) )\n","        div = np.repeat(np.sum(phi, 1).reshape(-1, 1), phi.shape[1], axis=1)\n","        density = (phi/div)\n","        return np.dot(density, Triangle2)'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'class LR(nn.Module):\\n    def __init__(self, input_size, num_time_bins):\\n        super().__init__()\\n        self.input_size, self.num_time_bins = input_size, num_time_bins\\n        self.fc = torch.nn.Linear(self.input_size, self.num_time_bins)\\n        self.reset_parameters()\\n \\n    def forward(self, x):\\n        out = self.fc(x)\\n        return out\\n \\n    def reset_parameters(self):\\n        self.fc.weight = nn.init.xavier_normal_(self.fc.weight)\\n        self.fc.bias = nn.init.constant_(self.fc.bias, 0.001)\\n \\nclass MTLR():\\n    def __init__(self, model, input_size, num_time_bins):\\n        self.input_size, self.num_time_bins = input_size, num_time_bins\\n        self.device = torch.device(\\'cuda\\' if torch.cuda.is_available() else \\'cpu\\')\\n        self.model = model(self.input_size, self.num_time_bins).to(self.device)\\n        self.triangle = torch.FloatTensor(np.tri(self.num_time_bins, self.num_time_bins + 1, dtype=np.float32))\\n        self.times = None\\n \\n    def process_data(self, x, t, e):\\n        Y_cens, Y_uncens = [], []\\n        X_cens, X_uncens = [], []\\n        for i in range(x.shape[0]):\\n            if e[i] != 0:  # not censored\\n                tmp = np.zeros((self.num_time_bins + 1))\\n                tmp[int(t[i])] = 1\\n                X_uncens.append(x[i,:]), Y_uncens.append(tmp)\\n            else:  # label[i,2]==0: censored\\n                tmp = np.zeros((self.num_time_bins + 1))\\n                tmp[int(t[i] + 1):] = 1  # fill 1 until from the censoring time (to get 1 - \\\\sum F)\\n                X_cens.append(x[i,:]), Y_cens.append(tmp)\\n        return torch.FloatTensor(np.asarray(X_uncens)), torch.FloatTensor(np.asarray(Y_uncens)), torch.FloatTensor(np.asarray(X_cens)), torch.FloatTensor(np.asarray(Y_cens))\\n \\n    def norm_diff(self, W):\\n        \"\"\" Special norm function for the last layer of the MTLR \"\"\"\\n        dims=len(W.shape)\\n        if dims==1:\\n            diff = W[1:]-W[:-1]\\n        elif dims==2:\\n            diff = W[1:, :]-W[:-1, :]\\n        return torch.sum(diff*diff)\\n \\n    def loss_function(self, X_cens, X_uncens, Y_cens, Y_uncens, l2_reg, l2_smooth):\\n        \\n        # Likelihood Calculations -- Uncensored\\n        score_uncens = self.model(X_uncens)\\n        phi_uncens = torch.exp( torch.mm(score_uncens, self.triangle) )\\n        reduc_phi_uncens = torch.sum(phi_uncens*Y_uncens, dim = 1)\\n \\n        # Likelihood Calculations -- Censored\\n        score_cens = self.model(X_cens)\\n        phi_cens = torch.exp( torch.mm(score_cens, self.triangle) )\\n        reduc_phi_cens = torch.sum( phi_cens*Y_cens, dim = 1)\\n \\n        # Likelihood Calculations -- Normalization\\n        z_uncens = torch.exp( torch.mm(score_uncens, self.triangle) )\\n        reduc_z_uncens = torch.sum( z_uncens, dim = 1)\\n \\n        z_cens = torch.exp( torch.mm(score_cens, self.triangle) )\\n        reduc_z_cens = torch.sum( z_cens, dim = 1)\\n \\n        # MTLR cost function\\n        loss = - (\\n                    torch.sum( torch.log(reduc_phi_uncens) )                   + torch.sum( torch.log(reduc_phi_cens) )   \\n                  - torch.sum( torch.log(reduc_z_uncens) )                   - torch.sum( torch.log(reduc_z_cens) ) \\n                 )\\n \\n        # Adding the regularized loss\\n        nb_set_parameters = len(list(self.model.parameters()))\\n        for i, w in enumerate(self.model.parameters()):\\n            loss += l2_reg*torch.sum(w*w)/2.\\n            \\n            if i >= nb_set_parameters - 2:\\n                loss += l2_smooth*self.norm_diff(w)\\n                \\n        return loss\\n \\n    def train_model(self, optim, X_cens, X_uncens, Y_cens, Y_uncens, lr, l2_reg, l2_smooth):\\n        self.model.train()\\n        optim.step()\\n        optim.zero_grad()\\n        loss = self.loss_function(X_cens, X_uncens, Y_cens, Y_uncens, l2_reg, l2_smooth)\\n        loss.backward()\\n        return loss.item()\\n \\n    def eval_model(self, X_cens, X_uncens, Y_cens, Y_uncens, l2_reg, l2_smooth):\\n        self.model.eval()\\n        loss = self.loss_function(X_cens, X_uncens, Y_cens, Y_uncens, l2_reg, l2_smooth)\\n        return loss.item()\\n \\n    def fit(self, X_train, T_train, E_train, epoch, lr, batch_size, X_test=None, T_test=None, E_test=None, l2_reg=1e-2, l2_smooth=1e-2, is_min_time_zero = False, extra_pct_time = 0.):\\n        min_t = 0 if is_min_time_zero else min(T_train)\\n        max_t = max(T_train)*(1+extra_pct_time)\\n        self.times = np.linspace(min_t, max_t, self.num_time_bins+1)\\n        X_cens, X_uncens, Y_cens, Y_uncens = lmtlr.compute_XY(X_train, T_train, E_train, is_min_time_zero, extra_pct_time)\\n        X_cens, X_uncens, Y_cens, Y_uncens = X_cens.to(self.device), X_uncens.to(self.device), Y_cens.to(self.device), Y_uncens.to(self.device)\\n \\n        optim = Adam(self.model.parameters(), lr=lr)\\n        for i in range(epoch):\\n            print(\\'##### EPOCH \\'+str(i) + \\' #####\\')\\n            train_loss = self.train_model(optim, X_cens, X_uncens, Y_cens, Y_uncens, lr, l2_reg, l2_smooth)\\n            print(\\'train loss : \\' ,train_loss)\\n            if X_test is not None:\\n                test_loss = self.eval_model(X_cens, X_uncens, Y_cens, Y_uncens, l2_reg, l2_smooth)\\n                print(\\'test loss : \\' ,test_loss)\\n            #print(\\'\\n\\')\\n \\n    def predict_survival(self, x):\\n        x = torch.tensor(x.astype(np.float32)).to(self.device)\\n        with torch.no_grad():\\n            output = self.model(x).data.numpy()\\n        \\n        Triangle1 = np.tri(self.num_time_bins , self.num_time_bins + 1 )\\n        Triangle2 = np.tri(self.num_time_bins + 1, self.num_time_bins + 1)\\n        phi = np.exp( np.dot(output, Triangle1) )\\n        div = np.repeat(np.sum(phi, 1).reshape(-1, 1), phi.shape[1], axis=1)\\n        density = (phi/div)\\n        return np.dot(density, Triangle2)'"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"o7MW3BDJH23Z","executionInfo":{"status":"ok","timestamp":1602463887533,"user_tz":-60,"elapsed":679756,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}},"outputId":"9e7b073b-9e17-4897-b8ea-d2e502a5dbed","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["num_time_bins, epoch, lr, batch_size = 73, 4000, 1e-5, 512\n"," \n","'''train_load = DataLoader(SURV_DATA(X_train.values, T_train.values, E_train.values, num_time_bins), batch_size=batch_size, shuffle=True)  # DATALOADER obj\n","test_load = DataLoader(SURV_DATA(X_test.values, T_test.values, E_test.values, num_time_bins), batch_size=batch_size, shuffle=True)  # DATALOADER obj\n","l_mtlr = MTLR(LR, X_train.shape[1], num_time_bins, train_load, test_load)\n","#print(l_mtlr.model)\n","l_mtlr.fit(epoch, lr, eval=False)'''\n"," \n","#lr_model = LRMultiTask(X_train.shape[1], num_time_bins)#.to(self.device)\n","nn_model = NN_Multi_Task(X_train.shape[1], num_time_bins, units=[150, 290, 330, 260, 220, 160], factors=None, dropout=[0.2, 0.2, 0.2, 0.2, 0.2, 0.2])\n","l_mtlr = MTLR(nn_model, X_train.shape[1], num_time_bins)\n","print(l_mtlr.model)\n","l_mtlr.fit(X_train.values, T_train.values, E_train.values, epoch, lr, batch_size, X_valid.values, T_valid.values, E_valid.values, extra_pct_time=0.1, l2_reg=1e-2, l2_smooth=1e-2, eval=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n","test loss :  750.976806640625  _______ Metric :  \n","##### EPOCH 2334 #####\n","train loss :  2966.9111328125\n","test loss :  750.982177734375  _______ Metric :  \n","##### EPOCH 2335 #####\n","train loss :  2937.2998046875\n","test loss :  750.972900390625  _______ Metric :  \n","##### EPOCH 2336 #####\n","train loss :  2957.4580078125\n","test loss :  750.968505859375  _______ Metric :  \n","##### EPOCH 2337 #####\n","train loss :  2942.5146484375\n","test loss :  750.963134765625  _______ Metric :  \n","##### EPOCH 2338 #####\n","train loss :  2939.0732421875\n","test loss :  750.964111328125  _______ Metric :  \n","##### EPOCH 2339 #####\n","train loss :  2952.1142578125\n","test loss :  750.965087890625  _______ Metric :  \n","##### EPOCH 2340 #####\n","train loss :  2952.1142578125\n","test loss :  750.961669921875  _______ Metric :  \n","##### EPOCH 2341 #####\n","train loss :  2940.8837890625\n","test loss :  750.960693359375  _______ Metric :  \n","##### EPOCH 2342 #####\n","train loss :  2970.4326171875\n","test loss :  750.960693359375  _______ Metric :  \n","##### EPOCH 2343 #####\n","train loss :  2919.8037109375\n","test loss :  750.965576171875  _______ Metric :  \n","##### EPOCH 2344 #####\n","train loss :  2906.5205078125\n","test loss :  750.969482421875  _______ Metric :  \n","##### EPOCH 2345 #####\n","train loss :  2936.2158203125\n","test loss :  750.970947265625  _______ Metric :  \n","##### EPOCH 2346 #####\n","train loss :  2932.1064453125\n","test loss :  750.975341796875  _______ Metric :  \n","##### EPOCH 2347 #####\n","train loss :  2941.9775390625\n","test loss :  750.975830078125  _______ Metric :  \n","##### EPOCH 2348 #####\n","train loss :  2920.5087890625\n","test loss :  750.972412109375  _______ Metric :  \n","##### EPOCH 2349 #####\n","train loss :  2934.7353515625\n","test loss :  750.973876953125  _______ Metric :  \n","##### EPOCH 2350 #####\n","train loss :  2955.7001953125\n","test loss :  750.973388671875  _______ Metric :  \n","##### EPOCH 2351 #####\n","train loss :  2930.2958984375\n","test loss :  750.970947265625  _______ Metric :  \n","##### EPOCH 2352 #####\n","train loss :  2915.8642578125\n","test loss :  750.970458984375  _______ Metric :  \n","##### EPOCH 2353 #####\n","train loss :  2902.1650390625\n","test loss :  750.980224609375  _______ Metric :  \n","##### EPOCH 2354 #####\n","train loss :  2945.8662109375\n","test loss :  750.978271484375  _______ Metric :  \n","##### EPOCH 2355 #####\n","train loss :  2910.6591796875\n","test loss :  750.979736328125  _______ Metric :  \n","##### EPOCH 2356 #####\n","train loss :  2916.0966796875\n","test loss :  750.979736328125  _______ Metric :  \n","##### EPOCH 2357 #####\n","train loss :  2948.6748046875\n","test loss :  750.969970703125  _______ Metric :  \n","##### EPOCH 2358 #####\n","train loss :  2932.4990234375\n","test loss :  750.955322265625  _______ Metric :  \n","##### EPOCH 2359 #####\n","train loss :  2938.9677734375\n","test loss :  750.946533203125  _______ Metric :  \n","##### EPOCH 2360 #####\n","train loss :  2968.3994140625\n","test loss :  750.937255859375  _______ Metric :  \n","##### EPOCH 2361 #####\n","train loss :  2928.1162109375\n","test loss :  750.931396484375  _______ Metric :  \n","##### EPOCH 2362 #####\n","train loss :  2915.7783203125\n","test loss :  750.923095703125  _______ Metric :  \n","##### EPOCH 2363 #####\n","train loss :  2977.0673828125\n","test loss :  750.913330078125  _______ Metric :  \n","##### EPOCH 2364 #####\n","train loss :  2965.4833984375\n","test loss :  750.906005859375  _______ Metric :  \n","##### EPOCH 2365 #####\n","train loss :  2952.2412109375\n","test loss :  750.897216796875  _______ Metric :  \n","##### EPOCH 2366 #####\n","train loss :  2926.5087890625\n","test loss :  750.892333984375  _______ Metric :  \n","##### EPOCH 2367 #####\n","train loss :  2979.3037109375\n","test loss :  750.881103515625  _______ Metric :  \n","##### EPOCH 2368 #####\n","train loss :  2920.4365234375\n","test loss :  750.879638671875  _______ Metric :  \n","##### EPOCH 2369 #####\n","train loss :  2922.6376953125\n","test loss :  750.872802734375  _______ Metric :  \n","##### EPOCH 2370 #####\n","train loss :  2915.9853515625\n","test loss :  750.865478515625  _______ Metric :  \n","##### EPOCH 2371 #####\n","train loss :  2970.6201171875\n","test loss :  750.8582153320312  _______ Metric :  \n","##### EPOCH 2372 #####\n","train loss :  2936.9853515625\n","test loss :  750.8577270507812  _______ Metric :  \n","##### EPOCH 2373 #####\n","train loss :  2934.9443359375\n","test loss :  750.8543090820312  _______ Metric :  \n","##### EPOCH 2374 #####\n","train loss :  2948.4423828125\n","test loss :  750.8479614257812  _______ Metric :  \n","##### EPOCH 2375 #####\n","train loss :  2942.6689453125\n","test loss :  750.8479614257812  _______ Metric :  \n","##### EPOCH 2376 #####\n","train loss :  2907.2119140625\n","test loss :  750.8518676757812  _______ Metric :  \n","##### EPOCH 2377 #####\n","train loss :  2951.2060546875\n","test loss :  750.8494262695312  _______ Metric :  \n","##### EPOCH 2378 #####\n","train loss :  2952.0419921875\n","test loss :  750.8557739257812  _______ Metric :  \n","##### EPOCH 2379 #####\n","train loss :  2929.3525390625\n","test loss :  750.8601684570312  _______ Metric :  \n","##### EPOCH 2380 #####\n","train loss :  2929.2607421875\n","test loss :  750.8650512695312  _______ Metric :  \n","##### EPOCH 2381 #####\n","train loss :  2946.1318359375\n","test loss :  750.8655395507812  _______ Metric :  \n","##### EPOCH 2382 #####\n","train loss :  2949.2119140625\n","test loss :  750.8679809570312  _______ Metric :  \n","##### EPOCH 2383 #####\n","train loss :  2917.7529296875\n","test loss :  750.8630981445312  _______ Metric :  \n","##### EPOCH 2384 #####\n","train loss :  2986.9814453125\n","test loss :  750.8645629882812  _______ Metric :  \n","##### EPOCH 2385 #####\n","train loss :  2967.5283203125\n","test loss :  750.8640747070312  _______ Metric :  \n","##### EPOCH 2386 #####\n","train loss :  2926.8857421875\n","test loss :  750.8674926757812  _______ Metric :  \n","##### EPOCH 2387 #####\n","train loss :  2924.6708984375\n","test loss :  750.8670043945312  _______ Metric :  \n","##### EPOCH 2388 #####\n","train loss :  2933.9736328125\n","test loss :  750.8626098632812  _______ Metric :  \n","##### EPOCH 2389 #####\n","train loss :  2919.1513671875\n","test loss :  750.8587036132812  _______ Metric :  \n","##### EPOCH 2390 #####\n","train loss :  2929.1083984375\n","test loss :  750.8494262695312  _______ Metric :  \n","##### EPOCH 2391 #####\n","train loss :  2991.5185546875\n","test loss :  750.8464965820312  _______ Metric :  \n","##### EPOCH 2392 #####\n","train loss :  2980.1103515625\n","test loss :  750.8377075195312  _______ Metric :  \n","##### EPOCH 2393 #####\n","train loss :  2961.0498046875\n","test loss :  750.8323364257812  _______ Metric :  \n","##### EPOCH 2394 #####\n","train loss :  2947.1298828125\n","test loss :  750.8240356445312  _______ Metric :  \n","##### EPOCH 2395 #####\n","train loss :  2997.8798828125\n","test loss :  750.8186645507812  _______ Metric :  \n","##### EPOCH 2396 #####\n","train loss :  2934.6162109375\n","test loss :  750.8113403320312  _______ Metric :  \n","##### EPOCH 2397 #####\n","train loss :  2938.5712890625\n","test loss :  750.8113403320312  _______ Metric :  \n","##### EPOCH 2398 #####\n","train loss :  2918.9306640625\n","test loss :  750.8113403320312  _______ Metric :  \n","##### EPOCH 2399 #####\n","train loss :  2900.9931640625\n","test loss :  750.8147583007812  _______ Metric :  \n","##### EPOCH 2400 #####\n","train loss :  2913.9169921875\n","test loss :  750.8137817382812  _______ Metric :  \n","##### EPOCH 2401 #####\n","train loss :  2941.8134765625\n","test loss :  750.8074340820312  _______ Metric :  \n","##### EPOCH 2402 #####\n","train loss :  2978.0517578125\n","test loss :  750.7942504882812  _______ Metric :  \n","##### EPOCH 2403 #####\n","train loss :  2978.1376953125\n","test loss :  750.7937622070312  _______ Metric :  \n","##### EPOCH 2404 #####\n","train loss :  2965.4873046875\n","test loss :  750.7903442382812  _______ Metric :  \n","##### EPOCH 2405 #####\n","train loss :  2933.2373046875\n","test loss :  750.7913208007812  _______ Metric :  \n","##### EPOCH 2406 #####\n","train loss :  3012.5908203125\n","test loss :  750.7913208007812  _______ Metric :  \n","##### EPOCH 2407 #####\n","train loss :  2956.8876953125\n","test loss :  750.7986450195312  _______ Metric :  \n","##### EPOCH 2408 #####\n","train loss :  2947.7138671875\n","test loss :  750.7957153320312  _______ Metric :  \n","##### EPOCH 2409 #####\n","train loss :  2956.8212890625\n","test loss :  750.7913208007812  _______ Metric :  \n","##### EPOCH 2410 #####\n","train loss :  2917.8193359375\n","test loss :  750.7898559570312  _______ Metric :  \n","##### EPOCH 2411 #####\n","train loss :  2937.4267578125\n","test loss :  750.7893676757812  _______ Metric :  \n","##### EPOCH 2412 #####\n","train loss :  2906.7236328125\n","test loss :  750.7932739257812  _______ Metric :  \n","##### EPOCH 2413 #####\n","train loss :  2917.5283203125\n","test loss :  750.7927856445312  _______ Metric :  \n","##### EPOCH 2414 #####\n","train loss :  2968.0673828125\n","test loss :  750.7903442382812  _______ Metric :  \n","##### EPOCH 2415 #####\n","train loss :  2952.1630859375\n","test loss :  750.8001098632812  _______ Metric :  \n","##### EPOCH 2416 #####\n","train loss :  2925.1201171875\n","test loss :  750.7986450195312  _______ Metric :  \n","##### EPOCH 2417 #####\n","train loss :  2947.6044921875\n","test loss :  750.8020629882812  _______ Metric :  \n","##### EPOCH 2418 #####\n","train loss :  2932.2412109375\n","test loss :  750.8045043945312  _______ Metric :  \n","##### EPOCH 2419 #####\n","train loss :  2959.8642578125\n","test loss :  750.8005981445312  _______ Metric :  \n","##### EPOCH 2420 #####\n","train loss :  2936.6337890625\n","test loss :  750.8035278320312  _______ Metric :  \n","##### EPOCH 2421 #####\n","train loss :  2961.8212890625\n","test loss :  750.8015747070312  _______ Metric :  \n","##### EPOCH 2422 #####\n","train loss :  2934.4521484375\n","test loss :  750.8010864257812  _______ Metric :  \n","##### EPOCH 2423 #####\n","train loss :  2936.4931640625\n","test loss :  750.8020629882812  _______ Metric :  \n","##### EPOCH 2424 #####\n","train loss :  2988.3154296875\n","test loss :  750.7986450195312  _______ Metric :  \n","##### EPOCH 2425 #####\n","train loss :  2941.1572265625\n","test loss :  750.8005981445312  _______ Metric :  \n","##### EPOCH 2426 #####\n","train loss :  2916.2841796875\n","test loss :  750.8020629882812  _______ Metric :  \n","##### EPOCH 2427 #####\n","train loss :  2946.9384765625\n","test loss :  750.7976684570312  _______ Metric :  \n","##### EPOCH 2428 #####\n","train loss :  2971.4287109375\n","test loss :  750.7913208007812  _______ Metric :  \n","##### EPOCH 2429 #####\n","train loss :  2921.9072265625\n","test loss :  750.7854614257812  _______ Metric :  \n","##### EPOCH 2430 #####\n","train loss :  2952.9384765625\n","test loss :  750.7791137695312  _______ Metric :  \n","##### EPOCH 2431 #####\n","train loss :  2943.8955078125\n","test loss :  750.7717895507812  _______ Metric :  \n","##### EPOCH 2432 #####\n","train loss :  2933.6943359375\n","test loss :  750.7664184570312  _______ Metric :  \n","##### EPOCH 2433 #####\n","train loss :  2914.4150390625\n","test loss :  750.7522583007812  _______ Metric :  \n","##### EPOCH 2434 #####\n","train loss :  2941.8330078125\n","test loss :  750.7517700195312  _______ Metric :  \n","##### EPOCH 2435 #####\n","train loss :  2926.1962890625\n","test loss :  750.7517700195312  _______ Metric :  \n","##### EPOCH 2436 #####\n","train loss :  2967.5458984375\n","test loss :  750.7478637695312  _______ Metric :  \n","##### EPOCH 2437 #####\n","train loss :  2972.5654296875\n","test loss :  750.7459106445312  _______ Metric :  \n","##### EPOCH 2438 #####\n","train loss :  2937.5263671875\n","test loss :  750.7473754882812  _______ Metric :  \n","##### EPOCH 2439 #####\n","train loss :  2910.8173828125\n","test loss :  750.7522583007812  _______ Metric :  \n","##### EPOCH 2440 #####\n","train loss :  2975.1669921875\n","test loss :  750.7503051757812  _______ Metric :  \n","##### EPOCH 2441 #####\n","train loss :  2900.8837890625\n","test loss :  750.7537231445312  _______ Metric :  \n","##### EPOCH 2442 #####\n","train loss :  2938.1005859375\n","test loss :  750.7576293945312  _______ Metric :  \n","##### EPOCH 2443 #####\n","train loss :  2957.0263671875\n","test loss :  750.7615356445312  _______ Metric :  \n","##### EPOCH 2444 #####\n","train loss :  2909.4580078125\n","test loss :  750.7683715820312  _______ Metric :  \n","##### EPOCH 2445 #####\n","train loss :  2898.9716796875\n","test loss :  750.7791137695312  _______ Metric :  \n","##### EPOCH 2446 #####\n","train loss :  2942.9619140625\n","test loss :  750.7879028320312  _______ Metric :  \n","##### EPOCH 2447 #####\n","train loss :  2915.7333984375\n","test loss :  750.7844848632812  _______ Metric :  \n","##### EPOCH 2448 #####\n","train loss :  2941.4775390625\n","test loss :  750.7879028320312  _______ Metric :  \n","##### EPOCH 2449 #####\n","train loss :  2947.1708984375\n","test loss :  750.7883911132812  _______ Metric :  \n","##### EPOCH 2450 #####\n","train loss :  2934.8779296875\n","test loss :  750.7942504882812  _______ Metric :  \n","##### EPOCH 2451 #####\n","train loss :  2943.4013671875\n","test loss :  750.8113403320312  _______ Metric :  \n","##### EPOCH 2452 #####\n","train loss :  2911.3623046875\n","test loss :  750.8132934570312  _______ Metric :  \n","##### EPOCH 2453 #####\n","train loss :  2937.8916015625\n","test loss :  750.8196411132812  _______ Metric :  \n","##### EPOCH 2454 #####\n","train loss :  2924.0927734375\n","test loss :  750.8308715820312  _______ Metric :  \n","##### EPOCH 2455 #####\n","train loss :  2909.3173828125\n","test loss :  750.8348388671875  _______ Metric :  \n","##### EPOCH 2456 #####\n","train loss :  2951.0576171875\n","test loss :  750.8455810546875  _______ Metric :  \n","##### EPOCH 2457 #####\n","train loss :  2906.669189453125\n","test loss :  750.8543701171875  _______ Metric :  \n","##### EPOCH 2458 #####\n","train loss :  2949.450439453125\n","test loss :  750.8621826171875  _______ Metric :  \n","##### EPOCH 2459 #####\n","train loss :  2962.532470703125\n","test loss :  750.8660888671875  _______ Metric :  \n","##### EPOCH 2460 #####\n","train loss :  2926.694580078125\n","test loss :  750.8675537109375  _______ Metric :  \n","##### EPOCH 2461 #####\n","train loss :  2932.796142578125\n","test loss :  750.8753662109375  _______ Metric :  \n","##### EPOCH 2462 #####\n","train loss :  2949.001220703125\n","test loss :  750.8763427734375  _______ Metric :  \n","##### EPOCH 2463 #####\n","train loss :  2949.034423828125\n","test loss :  750.8719482421875  _______ Metric :  \n","##### EPOCH 2464 #####\n","train loss :  2953.659423828125\n","test loss :  750.8797607421875  _______ Metric :  \n","##### EPOCH 2465 #####\n","train loss :  2931.270751953125\n","test loss :  750.8846435546875  _______ Metric :  \n","##### EPOCH 2466 #####\n","train loss :  2879.175048828125\n","test loss :  750.8748779296875  _______ Metric :  \n","##### EPOCH 2467 #####\n","train loss :  3003.089111328125\n","test loss :  750.8636474609375  _______ Metric :  \n","##### EPOCH 2468 #####\n","train loss :  2931.184814453125\n","test loss :  750.8607177734375  _______ Metric :  \n","##### EPOCH 2469 #####\n","train loss :  2945.692626953125\n","test loss :  750.8612060546875  _______ Metric :  \n","##### EPOCH 2470 #####\n","train loss :  2943.835205078125\n","test loss :  750.8509521484375  _______ Metric :  \n","##### EPOCH 2471 #####\n","train loss :  2943.272705078125\n","test loss :  750.8494873046875  _______ Metric :  \n","##### EPOCH 2472 #####\n","train loss :  2923.241455078125\n","test loss :  750.8406982421875  _______ Metric :  \n","##### EPOCH 2473 #####\n","train loss :  2977.153564453125\n","test loss :  750.8289794921875  _______ Metric :  \n","##### EPOCH 2474 #####\n","train loss :  2929.372314453125\n","test loss :  750.8206787109375  _______ Metric :  \n","##### EPOCH 2475 #####\n","train loss :  2909.927001953125\n","test loss :  750.8109130859375  _______ Metric :  \n","##### EPOCH 2476 #####\n","train loss :  2940.606689453125\n","test loss :  750.7947998046875  _______ Metric :  \n","##### EPOCH 2477 #####\n","train loss :  2932.823486328125\n","test loss :  750.7845458984375  _______ Metric :  \n","##### EPOCH 2478 #####\n","train loss :  2943.581298828125\n","test loss :  750.7811279296875  _______ Metric :  \n","##### EPOCH 2479 #####\n","train loss :  2960.856689453125\n","test loss :  750.7718505859375  _______ Metric :  \n","##### EPOCH 2480 #####\n","train loss :  2968.110595703125\n","test loss :  750.7703857421875  _______ Metric :  \n","##### EPOCH 2481 #####\n","train loss :  2903.843017578125\n","test loss :  750.7728271484375  _______ Metric :  \n","##### EPOCH 2482 #####\n","train loss :  2943.514892578125\n","test loss :  750.7772216796875  _______ Metric :  \n","##### EPOCH 2483 #####\n","train loss :  2956.977783203125\n","test loss :  750.7747802734375  _______ Metric :  \n","##### EPOCH 2484 #####\n","train loss :  2968.762939453125\n","test loss :  750.7757568359375  _______ Metric :  \n","##### EPOCH 2485 #####\n","train loss :  2971.561767578125\n","test loss :  750.7777099609375  _______ Metric :  \n","##### EPOCH 2486 #####\n","train loss :  2917.290283203125\n","test loss :  750.7884521484375  _______ Metric :  \n","##### EPOCH 2487 #####\n","train loss :  2950.583251953125\n","test loss :  750.7908935546875  _______ Metric :  \n","##### EPOCH 2488 #####\n","train loss :  2917.327392578125\n","test loss :  750.7923583984375  _______ Metric :  \n","##### EPOCH 2489 #####\n","train loss :  2934.264892578125\n","test loss :  750.8060302734375  _______ Metric :  \n","##### EPOCH 2490 #####\n","train loss :  2946.028564453125\n","test loss :  750.8118896484375  _______ Metric :  \n","##### EPOCH 2491 #####\n","train loss :  2986.395751953125\n","test loss :  750.8211669921875  _______ Metric :  \n","##### EPOCH 2492 #####\n","train loss :  2917.001220703125\n","test loss :  750.8255615234375  _______ Metric :  \n","##### EPOCH 2493 #####\n","train loss :  2972.882080078125\n","test loss :  750.8402099609375  _______ Metric :  \n","##### EPOCH 2494 #####\n","train loss :  2911.452392578125\n","test loss :  750.8485107421875  _______ Metric :  \n","##### EPOCH 2495 #####\n","train loss :  2954.284423828125\n","test loss :  750.8465576171875  _______ Metric :  \n","##### EPOCH 2496 #####\n","train loss :  2933.844970703125\n","test loss :  750.8548583984375  _______ Metric :  \n","##### EPOCH 2497 #####\n","train loss :  2948.122314453125\n","test loss :  750.8548583984375  _______ Metric :  \n","##### EPOCH 2498 #####\n","train loss :  2966.173095703125\n","test loss :  750.8572998046875  _______ Metric :  \n","##### EPOCH 2499 #####\n","train loss :  2945.995361328125\n","test loss :  750.8504638671875  _______ Metric :  \n","##### EPOCH 2500 #####\n","train loss :  2952.534423828125\n","test loss :  750.8499755859375  _______ Metric :  \n","##### EPOCH 2501 #####\n","train loss :  2943.780517578125\n","test loss :  750.8543701171875  _______ Metric :  \n","##### EPOCH 2502 #####\n","train loss :  2950.444580078125\n","test loss :  750.8524169921875  _______ Metric :  \n","##### EPOCH 2503 #####\n","train loss :  2925.143798828125\n","test loss :  750.8514404296875  _______ Metric :  \n","##### EPOCH 2504 #####\n","train loss :  2946.811767578125\n","test loss :  750.8475341796875  _______ Metric :  \n","##### EPOCH 2505 #####\n","train loss :  2909.729736328125\n","test loss :  750.8426513671875  _______ Metric :  \n","##### EPOCH 2506 #####\n","train loss :  2892.251220703125\n","test loss :  750.8382568359375  _______ Metric :  \n","##### EPOCH 2507 #####\n","train loss :  2948.854736328125\n","test loss :  750.8270263671875  _______ Metric :  \n","##### EPOCH 2508 #####\n","train loss :  2914.864501953125\n","test loss :  750.8177490234375  _______ Metric :  \n","##### EPOCH 2509 #####\n","train loss :  2960.741455078125\n","test loss :  750.8045654296875  _______ Metric :  \n","##### EPOCH 2510 #####\n","train loss :  2914.829345703125\n","test loss :  750.7977294921875  _______ Metric :  \n","##### EPOCH 2511 #####\n","train loss :  2897.989501953125\n","test loss :  750.7869873046875  _______ Metric :  \n","##### EPOCH 2512 #####\n","train loss :  2918.579345703125\n","test loss :  750.7733154296875  _______ Metric :  \n","##### EPOCH 2513 #####\n","train loss :  2894.251220703125\n","test loss :  750.7606201171875  _______ Metric :  \n","##### EPOCH 2514 #####\n","train loss :  2957.231689453125\n","test loss :  750.7557373046875  _______ Metric :  \n","##### EPOCH 2515 #####\n","train loss :  2917.704345703125\n","test loss :  750.7425537109375  _______ Metric :  \n","##### EPOCH 2516 #####\n","train loss :  2940.333251953125\n","test loss :  750.7313232421875  _______ Metric :  \n","##### EPOCH 2517 #####\n","train loss :  2929.745361328125\n","test loss :  750.7220458984375  _______ Metric :  \n","##### EPOCH 2518 #####\n","train loss :  2971.001220703125\n","test loss :  750.7142333984375  _______ Metric :  \n","##### EPOCH 2519 #####\n","train loss :  2969.466064453125\n","test loss :  750.7078857421875  _______ Metric :  \n","##### EPOCH 2520 #####\n","train loss :  2908.180908203125\n","test loss :  750.7127685546875  _______ Metric :  \n","##### EPOCH 2521 #####\n","train loss :  2957.848876953125\n","test loss :  750.7210693359375  _______ Metric :  \n","##### EPOCH 2522 #####\n","train loss :  2925.077392578125\n","test loss :  750.7279052734375  _______ Metric :  \n","##### EPOCH 2523 #####\n","train loss :  2942.194580078125\n","test loss :  750.7342529296875  _______ Metric :  \n","##### EPOCH 2524 #####\n","train loss :  2916.850830078125\n","test loss :  750.7406005859375  _______ Metric :  \n","##### EPOCH 2525 #####\n","train loss :  2893.497314453125\n","test loss :  750.7401123046875  _______ Metric :  \n","##### EPOCH 2526 #####\n","train loss :  2896.341064453125\n","test loss :  750.7406005859375  _______ Metric :  \n","##### EPOCH 2527 #####\n","train loss :  2975.829345703125\n","test loss :  750.7469482421875  _______ Metric :  \n","##### EPOCH 2528 #####\n","train loss :  2947.329345703125\n","test loss :  750.7410888671875  _______ Metric :  \n","##### EPOCH 2529 #####\n","train loss :  2963.040283203125\n","test loss :  750.7332763671875  _______ Metric :  \n","##### EPOCH 2530 #####\n","train loss :  2936.454345703125\n","test loss :  750.7313232421875  _______ Metric :  \n","##### EPOCH 2531 #####\n","train loss :  2951.969970703125\n","test loss :  750.7254638671875  _______ Metric :  \n","##### EPOCH 2532 #####\n","train loss :  2954.466064453125\n","test loss :  750.7264404296875  _______ Metric :  \n","##### EPOCH 2533 #####\n","train loss :  2912.747314453125\n","test loss :  750.7230224609375  _______ Metric :  \n","##### EPOCH 2534 #####\n","train loss :  2921.960205078125\n","test loss :  750.7259521484375  _______ Metric :  \n","##### EPOCH 2535 #####\n","train loss :  2945.145751953125\n","test loss :  750.7156982421875  _______ Metric :  \n","##### EPOCH 2536 #####\n","train loss :  2948.073486328125\n","test loss :  750.7044677734375  _______ Metric :  \n","##### EPOCH 2537 #####\n","train loss :  2970.346923828125\n","test loss :  750.6888427734375  _______ Metric :  \n","##### EPOCH 2538 #####\n","train loss :  2929.833251953125\n","test loss :  750.6781005859375  _______ Metric :  \n","##### EPOCH 2539 #####\n","train loss :  2952.264892578125\n","test loss :  750.6732177734375  _______ Metric :  \n","##### EPOCH 2540 #####\n","train loss :  2949.382080078125\n","test loss :  750.6697998046875  _______ Metric :  \n","##### EPOCH 2541 #####\n","train loss :  2910.120361328125\n","test loss :  750.6639404296875  _______ Metric :  \n","##### EPOCH 2542 #####\n","train loss :  2964.567626953125\n","test loss :  750.6595458984375  _______ Metric :  \n","##### EPOCH 2543 #####\n","train loss :  2951.298095703125\n","test loss :  750.6522216796875  _______ Metric :  \n","##### EPOCH 2544 #####\n","train loss :  3035.776611328125\n","test loss :  750.6546630859375  _______ Metric :  \n","##### EPOCH 2545 #####\n","train loss :  2916.497314453125\n","test loss :  750.6497802734375  _______ Metric :  \n","##### EPOCH 2546 #####\n","train loss :  2925.065673828125\n","test loss :  750.6483154296875  _______ Metric :  \n","##### EPOCH 2547 #####\n","train loss :  2904.587158203125\n","test loss :  750.6502685546875  _______ Metric :  \n","##### EPOCH 2548 #####\n","train loss :  2911.040283203125\n","test loss :  750.6400146484375  _______ Metric :  \n","##### EPOCH 2549 #####\n","train loss :  2888.206298828125\n","test loss :  750.6365966796875  _______ Metric :  \n","##### EPOCH 2550 #####\n","train loss :  2940.063720703125\n","test loss :  750.6463623046875  _______ Metric :  \n","##### EPOCH 2551 #####\n","train loss :  2896.116455078125\n","test loss :  750.6429443359375  _______ Metric :  \n","##### EPOCH 2552 #####\n","train loss :  2893.981689453125\n","test loss :  750.6439208984375  _______ Metric :  \n","##### EPOCH 2553 #####\n","train loss :  2923.702392578125\n","test loss :  750.6375732421875  _______ Metric :  \n","##### EPOCH 2554 #####\n","train loss :  2922.983642578125\n","test loss :  750.6361083984375  _______ Metric :  \n","##### EPOCH 2555 #####\n","train loss :  2950.132080078125\n","test loss :  750.6380615234375  _______ Metric :  \n","##### EPOCH 2556 #####\n","train loss :  2930.997314453125\n","test loss :  750.6400146484375  _______ Metric :  \n","##### EPOCH 2557 #####\n","train loss :  2922.528564453125\n","test loss :  750.6380615234375  _______ Metric :  \n","##### EPOCH 2558 #####\n","train loss :  2930.802001953125\n","test loss :  750.6370849609375  _______ Metric :  \n","##### EPOCH 2559 #####\n","train loss :  2910.837158203125\n","test loss :  750.6346435546875  _______ Metric :  \n","##### EPOCH 2560 #####\n","train loss :  2933.249267578125\n","test loss :  750.6273193359375  _______ Metric :  \n","##### EPOCH 2561 #####\n","train loss :  2931.196533203125\n","test loss :  750.6322021484375  _______ Metric :  \n","##### EPOCH 2562 #####\n","train loss :  2922.739501953125\n","test loss :  750.6243896484375  _______ Metric :  \n","##### EPOCH 2563 #####\n","train loss :  2955.153564453125\n","test loss :  750.6151123046875  _______ Metric :  \n","##### EPOCH 2564 #####\n","train loss :  2922.860595703125\n","test loss :  750.6121826171875  _______ Metric :  \n","##### EPOCH 2565 #####\n","train loss :  2959.124267578125\n","test loss :  750.6175537109375  _______ Metric :  \n","##### EPOCH 2566 #####\n","train loss :  2930.682861328125\n","test loss :  750.6190185546875  _______ Metric :  \n","##### EPOCH 2567 #####\n","train loss :  2967.052001953125\n","test loss :  750.6151123046875  _______ Metric :  \n","##### EPOCH 2568 #####\n","train loss :  2927.915283203125\n","test loss :  750.6141357421875  _______ Metric :  \n","##### EPOCH 2569 #####\n","train loss :  2942.335205078125\n","test loss :  750.6126708984375  _______ Metric :  \n","##### EPOCH 2570 #####\n","train loss :  2934.425048828125\n","test loss :  750.6121826171875  _______ Metric :  \n","##### EPOCH 2571 #####\n","train loss :  2946.708251953125\n","test loss :  750.6131591796875  _______ Metric :  \n","##### EPOCH 2572 #####\n","train loss :  2918.731689453125\n","test loss :  750.6116943359375  _______ Metric :  \n","##### EPOCH 2573 #####\n","train loss :  2928.889892578125\n","test loss :  750.6048583984375  _______ Metric :  \n","##### EPOCH 2574 #####\n","train loss :  2916.907470703125\n","test loss :  750.6033935546875  _______ Metric :  \n","##### EPOCH 2575 #####\n","train loss :  2923.690673828125\n","test loss :  750.5985107421875  _______ Metric :  \n","##### EPOCH 2576 #####\n","train loss :  2953.626220703125\n","test loss :  750.5985107421875  _______ Metric :  \n","##### EPOCH 2577 #####\n","train loss :  2963.009033203125\n","test loss :  750.6097412109375  _______ Metric :  \n","##### EPOCH 2578 #####\n","train loss :  2917.257080078125\n","test loss :  750.6165771484375  _______ Metric :  \n","##### EPOCH 2579 #####\n","train loss :  2921.852783203125\n","test loss :  750.6175537109375  _______ Metric :  \n","##### EPOCH 2580 #####\n","train loss :  2919.686767578125\n","test loss :  750.6229248046875  _______ Metric :  \n","##### EPOCH 2581 #####\n","train loss :  2936.323486328125\n","test loss :  750.6209716796875  _______ Metric :  \n","##### EPOCH 2582 #####\n","train loss :  2953.620361328125\n","test loss :  750.6224365234375  _______ Metric :  \n","##### EPOCH 2583 #####\n","train loss :  2937.489501953125\n","test loss :  750.6190185546875  _______ Metric :  \n","##### EPOCH 2584 #####\n","train loss :  2939.817626953125\n","test loss :  750.6175537109375  _______ Metric :  \n","##### EPOCH 2585 #####\n","train loss :  2951.917236328125\n","test loss :  750.6102294921875  _______ Metric :  \n","##### EPOCH 2586 #####\n","train loss :  2915.747314453125\n","test loss :  750.6116943359375  _______ Metric :  \n","##### EPOCH 2587 #####\n","train loss :  2959.005126953125\n","test loss :  750.6048583984375  _______ Metric :  \n","##### EPOCH 2588 #####\n","train loss :  2943.729736328125\n","test loss :  750.5931396484375  _______ Metric :  \n","##### EPOCH 2589 #####\n","train loss :  2984.395751953125\n","test loss :  750.5863037109375  _______ Metric :  \n","##### EPOCH 2590 #####\n","train loss :  2932.913330078125\n","test loss :  750.5770263671875  _______ Metric :  \n","##### EPOCH 2591 #####\n","train loss :  2927.745361328125\n","test loss :  750.5745849609375  _______ Metric :  \n","##### EPOCH 2592 #####\n","train loss :  2938.352783203125\n","test loss :  750.5745849609375  _______ Metric :  \n","##### EPOCH 2593 #####\n","train loss :  2943.339111328125\n","test loss :  750.5780029296875  _______ Metric :  \n","##### EPOCH 2594 #####\n","train loss :  2956.971923828125\n","test loss :  750.5716552734375  _______ Metric :  \n","##### EPOCH 2595 #####\n","train loss :  2954.727783203125\n","test loss :  750.5633544921875  _______ Metric :  \n","##### EPOCH 2596 #####\n","train loss :  2975.811767578125\n","test loss :  750.5579833984375  _______ Metric :  \n","##### EPOCH 2597 #####\n","train loss :  2943.678955078125\n","test loss :  750.5560302734375  _______ Metric :  \n","##### EPOCH 2598 #####\n","train loss :  2914.260986328125\n","test loss :  750.5560302734375  _______ Metric :  \n","##### EPOCH 2599 #####\n","train loss :  2924.639892578125\n","test loss :  750.5526123046875  _______ Metric :  \n","##### EPOCH 2600 #####\n","train loss :  2968.466064453125\n","test loss :  750.5550537109375  _______ Metric :  \n","##### EPOCH 2601 #####\n","train loss :  2920.866455078125\n","test loss :  750.5526123046875  _______ Metric :  \n","##### EPOCH 2602 #####\n","train loss :  2926.651611328125\n","test loss :  750.5589599609375  _______ Metric :  \n","##### EPOCH 2603 #####\n","train loss :  2942.507080078125\n","test loss :  750.5535888671875  _______ Metric :  \n","##### EPOCH 2604 #####\n","train loss :  2919.569580078125\n","test loss :  750.5599365234375  _______ Metric :  \n","##### EPOCH 2605 #####\n","train loss :  2963.479736328125\n","test loss :  750.5633544921875  _______ Metric :  \n","##### EPOCH 2606 #####\n","train loss :  2929.282470703125\n","test loss :  750.5711669921875  _______ Metric :  \n","##### EPOCH 2607 #####\n","train loss :  2935.143798828125\n","test loss :  750.5775146484375  _______ Metric :  \n","##### EPOCH 2608 #####\n","train loss :  2931.098876953125\n","test loss :  750.5790405273438  _______ Metric :  \n","##### EPOCH 2609 #####\n","train loss :  2968.680908203125\n","test loss :  750.5800170898438  _______ Metric :  \n","##### EPOCH 2610 #####\n","train loss :  2945.180908203125\n","test loss :  750.5829467773438  _______ Metric :  \n","##### EPOCH 2611 #####\n","train loss :  2918.876220703125\n","test loss :  750.5868530273438  _______ Metric :  \n","##### EPOCH 2612 #####\n","train loss :  2903.354736328125\n","test loss :  750.5863647460938  _______ Metric :  \n","##### EPOCH 2613 #####\n","train loss :  2941.305908203125\n","test loss :  750.5888061523438  _______ Metric :  \n","##### EPOCH 2614 #####\n","train loss :  2963.436767578125\n","test loss :  750.5912475585938  _______ Metric :  \n","##### EPOCH 2615 #####\n","train loss :  2908.885986328125\n","test loss :  750.5941772460938  _______ Metric :  \n","##### EPOCH 2616 #####\n","train loss :  2938.559814453125\n","test loss :  750.5927124023438  _______ Metric :  \n","##### EPOCH 2617 #####\n","train loss :  2944.518798828125\n","test loss :  750.5848999023438  _______ Metric :  \n","##### EPOCH 2618 #####\n","train loss :  2923.729736328125\n","test loss :  750.5805053710938  _______ Metric :  \n","##### EPOCH 2619 #####\n","train loss :  2946.434814453125\n","test loss :  750.5746459960938  _______ Metric :  \n","##### EPOCH 2620 #####\n","train loss :  2974.671142578125\n","test loss :  750.56884765625  _______ Metric :  \n","##### EPOCH 2621 #####\n","train loss :  2978.085205078125\n","test loss :  750.56494140625  _______ Metric :  \n","##### EPOCH 2622 #####\n","train loss :  2963.880126953125\n","test loss :  750.55712890625  _______ Metric :  \n","##### EPOCH 2623 #####\n","train loss :  2931.178955078125\n","test loss :  750.552734375  _______ Metric :  \n","##### EPOCH 2624 #####\n","train loss :  2927.354736328125\n","test loss :  750.54833984375  _______ Metric :  \n","##### EPOCH 2625 #####\n","train loss :  2925.450439453125\n","test loss :  750.54150390625  _______ Metric :  \n","##### EPOCH 2626 #####\n","train loss :  2957.419189453125\n","test loss :  750.53173828125  _______ Metric :  \n","##### EPOCH 2627 #####\n","train loss :  2922.540283203125\n","test loss :  750.51806640625  _______ Metric :  \n","##### EPOCH 2628 #####\n","train loss :  2955.557861328125\n","test loss :  750.51171875  _______ Metric :  \n","##### EPOCH 2629 #####\n","train loss :  2967.862548828125\n","test loss :  750.5  _______ Metric :  \n","##### EPOCH 2630 #####\n","train loss :  2932.245361328125\n","test loss :  750.49462890625  _______ Metric :  \n","##### EPOCH 2631 #####\n","train loss :  2924.505126953125\n","test loss :  750.4912109375  _______ Metric :  \n","##### EPOCH 2632 #####\n","train loss :  2937.075439453125\n","test loss :  750.48486328125  _______ Metric :  \n","##### EPOCH 2633 #####\n","train loss :  2939.680908203125\n","test loss :  750.48291015625  _______ Metric :  \n","##### EPOCH 2634 #####\n","train loss :  2949.280517578125\n","test loss :  750.478515625  _______ Metric :  \n","##### EPOCH 2635 #####\n","train loss :  2938.589111328125\n","test loss :  750.46484375  _______ Metric :  \n","##### EPOCH 2636 #####\n","train loss :  2945.827392578125\n","test loss :  750.4521484375  _______ Metric :  \n","##### EPOCH 2637 #####\n","train loss :  2909.253173828125\n","test loss :  750.439453125  _______ Metric :  \n","##### EPOCH 2638 #####\n","train loss :  2962.968017578125\n","test loss :  750.42431640625  _______ Metric :  \n","##### EPOCH 2639 #####\n","train loss :  2918.891845703125\n","test loss :  750.40771484375  _______ Metric :  \n","##### EPOCH 2640 #####\n","train loss :  2949.927001953125\n","test loss :  750.4013671875  _______ Metric :  \n","##### EPOCH 2641 #####\n","train loss :  2937.145751953125\n","test loss :  750.3955078125  _______ Metric :  \n","##### EPOCH 2642 #####\n","train loss :  2940.544189453125\n","test loss :  750.39599609375  _______ Metric :  \n","##### EPOCH 2643 #####\n","train loss :  2964.673095703125\n","test loss :  750.39453125  _______ Metric :  \n","##### EPOCH 2644 #####\n","train loss :  2955.024658203125\n","test loss :  750.39306640625  _______ Metric :  \n","##### EPOCH 2645 #####\n","train loss :  2931.050048828125\n","test loss :  750.38916015625  _______ Metric :  \n","##### EPOCH 2646 #####\n","train loss :  2975.415283203125\n","test loss :  750.38720703125  _______ Metric :  \n","##### EPOCH 2647 #####\n","train loss :  2934.677001953125\n","test loss :  750.38330078125  _______ Metric :  \n","##### EPOCH 2648 #####\n","train loss :  2977.257080078125\n","test loss :  750.37646484375  _______ Metric :  \n","##### EPOCH 2649 #####\n","train loss :  2933.352783203125\n","test loss :  750.375  _______ Metric :  \n","##### EPOCH 2650 #####\n","train loss :  2933.866455078125\n","test loss :  750.38134765625  _______ Metric :  \n","##### EPOCH 2651 #####\n","train loss :  2939.165283203125\n","test loss :  750.3798828125  _______ Metric :  \n","##### EPOCH 2652 #####\n","train loss :  2931.475830078125\n","test loss :  750.3779296875  _______ Metric :  \n","##### EPOCH 2653 #####\n","train loss :  2964.231689453125\n","test loss :  750.3818969726562  _______ Metric :  \n","##### EPOCH 2654 #####\n","train loss :  2967.690673828125\n","test loss :  750.3848266601562  _______ Metric :  \n","##### EPOCH 2655 #####\n","train loss :  2959.809814453125\n","test loss :  750.3765258789062  _______ Metric :  \n","##### EPOCH 2656 #####\n","train loss :  2934.428955078125\n","test loss :  750.3731079101562  _______ Metric :  \n","##### EPOCH 2657 #####\n","train loss :  2955.249267578125\n","test loss :  750.3784790039062  _______ Metric :  \n","##### EPOCH 2658 #####\n","train loss :  2971.270751953125\n","test loss :  750.3726196289062  _______ Metric :  \n","##### EPOCH 2659 #####\n","train loss :  2933.854736328125\n","test loss :  750.3799438476562  _______ Metric :  \n","##### EPOCH 2660 #####\n","train loss :  2927.247314453125\n","test loss :  750.3760375976562  _______ Metric :  \n","##### EPOCH 2661 #####\n","train loss :  2928.745361328125\n","test loss :  750.3745727539062  _______ Metric :  \n","##### EPOCH 2662 #####\n","train loss :  2947.050048828125\n","test loss :  750.3677368164062  _______ Metric :  \n","##### EPOCH 2663 #####\n","train loss :  2959.284423828125\n","test loss :  750.3569946289062  _______ Metric :  \n","##### EPOCH 2664 #####\n","train loss :  2911.704345703125\n","test loss :  750.3472290039062  _______ Metric :  \n","##### EPOCH 2665 #####\n","train loss :  2947.464111328125\n","test loss :  750.3413696289062  _______ Metric :  \n","##### EPOCH 2666 #####\n","train loss :  2922.469970703125\n","test loss :  750.3442993164062  _______ Metric :  \n","##### EPOCH 2667 #####\n","train loss :  2888.509033203125\n","test loss :  750.3433227539062  _______ Metric :  \n","##### EPOCH 2668 #####\n","train loss :  2913.126220703125\n","test loss :  750.3413696289062  _______ Metric :  \n","##### EPOCH 2669 #####\n","train loss :  2903.007080078125\n","test loss :  750.3394165039062  _______ Metric :  \n","##### EPOCH 2670 #####\n","train loss :  2925.497314453125\n","test loss :  750.3281860351562  _______ Metric :  \n","##### EPOCH 2671 #####\n","train loss :  2936.446533203125\n","test loss :  750.3175048828125  _______ Metric :  \n","##### EPOCH 2672 #####\n","train loss :  2942.001220703125\n","test loss :  750.3150634765625  _______ Metric :  \n","##### EPOCH 2673 #####\n","train loss :  2913.684814453125\n","test loss :  750.3082275390625  _______ Metric :  \n","##### EPOCH 2674 #####\n","train loss :  2935.977783203125\n","test loss :  750.3106689453125  _______ Metric :  \n","##### EPOCH 2675 #####\n","train loss :  2940.466064453125\n","test loss :  750.3077392578125  _______ Metric :  \n","##### EPOCH 2676 #####\n","train loss :  2962.737548828125\n","test loss :  750.3033447265625  _______ Metric :  \n","##### EPOCH 2677 #####\n","train loss :  2898.268798828125\n","test loss :  750.3009033203125  _______ Metric :  \n","##### EPOCH 2678 #####\n","train loss :  2943.647705078125\n","test loss :  750.3018798828125  _______ Metric :  \n","##### EPOCH 2679 #####\n","train loss :  2989.520751953125\n","test loss :  750.2989501953125  _______ Metric :  \n","##### EPOCH 2680 #####\n","train loss :  2930.956298828125\n","test loss :  750.3009033203125  _______ Metric :  \n","##### EPOCH 2681 #####\n","train loss :  2938.362548828125\n","test loss :  750.2969970703125  _______ Metric :  \n","##### EPOCH 2682 #####\n","train loss :  2937.520751953125\n","test loss :  750.2921142578125  _______ Metric :  \n","##### EPOCH 2683 #####\n","train loss :  2953.393798828125\n","test loss :  750.2882080078125  _______ Metric :  \n","##### EPOCH 2684 #####\n","train loss :  2924.528564453125\n","test loss :  750.2818603515625  _______ Metric :  \n","##### EPOCH 2685 #####\n","train loss :  2957.298095703125\n","test loss :  750.2750244140625  _______ Metric :  \n","##### EPOCH 2686 #####\n","train loss :  2958.991455078125\n","test loss :  750.2740478515625  _______ Metric :  \n","##### EPOCH 2687 #####\n","train loss :  2961.159423828125\n","test loss :  750.2667846679688  _______ Metric :  \n","##### EPOCH 2688 #####\n","train loss :  2969.911376953125\n","test loss :  750.2570190429688  _______ Metric :  \n","##### EPOCH 2689 #####\n","train loss :  2925.352783203125\n","test loss :  750.2501831054688  _______ Metric :  \n","##### EPOCH 2690 #####\n","train loss :  2967.813720703125\n","test loss :  750.2453002929688  _______ Metric :  \n","##### EPOCH 2691 #####\n","train loss :  2944.360595703125\n","test loss :  750.2326049804688  _______ Metric :  \n","##### EPOCH 2692 #####\n","train loss :  2928.807861328125\n","test loss :  750.2272338867188  _______ Metric :  \n","##### EPOCH 2693 #####\n","train loss :  2943.438720703125\n","test loss :  750.2174682617188  _______ Metric :  \n","##### EPOCH 2694 #####\n","train loss :  2961.979736328125\n","test loss :  750.2111206054688  _______ Metric :  \n","##### EPOCH 2695 #####\n","train loss :  2921.940673828125\n","test loss :  750.2052612304688  _______ Metric :  \n","##### EPOCH 2696 #####\n","train loss :  2953.005126953125\n","test loss :  750.1969604492188  _______ Metric :  \n","##### EPOCH 2697 #####\n","train loss :  2932.981689453125\n","test loss :  750.1818237304688  _______ Metric :  \n","##### EPOCH 2698 #####\n","train loss :  2903.891845703125\n","test loss :  750.1764526367188  _______ Metric :  \n","##### EPOCH 2699 #####\n","train loss :  2966.692626953125\n","test loss :  750.1647338867188  _______ Metric :  \n","##### EPOCH 2700 #####\n","train loss :  2934.452392578125\n","test loss :  750.1657104492188  _______ Metric :  \n","##### EPOCH 2701 #####\n","train loss :  2931.124267578125\n","test loss :  750.1578979492188  _______ Metric :  \n","##### EPOCH 2702 #####\n","train loss :  2905.694580078125\n","test loss :  750.1564331054688  _______ Metric :  \n","##### EPOCH 2703 #####\n","train loss :  2901.329345703125\n","test loss :  750.1622924804688  _______ Metric :  \n","##### EPOCH 2704 #####\n","train loss :  2970.196533203125\n","test loss :  750.1564331054688  _______ Metric :  \n","##### EPOCH 2705 #####\n","train loss :  2927.005126953125\n","test loss :  750.1549682617188  _______ Metric :  \n","##### EPOCH 2706 #####\n","train loss :  2922.524658203125\n","test loss :  750.1515502929688  _______ Metric :  \n","##### EPOCH 2707 #####\n","train loss :  2942.147705078125\n","test loss :  750.1422729492188  _______ Metric :  \n","##### EPOCH 2708 #####\n","train loss :  2943.882080078125\n","test loss :  750.1325073242188  _______ Metric :  \n","##### EPOCH 2709 #####\n","train loss :  2928.598876953125\n","test loss :  750.1188354492188  _______ Metric :  \n","##### EPOCH 2710 #####\n","train loss :  2982.696533203125\n","test loss :  750.1076049804688  _______ Metric :  \n","##### EPOCH 2711 #####\n","train loss :  2941.628173828125\n","test loss :  750.1051635742188  _______ Metric :  \n","##### EPOCH 2712 #####\n","train loss :  2952.698486328125\n","test loss :  750.1007690429688  _______ Metric :  \n","##### EPOCH 2713 #####\n","train loss :  2925.632080078125\n","test loss :  750.0944213867188  _______ Metric :  \n","##### EPOCH 2714 #####\n","train loss :  2969.417236328125\n","test loss :  750.0993041992188  _______ Metric :  \n","##### EPOCH 2715 #####\n","train loss :  2909.782470703125\n","test loss :  750.1056518554688  _______ Metric :  \n","##### EPOCH 2716 #####\n","train loss :  2931.954345703125\n","test loss :  750.1056518554688  _______ Metric :  \n","##### EPOCH 2717 #####\n","train loss :  2942.022705078125\n","test loss :  750.1134643554688  _______ Metric :  \n","##### EPOCH 2718 #####\n","train loss :  2964.009033203125\n","test loss :  750.1119995117188  _______ Metric :  \n","##### EPOCH 2719 #####\n","train loss :  2938.053955078125\n","test loss :  750.1163940429688  _______ Metric :  \n","##### EPOCH 2720 #####\n","train loss :  2922.538330078125\n","test loss :  750.1256713867188  _______ Metric :  \n","##### EPOCH 2721 #####\n","train loss :  2953.573486328125\n","test loss :  750.1232299804688  _______ Metric :  \n","##### EPOCH 2722 #####\n","train loss :  2972.274658203125\n","test loss :  750.1217651367188  _______ Metric :  \n","##### EPOCH 2723 #####\n","train loss :  2934.639892578125\n","test loss :  750.1222534179688  _______ Metric :  \n","##### EPOCH 2724 #####\n","train loss :  2994.872314453125\n","test loss :  750.1198120117188  _______ Metric :  \n","##### EPOCH 2725 #####\n","train loss :  2943.227783203125\n","test loss :  750.1212768554688  _______ Metric :  \n","##### EPOCH 2726 #####\n","train loss :  2925.825439453125\n","test loss :  750.1178588867188  _______ Metric :  \n","##### EPOCH 2727 #####\n","train loss :  2935.587158203125\n","test loss :  750.1163940429688  _______ Metric :  \n","##### EPOCH 2728 #####\n","train loss :  2951.688720703125\n","test loss :  750.1168823242188  _______ Metric :  \n","##### EPOCH 2729 #####\n","train loss :  2921.630126953125\n","test loss :  750.104248046875  _______ Metric :  \n","##### EPOCH 2730 #####\n","train loss :  2939.372314453125\n","test loss :  750.097412109375  _______ Metric :  \n","##### EPOCH 2731 #####\n","train loss :  2948.497314453125\n","test loss :  750.090087890625  _______ Metric :  \n","##### EPOCH 2732 #####\n","train loss :  2923.360595703125\n","test loss :  750.082763671875  _______ Metric :  \n","##### EPOCH 2733 #####\n","train loss :  2914.930908203125\n","test loss :  750.083251953125  _______ Metric :  \n","##### EPOCH 2734 #####\n","train loss :  2938.577392578125\n","test loss :  750.081298828125  _______ Metric :  \n","##### EPOCH 2735 #####\n","train loss :  2950.233642578125\n","test loss :  750.076416015625  _______ Metric :  \n","##### EPOCH 2736 #####\n","train loss :  2962.137939453125\n","test loss :  750.070556640625  _______ Metric :  \n","##### EPOCH 2737 #####\n","train loss :  2936.757080078125\n","test loss :  750.067626953125  _______ Metric :  \n","##### EPOCH 2738 #####\n","train loss :  2949.147705078125\n","test loss :  750.070556640625  _______ Metric :  \n","##### EPOCH 2739 #####\n","train loss :  2989.434814453125\n","test loss :  750.071533203125  _______ Metric :  \n","##### EPOCH 2740 #####\n","train loss :  2962.069580078125\n","test loss :  750.083740234375  _______ Metric :  \n","##### EPOCH 2741 #####\n","train loss :  2961.602783203125\n","test loss :  750.089599609375  _______ Metric :  \n","##### EPOCH 2742 #####\n","train loss :  2911.501220703125\n","test loss :  750.093994140625  _______ Metric :  \n","##### EPOCH 2743 #####\n","train loss :  2955.270751953125\n","test loss :  750.100341796875  _______ Metric :  \n","##### EPOCH 2744 #####\n","train loss :  2931.122314453125\n","test loss :  750.106201171875  _______ Metric :  \n","##### EPOCH 2745 #####\n","train loss :  2950.454345703125\n","test loss :  750.111572265625  _______ Metric :  \n","##### EPOCH 2746 #####\n","train loss :  2968.870361328125\n","test loss :  750.123291015625  _______ Metric :  \n","##### EPOCH 2747 #####\n","train loss :  2920.219970703125\n","test loss :  750.125732421875  _______ Metric :  \n","##### EPOCH 2748 #####\n","train loss :  2948.805908203125\n","test loss :  750.123291015625  _______ Metric :  \n","##### EPOCH 2749 #####\n","train loss :  2954.173095703125\n","test loss :  750.119873046875  _______ Metric :  \n","##### EPOCH 2750 #####\n","train loss :  2920.614501953125\n","test loss :  750.122314453125  _______ Metric :  \n","##### EPOCH 2751 #####\n","train loss :  2946.778564453125\n","test loss :  750.130126953125  _______ Metric :  \n","##### EPOCH 2752 #####\n","train loss :  2940.284423828125\n","test loss :  750.133544921875  _______ Metric :  \n","##### EPOCH 2753 #####\n","train loss :  2940.802001953125\n","test loss :  750.138916015625  _______ Metric :  \n","##### EPOCH 2754 #####\n","train loss :  2949.241455078125\n","test loss :  750.137451171875  _______ Metric :  \n","##### EPOCH 2755 #####\n","train loss :  2927.403564453125\n","test loss :  750.132568359375  _______ Metric :  \n","##### EPOCH 2756 #####\n","train loss :  2915.057861328125\n","test loss :  750.132080078125  _______ Metric :  \n","##### EPOCH 2757 #####\n","train loss :  2945.124267578125\n","test loss :  750.129150390625  _______ Metric :  \n","##### EPOCH 2758 #####\n","train loss :  2950.528564453125\n","test loss :  750.138427734375  _______ Metric :  \n","##### EPOCH 2759 #####\n","train loss :  2922.735595703125\n","test loss :  750.137451171875  _______ Metric :  \n","##### EPOCH 2760 #####\n","train loss :  2946.323486328125\n","test loss :  750.138916015625  _______ Metric :  \n","##### EPOCH 2761 #####\n","train loss :  2946.218017578125\n","test loss :  750.138916015625  _______ Metric :  \n","##### EPOCH 2762 #####\n","train loss :  2990.677001953125\n","test loss :  750.131591796875  _______ Metric :  \n","##### EPOCH 2763 #####\n","train loss :  2945.432861328125\n","test loss :  750.120849609375  _______ Metric :  \n","##### EPOCH 2764 #####\n","train loss :  2959.292236328125\n","test loss :  750.117919921875  _______ Metric :  \n","##### EPOCH 2765 #####\n","train loss :  2945.969970703125\n","test loss :  750.118408203125  _______ Metric :  \n","##### EPOCH 2766 #####\n","train loss :  2914.774658203125\n","test loss :  750.112060546875  _______ Metric :  \n","##### EPOCH 2767 #####\n","train loss :  2963.928955078125\n","test loss :  750.114013671875  _______ Metric :  \n","##### EPOCH 2768 #####\n","train loss :  2921.370361328125\n","test loss :  750.108642578125  _______ Metric :  \n","##### EPOCH 2769 #####\n","train loss :  2938.059814453125\n","test loss :  750.109619140625  _______ Metric :  \n","##### EPOCH 2770 #####\n","train loss :  2948.866455078125\n","test loss :  750.109130859375  _______ Metric :  \n","##### EPOCH 2771 #####\n","train loss :  2954.678955078125\n","test loss :  750.101318359375  _______ Metric :  \n","##### EPOCH 2772 #####\n","train loss :  2931.975830078125\n","test loss :  750.095947265625  _______ Metric :  \n","##### EPOCH 2773 #####\n","train loss :  2899.428955078125\n","test loss :  750.093505859375  _______ Metric :  \n","##### EPOCH 2774 #####\n","train loss :  2937.325439453125\n","test loss :  750.093994140625  _______ Metric :  \n","##### EPOCH 2775 #####\n","train loss :  2952.249267578125\n","test loss :  750.094482421875  _______ Metric :  \n","##### EPOCH 2776 #####\n","train loss :  2937.473876953125\n","test loss :  750.092529296875  _______ Metric :  \n","##### EPOCH 2777 #####\n","train loss :  2927.768798828125\n","test loss :  750.094482421875  _______ Metric :  \n","##### EPOCH 2778 #####\n","train loss :  2939.858642578125\n","test loss :  750.092529296875  _______ Metric :  \n","##### EPOCH 2779 #####\n","train loss :  2923.061767578125\n","test loss :  750.096923828125  _______ Metric :  \n","##### EPOCH 2780 #####\n","train loss :  2928.098876953125\n","test loss :  750.094970703125  _______ Metric :  \n","##### EPOCH 2781 #####\n","train loss :  2895.841064453125\n","test loss :  750.089111328125  _______ Metric :  \n","##### EPOCH 2782 #####\n","train loss :  2938.585205078125\n","test loss :  750.091064453125  _______ Metric :  \n","##### EPOCH 2783 #####\n","train loss :  2928.885986328125\n","test loss :  750.090576171875  _______ Metric :  \n","##### EPOCH 2784 #####\n","train loss :  2889.921142578125\n","test loss :  750.101318359375  _______ Metric :  \n","##### EPOCH 2785 #####\n","train loss :  2930.385986328125\n","test loss :  750.102783203125  _______ Metric :  \n","##### EPOCH 2786 #####\n","train loss :  2966.989501953125\n","test loss :  750.109130859375  _______ Metric :  \n","##### EPOCH 2787 #####\n","train loss :  2902.809814453125\n","test loss :  750.108154296875  _______ Metric :  \n","##### EPOCH 2788 #####\n","train loss :  2917.721923828125\n","test loss :  750.101806640625  _______ Metric :  \n","##### EPOCH 2789 #####\n","train loss :  2947.407470703125\n","test loss :  750.096923828125  _______ Metric :  \n","##### EPOCH 2790 #####\n","train loss :  2943.682861328125\n","test loss :  750.094482421875  _______ Metric :  \n","##### EPOCH 2791 #####\n","train loss :  2934.005126953125\n","test loss :  750.090576171875  _______ Metric :  \n","##### EPOCH 2792 #####\n","train loss :  2918.145751953125\n","test loss :  750.094970703125  _______ Metric :  \n","##### EPOCH 2793 #####\n","train loss :  2924.643798828125\n","test loss :  750.100341796875  _______ Metric :  \n","##### EPOCH 2794 #####\n","train loss :  2934.489501953125\n","test loss :  750.105712890625  _______ Metric :  \n","##### EPOCH 2795 #####\n","train loss :  2954.534423828125\n","test loss :  750.100341796875  _______ Metric :  \n","##### EPOCH 2796 #####\n","train loss :  2911.440673828125\n","test loss :  750.101806640625  _______ Metric :  \n","##### EPOCH 2797 #####\n","train loss :  2953.262939453125\n","test loss :  750.121337890625  _______ Metric :  \n","##### EPOCH 2798 #####\n","train loss :  2901.331298828125\n","test loss :  750.127197265625  _______ Metric :  \n","##### EPOCH 2799 #####\n","train loss :  2940.659423828125\n","test loss :  750.128173828125  _______ Metric :  \n","##### EPOCH 2800 #####\n","train loss :  2950.876220703125\n","test loss :  750.129150390625  _______ Metric :  \n","##### EPOCH 2801 #####\n","train loss :  2889.329345703125\n","test loss :  750.135009765625  _______ Metric :  \n","##### EPOCH 2802 #####\n","train loss :  2921.403564453125\n","test loss :  750.134521484375  _______ Metric :  \n","##### EPOCH 2803 #####\n","train loss :  2932.108642578125\n","test loss :  750.125732421875  _______ Metric :  \n","##### EPOCH 2804 #####\n","train loss :  2961.177001953125\n","test loss :  750.121337890625  _______ Metric :  \n","##### EPOCH 2805 #####\n","train loss :  2944.206298828125\n","test loss :  750.112548828125  _______ Metric :  \n","##### EPOCH 2806 #####\n","train loss :  2936.169189453125\n","test loss :  750.114990234375  _______ Metric :  \n","##### EPOCH 2807 #####\n","train loss :  2946.909423828125\n","test loss :  750.106689453125  _______ Metric :  \n","##### EPOCH 2808 #####\n","train loss :  2929.518798828125\n","test loss :  750.100341796875  _______ Metric :  \n","##### EPOCH 2809 #####\n","train loss :  2954.563720703125\n","test loss :  750.086181640625  _______ Metric :  \n","##### EPOCH 2810 #####\n","train loss :  2937.370361328125\n","test loss :  750.075927734375  _______ Metric :  \n","##### EPOCH 2811 #####\n","train loss :  2951.059814453125\n","test loss :  750.068115234375  _______ Metric :  \n","##### EPOCH 2812 #####\n","train loss :  2969.106689453125\n","test loss :  750.057373046875  _______ Metric :  \n","##### EPOCH 2813 #####\n","train loss :  2940.264892578125\n","test loss :  750.050537109375  _______ Metric :  \n","##### EPOCH 2814 #####\n","train loss :  2931.354736328125\n","test loss :  750.047119140625  _______ Metric :  \n","##### EPOCH 2815 #####\n","train loss :  2988.468017578125\n","test loss :  750.042724609375  _______ Metric :  \n","##### EPOCH 2816 #####\n","train loss :  2938.186767578125\n","test loss :  750.043212890625  _______ Metric :  \n","##### EPOCH 2817 #####\n","train loss :  2963.585205078125\n","test loss :  750.037353515625  _______ Metric :  \n","##### EPOCH 2818 #####\n","train loss :  2934.167236328125\n","test loss :  750.034912109375  _______ Metric :  \n","##### EPOCH 2819 #####\n","train loss :  2894.221923828125\n","test loss :  750.031494140625  _______ Metric :  \n","##### EPOCH 2820 #####\n","train loss :  2902.407470703125\n","test loss :  750.032470703125  _______ Metric :  \n","##### EPOCH 2821 #####\n","train loss :  2934.524658203125\n","test loss :  750.031494140625  _______ Metric :  \n","##### EPOCH 2822 #####\n","train loss :  2931.604736328125\n","test loss :  750.036376953125  _______ Metric :  \n","##### EPOCH 2823 #####\n","train loss :  2922.800048828125\n","test loss :  750.043701171875  _______ Metric :  \n","##### EPOCH 2824 #####\n","train loss :  2946.665283203125\n","test loss :  750.046142578125  _______ Metric :  \n","##### EPOCH 2825 #####\n","train loss :  2950.835205078125\n","test loss :  750.051513671875  _______ Metric :  \n","##### EPOCH 2826 #####\n","train loss :  2947.579345703125\n","test loss :  750.053466796875  _______ Metric :  \n","##### EPOCH 2827 #####\n","train loss :  2947.579345703125\n","test loss :  750.055908203125  _______ Metric :  \n","##### EPOCH 2828 #####\n","train loss :  2919.001220703125\n","test loss :  750.067626953125  _______ Metric :  \n","##### EPOCH 2829 #####\n","train loss :  2941.735595703125\n","test loss :  750.072021484375  _______ Metric :  \n","##### EPOCH 2830 #####\n","train loss :  2932.001220703125\n","test loss :  750.072021484375  _______ Metric :  \n","##### EPOCH 2831 #####\n","train loss :  2965.856689453125\n","test loss :  750.065185546875  _______ Metric :  \n","##### EPOCH 2832 #####\n","train loss :  2977.059814453125\n","test loss :  750.066162109375  _______ Metric :  \n","##### EPOCH 2833 #####\n","train loss :  2961.223876953125\n","test loss :  750.059814453125  _______ Metric :  \n","##### EPOCH 2834 #####\n","train loss :  2949.649658203125\n","test loss :  750.052490234375  _______ Metric :  \n","##### EPOCH 2835 #####\n","train loss :  2918.032470703125\n","test loss :  750.047607421875  _______ Metric :  \n","##### EPOCH 2836 #####\n","train loss :  2926.692626953125\n","test loss :  750.044677734375  _______ Metric :  \n","##### EPOCH 2837 #####\n","train loss :  2943.925048828125\n","test loss :  750.036376953125  _______ Metric :  \n","##### EPOCH 2838 #####\n","train loss :  2963.581298828125\n","test loss :  750.034423828125  _______ Metric :  \n","##### EPOCH 2839 #####\n","train loss :  2938.157470703125\n","test loss :  750.033447265625  _______ Metric :  \n","##### EPOCH 2840 #####\n","train loss :  2926.555908203125\n","test loss :  750.034912109375  _______ Metric :  \n","##### EPOCH 2841 #####\n","train loss :  2967.786376953125\n","test loss :  750.040771484375  _______ Metric :  \n","##### EPOCH 2842 #####\n","train loss :  2933.077392578125\n","test loss :  750.043212890625  _______ Metric :  \n","##### EPOCH 2843 #####\n","train loss :  2946.784423828125\n","test loss :  750.036865234375  _______ Metric :  \n","##### EPOCH 2844 #####\n","train loss :  2916.546142578125\n","test loss :  750.035400390625  _______ Metric :  \n","##### EPOCH 2845 #####\n","train loss :  2933.311767578125\n","test loss :  750.037353515625  _______ Metric :  \n","##### EPOCH 2846 #####\n","train loss :  2903.475830078125\n","test loss :  750.032958984375  _______ Metric :  \n","##### EPOCH 2847 #####\n","train loss :  2937.253173828125\n","test loss :  750.027587890625  _______ Metric :  \n","##### EPOCH 2848 #####\n","train loss :  2935.637939453125\n","test loss :  750.022216796875  _______ Metric :  \n","##### EPOCH 2849 #####\n","train loss :  2935.927001953125\n","test loss :  750.012939453125  _______ Metric :  \n","##### EPOCH 2850 #####\n","train loss :  2964.186767578125\n","test loss :  750.0120239257812  _______ Metric :  \n","##### EPOCH 2851 #####\n","train loss :  2939.544189453125\n","test loss :  750.0173950195312  _______ Metric :  \n","##### EPOCH 2852 #####\n","train loss :  2970.893798828125\n","test loss :  750.0095825195312  _______ Metric :  \n","##### EPOCH 2853 #####\n","train loss :  2928.878173828125\n","test loss :  750.0115356445312  _______ Metric :  \n","##### EPOCH 2854 #####\n","train loss :  2955.885986328125\n","test loss :  750.0134887695312  _______ Metric :  \n","##### EPOCH 2855 #####\n","train loss :  2930.932861328125\n","test loss :  750.0076293945312  _______ Metric :  \n","##### EPOCH 2856 #####\n","train loss :  2936.862548828125\n","test loss :  750.0051879882812  _______ Metric :  \n","##### EPOCH 2857 #####\n","train loss :  2921.462158203125\n","test loss :  750.0042114257812  _______ Metric :  \n","##### EPOCH 2858 #####\n","train loss :  2958.710205078125\n","test loss :  749.9968872070312  _______ Metric :  \n","##### EPOCH 2859 #####\n","train loss :  2940.415283203125\n","test loss :  749.9954223632812  _______ Metric :  \n","##### EPOCH 2860 #####\n","train loss :  2939.956298828125\n","test loss :  749.9983520507812  _______ Metric :  \n","##### EPOCH 2861 #####\n","train loss :  2894.721923828125\n","test loss :  749.9934692382812  _______ Metric :  \n","##### EPOCH 2862 #####\n","train loss :  2921.751220703125\n","test loss :  749.9920043945312  _______ Metric :  \n","##### EPOCH 2863 #####\n","train loss :  2933.643798828125\n","test loss :  749.9880981445312  _______ Metric :  \n","##### EPOCH 2864 #####\n","train loss :  2905.102783203125\n","test loss :  749.9890747070312  _______ Metric :  \n","##### EPOCH 2865 #####\n","train loss :  2958.598876953125\n","test loss :  749.9876098632812  _______ Metric :  \n","##### EPOCH 2866 #####\n","train loss :  2916.704345703125\n","test loss :  749.9920043945312  _______ Metric :  \n","##### EPOCH 2867 #####\n","train loss :  2957.823486328125\n","test loss :  749.9983520507812  _______ Metric :  \n","##### EPOCH 2868 #####\n","train loss :  2897.08349609375\n","test loss :  750.0027465820312  _______ Metric :  \n","##### EPOCH 2869 #####\n","train loss :  2951.16357421875\n","test loss :  750.0027465820312  _______ Metric :  \n","##### EPOCH 2870 #####\n","train loss :  2928.17333984375\n","test loss :  750.0105590820312  _______ Metric :  \n","##### EPOCH 2871 #####\n","train loss :  2952.51708984375\n","test loss :  750.0154418945312  _______ Metric :  \n","##### EPOCH 2872 #####\n","train loss :  2955.98193359375\n","test loss :  750.0173950195312  _______ Metric :  \n","##### EPOCH 2873 #####\n","train loss :  2945.58544921875\n","test loss :  750.0164184570312  _______ Metric :  \n","##### EPOCH 2874 #####\n","train loss :  2952.13037109375\n","test loss :  750.0120239257812  _______ Metric :  \n","##### EPOCH 2875 #####\n","train loss :  2920.18115234375\n","test loss :  749.9924926757812  _______ Metric :  \n","##### EPOCH 2876 #####\n","train loss :  2925.81201171875\n","test loss :  749.9915161132812  _______ Metric :  \n","##### EPOCH 2877 #####\n","train loss :  2942.19677734375\n","test loss :  749.9880981445312  _______ Metric :  \n","##### EPOCH 2878 #####\n","train loss :  2932.59912109375\n","test loss :  749.9807739257812  _______ Metric :  \n","##### EPOCH 2879 #####\n","train loss :  2905.82958984375\n","test loss :  749.9783325195312  _______ Metric :  \n","##### EPOCH 2880 #####\n","train loss :  2950.96044921875\n","test loss :  749.9832153320312  _______ Metric :  \n","##### EPOCH 2881 #####\n","train loss :  2923.48193359375\n","test loss :  749.9739379882812  _______ Metric :  \n","##### EPOCH 2882 #####\n","train loss :  2973.15966796875\n","test loss :  749.9714965820312  _______ Metric :  \n","##### EPOCH 2883 #####\n","train loss :  2938.91943359375\n","test loss :  749.9631958007812  _______ Metric :  \n","##### EPOCH 2884 #####\n","train loss :  2880.34326171875\n","test loss :  749.9661254882812  _______ Metric :  \n","##### EPOCH 2885 #####\n","train loss :  2939.35107421875\n","test loss :  749.9656372070312  _______ Metric :  \n","##### EPOCH 2886 #####\n","train loss :  2971.28662109375\n","test loss :  749.9622192382812  _______ Metric :  \n","##### EPOCH 2887 #####\n","train loss :  2917.96240234375\n","test loss :  749.9544067382812  _______ Metric :  \n","##### EPOCH 2888 #####\n","train loss :  2945.83154296875\n","test loss :  749.9500122070312  _______ Metric :  \n","##### EPOCH 2889 #####\n","train loss :  2944.05224609375\n","test loss :  749.9402465820312  _______ Metric :  \n","##### EPOCH 2890 #####\n","train loss :  2921.77099609375\n","test loss :  749.9319458007812  _______ Metric :  \n","##### EPOCH 2891 #####\n","train loss :  2997.82568359375\n","test loss :  749.9221801757812  _______ Metric :  \n","##### EPOCH 2892 #####\n","train loss :  2923.50537109375\n","test loss :  749.9158325195312  _______ Metric :  \n","##### EPOCH 2893 #####\n","train loss :  2932.95654296875\n","test loss :  749.9085083007812  _______ Metric :  \n","##### EPOCH 2894 #####\n","train loss :  2982.48583984375\n","test loss :  749.9089965820312  _______ Metric :  \n","##### EPOCH 2895 #####\n","train loss :  2954.95068359375\n","test loss :  749.9026489257812  _______ Metric :  \n","##### EPOCH 2896 #####\n","train loss :  2948.06982421875\n","test loss :  749.8992309570312  _______ Metric :  \n","##### EPOCH 2897 #####\n","train loss :  2929.45458984375\n","test loss :  749.8992309570312  _______ Metric :  \n","##### EPOCH 2898 #####\n","train loss :  2927.35693359375\n","test loss :  749.9002075195312  _______ Metric :  \n","##### EPOCH 2899 #####\n","train loss :  2943.69091796875\n","test loss :  749.8943481445312  _______ Metric :  \n","##### EPOCH 2900 #####\n","train loss :  2990.31982421875\n","test loss :  749.8938598632812  _______ Metric :  \n","##### EPOCH 2901 #####\n","train loss :  2913.73583984375\n","test loss :  749.8914184570312  _______ Metric :  \n","##### EPOCH 2902 #####\n","train loss :  2935.41748046875\n","test loss :  749.8860473632812  _______ Metric :  \n","##### EPOCH 2903 #####\n","train loss :  2942.59326171875\n","test loss :  749.8787231445312  _______ Metric :  \n","##### EPOCH 2904 #####\n","train loss :  2992.22216796875\n","test loss :  749.8831176757812  _______ Metric :  \n","##### EPOCH 2905 #####\n","train loss :  2949.25927734375\n","test loss :  749.8718872070312  _______ Metric :  \n","##### EPOCH 2906 #####\n","train loss :  2930.57568359375\n","test loss :  749.8650512695312  _______ Metric :  \n","##### EPOCH 2907 #####\n","train loss :  2904.45849609375\n","test loss :  749.8655395507812  _______ Metric :  \n","##### EPOCH 2908 #####\n","train loss :  2932.96435546875\n","test loss :  749.8611450195312  _______ Metric :  \n","##### EPOCH 2909 #####\n","train loss :  2905.28857421875\n","test loss :  749.8552856445312  _______ Metric :  \n","##### EPOCH 2910 #####\n","train loss :  2951.91552734375\n","test loss :  749.8557739257812  _______ Metric :  \n","##### EPOCH 2911 #####\n","train loss :  2935.73583984375\n","test loss :  749.8557739257812  _______ Metric :  \n","##### EPOCH 2912 #####\n","train loss :  2948.64404296875\n","test loss :  749.8508911132812  _______ Metric :  \n","##### EPOCH 2913 #####\n","train loss :  2926.78662109375\n","test loss :  749.8440551757812  _______ Metric :  \n","##### EPOCH 2914 #####\n","train loss :  2954.12255859375\n","test loss :  749.8338012695312  _______ Metric :  \n","##### EPOCH 2915 #####\n","train loss :  2942.01904296875\n","test loss :  749.8220825195312  _______ Metric :  \n","##### EPOCH 2916 #####\n","train loss :  2931.04833984375\n","test loss :  749.8176879882812  _______ Metric :  \n","##### EPOCH 2917 #####\n","train loss :  2917.57177734375\n","test loss :  749.8113403320312  _______ Metric :  \n","##### EPOCH 2918 #####\n","train loss :  2923.96826171875\n","test loss :  749.8035278320312  _______ Metric :  \n","##### EPOCH 2919 #####\n","train loss :  2951.69091796875\n","test loss :  749.7971801757812  _______ Metric :  \n","##### EPOCH 2920 #####\n","train loss :  2970.17138671875\n","test loss :  749.7913208007812  _______ Metric :  \n","##### EPOCH 2921 #####\n","train loss :  2947.30224609375\n","test loss :  749.7932739257812  _______ Metric :  \n","##### EPOCH 2922 #####\n","train loss :  2899.64404296875\n","test loss :  749.7918090820312  _______ Metric :  \n","##### EPOCH 2923 #####\n","train loss :  2884.27880859375\n","test loss :  749.7918090820312  _______ Metric :  \n","##### EPOCH 2924 #####\n","train loss :  2961.60498046875\n","test loss :  749.7986450195312  _______ Metric :  \n","##### EPOCH 2925 #####\n","train loss :  2952.06982421875\n","test loss :  749.7996215820312  _______ Metric :  \n","##### EPOCH 2926 #####\n","train loss :  2966.73193359375\n","test loss :  749.8030395507812  _______ Metric :  \n","##### EPOCH 2927 #####\n","train loss :  2960.73388671875\n","test loss :  749.8054809570312  _______ Metric :  \n","##### EPOCH 2928 #####\n","train loss :  2921.45458984375\n","test loss :  749.8001098632812  _______ Metric :  \n","##### EPOCH 2929 #####\n","train loss :  2958.11474609375\n","test loss :  749.7981567382812  _______ Metric :  \n","##### EPOCH 2930 #####\n","train loss :  2937.65185546875\n","test loss :  749.7991333007812  _______ Metric :  \n","##### EPOCH 2931 #####\n","train loss :  2945.50732421875\n","test loss :  749.7918090820312  _______ Metric :  \n","##### EPOCH 2932 #####\n","train loss :  2917.55810546875\n","test loss :  749.7932739257812  _______ Metric :  \n","##### EPOCH 2933 #####\n","train loss :  2905.85107421875\n","test loss :  749.7957153320312  _______ Metric :  \n","##### EPOCH 2934 #####\n","train loss :  2939.85498046875\n","test loss :  749.7893676757812  _______ Metric :  \n","##### EPOCH 2935 #####\n","train loss :  2947.70263671875\n","test loss :  749.7825317382812  _______ Metric :  \n","##### EPOCH 2936 #####\n","train loss :  2965.00537109375\n","test loss :  749.7815551757812  _______ Metric :  \n","##### EPOCH 2937 #####\n","train loss :  2914.07373046875\n","test loss :  749.7766723632812  _______ Metric :  \n","##### EPOCH 2938 #####\n","train loss :  2903.39990234375\n","test loss :  749.7649536132812  _______ Metric :  \n","##### EPOCH 2939 #####\n","train loss :  2934.44091796875\n","test loss :  749.7571411132812  _______ Metric :  \n","##### EPOCH 2940 #####\n","train loss :  2923.20263671875\n","test loss :  749.7532348632812  _______ Metric :  \n","##### EPOCH 2941 #####\n","train loss :  2898.84326171875\n","test loss :  749.7473754882812  _______ Metric :  \n","##### EPOCH 2942 #####\n","train loss :  2936.70458984375\n","test loss :  749.7473754882812  _______ Metric :  \n","##### EPOCH 2943 #####\n","train loss :  2973.96240234375\n","test loss :  749.7503051757812  _______ Metric :  \n","##### EPOCH 2944 #####\n","train loss :  2974.69482421875\n","test loss :  749.7512817382812  _______ Metric :  \n","##### EPOCH 2945 #####\n","train loss :  2950.54833984375\n","test loss :  749.7532348632812  _______ Metric :  \n","##### EPOCH 2946 #####\n","train loss :  2954.25927734375\n","test loss :  749.7537231445312  _______ Metric :  \n","##### EPOCH 2947 #####\n","train loss :  2930.60107421875\n","test loss :  749.7542114257812  _______ Metric :  \n","##### EPOCH 2948 #####\n","train loss :  2957.35107421875\n","test loss :  749.7600708007812  _______ Metric :  \n","##### EPOCH 2949 #####\n","train loss :  2939.16943359375\n","test loss :  749.7669067382812  _______ Metric :  \n","##### EPOCH 2950 #####\n","train loss :  2970.53076171875\n","test loss :  749.7756958007812  _______ Metric :  \n","##### EPOCH 2951 #####\n","train loss :  2953.09912109375\n","test loss :  749.7791137695312  _______ Metric :  \n","##### EPOCH 2952 #####\n","train loss :  2921.66162109375\n","test loss :  749.7811279296875  _______ Metric :  \n","##### EPOCH 2953 #####\n","train loss :  2953.89794921875\n","test loss :  749.7742919921875  _______ Metric :  \n","##### EPOCH 2954 #####\n","train loss :  2905.21044921875\n","test loss :  749.7694091796875  _______ Metric :  \n","##### EPOCH 2955 #####\n","train loss :  2926.98583984375\n","test loss :  749.7703857421875  _______ Metric :  \n","##### EPOCH 2956 #####\n","train loss :  2935.25732421875\n","test loss :  749.7742919921875  _______ Metric :  \n","##### EPOCH 2957 #####\n","train loss :  2940.28662109375\n","test loss :  749.7684326171875  _______ Metric :  \n","##### EPOCH 2958 #####\n","train loss :  2948.59130859375\n","test loss :  749.7645263671875  _______ Metric :  \n","##### EPOCH 2959 #####\n","train loss :  2921.45849609375\n","test loss :  749.7611083984375  _______ Metric :  \n","##### EPOCH 2960 #####\n","train loss :  2941.55810546875\n","test loss :  749.7572021484375  _______ Metric :  \n","##### EPOCH 2961 #####\n","train loss :  2895.44482421875\n","test loss :  749.7576904296875  _______ Metric :  \n","##### EPOCH 2962 #####\n","train loss :  2938.39990234375\n","test loss :  749.7606201171875  _______ Metric :  \n","##### EPOCH 2963 #####\n","train loss :  2944.32568359375\n","test loss :  749.7596435546875  _______ Metric :  \n","##### EPOCH 2964 #####\n","train loss :  2898.63037109375\n","test loss :  749.7615966796875  _______ Metric :  \n","##### EPOCH 2965 #####\n","train loss :  2947.02685546875\n","test loss :  749.7625732421875  _______ Metric :  \n","##### EPOCH 2966 #####\n","train loss :  2896.12841796875\n","test loss :  749.7679443359375  _______ Metric :  \n","##### EPOCH 2967 #####\n","train loss :  2927.38037109375\n","test loss :  749.7586669921875  _______ Metric :  \n","##### EPOCH 2968 #####\n","train loss :  2939.17919921875\n","test loss :  749.7537841796875  _______ Metric :  \n","##### EPOCH 2969 #####\n","train loss :  2942.44287109375\n","test loss :  749.7454833984375  _______ Metric :  \n","##### EPOCH 2970 #####\n","train loss :  2917.08544921875\n","test loss :  749.7430419921875  _______ Metric :  \n","##### EPOCH 2971 #####\n","train loss :  2918.48974609375\n","test loss :  749.7371826171875  _______ Metric :  \n","##### EPOCH 2972 #####\n","train loss :  2996.48193359375\n","test loss :  749.7205810546875  _______ Metric :  \n","##### EPOCH 2973 #####\n","train loss :  2927.99169921875\n","test loss :  749.7200927734375  _______ Metric :  \n","##### EPOCH 2974 #####\n","train loss :  2936.99365234375\n","test loss :  749.7220458984375  _______ Metric :  \n","##### EPOCH 2975 #####\n","train loss :  2915.75341796875\n","test loss :  749.7152099609375  _______ Metric :  \n","##### EPOCH 2976 #####\n","train loss :  2954.44873046875\n","test loss :  749.7161865234375  _______ Metric :  \n","##### EPOCH 2977 #####\n","train loss :  2940.77685546875\n","test loss :  749.7137451171875  _______ Metric :  \n","##### EPOCH 2978 #####\n","train loss :  2951.09521484375\n","test loss :  749.7073974609375  _______ Metric :  \n","##### EPOCH 2979 #####\n","train loss :  2962.34912109375\n","test loss :  749.6898193359375  _______ Metric :  \n","##### EPOCH 2980 #####\n","train loss :  2952.38818359375\n","test loss :  749.6810302734375  _______ Metric :  \n","##### EPOCH 2981 #####\n","train loss :  2937.49755859375\n","test loss :  749.6702880859375  _______ Metric :  \n","##### EPOCH 2982 #####\n","train loss :  2937.09716796875\n","test loss :  749.6629638671875  _______ Metric :  \n","##### EPOCH 2983 #####\n","train loss :  2948.43896484375\n","test loss :  749.6497802734375  _______ Metric :  \n","##### EPOCH 2984 #####\n","train loss :  2928.09716796875\n","test loss :  749.6375732421875  _______ Metric :  \n","##### EPOCH 2985 #####\n","train loss :  2973.46826171875\n","test loss :  749.6258544921875  _______ Metric :  \n","##### EPOCH 2986 #####\n","train loss :  2915.82763671875\n","test loss :  749.6234130859375  _______ Metric :  \n","##### EPOCH 2987 #####\n","train loss :  2926.82568359375\n","test loss :  749.6146240234375  _______ Metric :  \n","##### EPOCH 2988 #####\n","train loss :  2929.30224609375\n","test loss :  749.6058349609375  _______ Metric :  \n","##### EPOCH 2989 #####\n","train loss :  2911.34912109375\n","test loss :  749.5921630859375  _______ Metric :  \n","##### EPOCH 2990 #####\n","train loss :  2939.83349609375\n","test loss :  749.5833740234375  _______ Metric :  \n","##### EPOCH 2991 #####\n","train loss :  2939.52294921875\n","test loss :  749.5799560546875  _______ Metric :  \n","##### EPOCH 2992 #####\n","train loss :  2894.00732421875\n","test loss :  749.5814208984375  _______ Metric :  \n","##### EPOCH 2993 #####\n","train loss :  2912.71240234375\n","test loss :  749.5750732421875  _______ Metric :  \n","##### EPOCH 2994 #####\n","train loss :  2961.16162109375\n","test loss :  749.5662841796875  _______ Metric :  \n","##### EPOCH 2995 #####\n","train loss :  2909.74169921875\n","test loss :  749.5643310546875  _______ Metric :  \n","##### EPOCH 2996 #####\n","train loss :  2954.92529296875\n","test loss :  749.5648193359375  _______ Metric :  \n","##### EPOCH 2997 #####\n","train loss :  2917.88427734375\n","test loss :  749.5609130859375  _______ Metric :  \n","##### EPOCH 2998 #####\n","train loss :  2949.71630859375\n","test loss :  749.5614013671875  _______ Metric :  \n","##### EPOCH 2999 #####\n","train loss :  2919.20654296875\n","test loss :  749.5599365234375  _______ Metric :  \n","##### EPOCH 3000 #####\n","train loss :  2929.12451171875\n","test loss :  749.5531005859375  _______ Metric :  \n","##### EPOCH 3001 #####\n","train loss :  2918.56201171875\n","test loss :  749.5487060546875  _______ Metric :  \n","##### EPOCH 3002 #####\n","train loss :  2950.70849609375\n","test loss :  749.5482177734375  _______ Metric :  \n","##### EPOCH 3003 #####\n","train loss :  2938.15576171875\n","test loss :  749.5496826171875  _______ Metric :  \n","##### EPOCH 3004 #####\n","train loss :  2921.60107421875\n","test loss :  749.5540771484375  _______ Metric :  \n","##### EPOCH 3005 #####\n","train loss :  2912.75341796875\n","test loss :  749.5638427734375  _______ Metric :  \n","##### EPOCH 3006 #####\n","train loss :  2939.27294921875\n","test loss :  749.5706787109375  _______ Metric :  \n","##### EPOCH 3007 #####\n","train loss :  2966.74560546875\n","test loss :  749.5740966796875  _______ Metric :  \n","##### EPOCH 3008 #####\n","train loss :  2906.81201171875\n","test loss :  749.5775146484375  _______ Metric :  \n","##### EPOCH 3009 #####\n","train loss :  2933.33544921875\n","test loss :  749.5838623046875  _______ Metric :  \n","##### EPOCH 3010 #####\n","train loss :  2947.03466796875\n","test loss :  749.5877685546875  _______ Metric :  \n","##### EPOCH 3011 #####\n","train loss :  2951.09521484375\n","test loss :  749.5950927734375  _______ Metric :  \n","##### EPOCH 3012 #####\n","train loss :  2860.82958984375\n","test loss :  749.6077880859375  _______ Metric :  \n","##### EPOCH 3013 #####\n","train loss :  2931.71240234375\n","test loss :  749.6146240234375  _______ Metric :  \n","##### EPOCH 3014 #####\n","train loss :  2892.16162109375\n","test loss :  749.6249389648438  _______ Metric :  \n","##### EPOCH 3015 #####\n","train loss :  2925.55615234375\n","test loss :  749.6347045898438  _______ Metric :  \n","##### EPOCH 3016 #####\n","train loss :  2978.25732421875\n","test loss :  749.6400756835938  _______ Metric :  \n","##### EPOCH 3017 #####\n","train loss :  2915.20654296875\n","test loss :  749.6498413085938  _______ Metric :  \n","##### EPOCH 3018 #####\n","train loss :  2936.99169921875\n","test loss :  749.6517944335938  _______ Metric :  \n","##### EPOCH 3019 #####\n","train loss :  2935.73583984375\n","test loss :  749.6644287109375  _______ Metric :  \n","##### EPOCH 3020 #####\n","train loss :  2930.25732421875\n","test loss :  749.6713256835938  _______ Metric :  \n","##### EPOCH 3021 #####\n","train loss :  2909.60693359375\n","test loss :  749.6824951171875  _______ Metric :  \n","##### EPOCH 3022 #####\n","train loss :  2981.83154296875\n","test loss :  749.6893920898438  _______ Metric :  \n","##### EPOCH 3023 #####\n","train loss :  2917.03076171875\n","test loss :  749.6898193359375  _______ Metric :  \n","##### EPOCH 3024 #####\n","train loss :  2929.71044921875\n","test loss :  749.6932373046875  _______ Metric :  \n","##### EPOCH 3025 #####\n","train loss :  2945.41162109375\n","test loss :  749.7005615234375  _______ Metric :  \n","##### EPOCH 3026 #####\n","train loss :  2974.91357421875\n","test loss :  749.7059326171875  _______ Metric :  \n","##### EPOCH 3027 #####\n","train loss :  2938.44287109375\n","test loss :  749.7093505859375  _______ Metric :  \n","##### EPOCH 3028 #####\n","train loss :  2924.68115234375\n","test loss :  749.7108154296875  _______ Metric :  \n","##### EPOCH 3029 #####\n","train loss :  2978.78076171875\n","test loss :  749.7137451171875  _______ Metric :  \n","##### EPOCH 3030 #####\n","train loss :  2943.87646484375\n","test loss :  749.7147216796875  _______ Metric :  \n","##### EPOCH 3031 #####\n","train loss :  2977.66552734375\n","test loss :  749.7225341796875  _______ Metric :  \n","##### EPOCH 3032 #####\n","train loss :  2943.10107421875\n","test loss :  749.7254638671875  _______ Metric :  \n","##### EPOCH 3033 #####\n","train loss :  2947.41162109375\n","test loss :  749.7249755859375  _______ Metric :  \n","##### EPOCH 3034 #####\n","train loss :  2919.33154296875\n","test loss :  749.7288818359375  _______ Metric :  \n","##### EPOCH 3035 #####\n","train loss :  2929.31787109375\n","test loss :  749.7347412109375  _______ Metric :  \n","##### EPOCH 3036 #####\n","train loss :  2951.31787109375\n","test loss :  749.7318115234375  _______ Metric :  \n","##### EPOCH 3037 #####\n","train loss :  2960.50927734375\n","test loss :  749.7327880859375  _______ Metric :  \n","##### EPOCH 3038 #####\n","train loss :  2914.73974609375\n","test loss :  749.7293701171875  _______ Metric :  \n","##### EPOCH 3039 #####\n","train loss :  2915.39794921875\n","test loss :  749.7347412109375  _______ Metric :  \n","##### EPOCH 3040 #####\n","train loss :  2934.76513671875\n","test loss :  749.7332763671875  _______ Metric :  \n","##### EPOCH 3041 #####\n","train loss :  2902.79638671875\n","test loss :  749.7391357421875  _______ Metric :  \n","##### EPOCH 3042 #####\n","train loss :  2924.25537109375\n","test loss :  749.7381591796875  _______ Metric :  \n","##### EPOCH 3043 #####\n","train loss :  2946.63232421875\n","test loss :  749.7396240234375  _______ Metric :  \n","##### EPOCH 3044 #####\n","train loss :  2933.94091796875\n","test loss :  749.7415771484375  _______ Metric :  \n","##### EPOCH 3045 #####\n","train loss :  2953.01123046875\n","test loss :  749.7518310546875  _______ Metric :  \n","##### EPOCH 3046 #####\n","train loss :  2899.71435546875\n","test loss :  749.7572021484375  _______ Metric :  \n","##### EPOCH 3047 #####\n","train loss :  2907.96826171875\n","test loss :  749.7606201171875  _______ Metric :  \n","##### EPOCH 3048 #####\n","train loss :  2944.99169921875\n","test loss :  749.7576904296875  _______ Metric :  \n","##### EPOCH 3049 #####\n","train loss :  2942.29833984375\n","test loss :  749.7547607421875  _______ Metric :  \n","##### EPOCH 3050 #####\n","train loss :  2970.39208984375\n","test loss :  749.7542724609375  _______ Metric :  \n","##### EPOCH 3051 #####\n","train loss :  2975.77294921875\n","test loss :  749.7518310546875  _______ Metric :  \n","##### EPOCH 3052 #####\n","train loss :  2917.72021484375\n","test loss :  749.7547607421875  _______ Metric :  \n","##### EPOCH 3053 #####\n","train loss :  2925.11669921875\n","test loss :  749.7640380859375  _______ Metric :  \n","##### EPOCH 3054 #####\n","train loss :  2946.45654296875\n","test loss :  749.7733154296875  _______ Metric :  \n","##### EPOCH 3055 #####\n","train loss :  2917.13232421875\n","test loss :  749.7845458984375  _______ Metric :  \n","##### EPOCH 3056 #####\n","train loss :  2895.54638671875\n","test loss :  749.7908935546875  _______ Metric :  \n","##### EPOCH 3057 #####\n","train loss :  2978.46044921875\n","test loss :  749.8001708984375  _______ Metric :  \n","##### EPOCH 3058 #####\n","train loss :  2949.19287109375\n","test loss :  749.8011474609375  _______ Metric :  \n","##### EPOCH 3059 #####\n","train loss :  2939.09521484375\n","test loss :  749.8055419921875  _______ Metric :  \n","##### EPOCH 3060 #####\n","train loss :  2920.50341796875\n","test loss :  749.8128662109375  _______ Metric :  \n","##### EPOCH 3061 #####\n","train loss :  2968.89599609375\n","test loss :  749.8118896484375  _______ Metric :  \n","##### EPOCH 3062 #####\n","train loss :  2948.61083984375\n","test loss :  749.8231201171875  _______ Metric :  \n","##### EPOCH 3063 #####\n","train loss :  2940.40771484375\n","test loss :  749.8289794921875  _______ Metric :  \n","##### EPOCH 3064 #####\n","train loss :  2915.00341796875\n","test loss :  749.8304443359375  _______ Metric :  \n","##### EPOCH 3065 #####\n","train loss :  2955.48974609375\n","test loss :  749.8280029296875  _______ Metric :  \n","##### EPOCH 3066 #####\n","train loss :  2936.12060546875\n","test loss :  749.8333740234375  _______ Metric :  \n","##### EPOCH 3067 #####\n","train loss :  2961.99755859375\n","test loss :  749.8358154296875  _______ Metric :  \n","##### EPOCH 3068 #####\n","train loss :  2932.89990234375\n","test loss :  749.8416748046875  _______ Metric :  \n","##### EPOCH 3069 #####\n","train loss :  2943.49951171875\n","test loss :  749.8421630859375  _______ Metric :  \n","##### EPOCH 3070 #####\n","train loss :  2901.16552734375\n","test loss :  749.8475341796875  _______ Metric :  \n","##### EPOCH 3071 #####\n","train loss :  2935.78857421875\n","test loss :  749.8387451171875  _______ Metric :  \n","##### EPOCH 3072 #####\n","train loss :  2949.09716796875\n","test loss :  749.8358154296875  _______ Metric :  \n","##### EPOCH 3073 #####\n","train loss :  2927.23974609375\n","test loss :  749.8309326171875  _______ Metric :  \n","##### EPOCH 3074 #####\n","train loss :  2940.71240234375\n","test loss :  749.8236083984375  _______ Metric :  \n","##### EPOCH 3075 #####\n","train loss :  2916.16748046875\n","test loss :  749.8236083984375  _______ Metric :  \n","##### EPOCH 3076 #####\n","train loss :  2932.61669921875\n","test loss :  749.8182373046875  _______ Metric :  \n","##### EPOCH 3077 #####\n","train loss :  2930.44091796875\n","test loss :  749.8128662109375  _______ Metric :  \n","##### EPOCH 3078 #####\n","train loss :  2895.26318359375\n","test loss :  749.8109130859375  _______ Metric :  \n","##### EPOCH 3079 #####\n","train loss :  2975.30810546875\n","test loss :  749.7987060546875  _______ Metric :  \n","##### EPOCH 3080 #####\n","train loss :  2960.51904296875\n","test loss :  749.7918701171875  _______ Metric :  \n","##### EPOCH 3081 #####\n","train loss :  2941.40576171875\n","test loss :  749.7806396484375  _______ Metric :  \n","##### EPOCH 3082 #####\n","train loss :  2965.27685546875\n","test loss :  749.7684326171875  _______ Metric :  \n","##### EPOCH 3083 #####\n","train loss :  2941.42919921875\n","test loss :  749.7659912109375  _______ Metric :  \n","##### EPOCH 3084 #####\n","train loss :  2927.60888671875\n","test loss :  749.7581787109375  _______ Metric :  \n","##### EPOCH 3085 #####\n","train loss :  2929.98583984375\n","test loss :  749.7508544921875  _______ Metric :  \n","##### EPOCH 3086 #####\n","train loss :  2932.77685546875\n","test loss :  749.7513427734375  _______ Metric :  \n","##### EPOCH 3087 #####\n","train loss :  2919.10888671875\n","test loss :  749.7543334960938  _______ Metric :  \n","##### EPOCH 3088 #####\n","train loss :  2935.94677734375\n","test loss :  749.7567749023438  _______ Metric :  \n","##### EPOCH 3089 #####\n","train loss :  2930.71826171875\n","test loss :  749.75732421875  _______ Metric :  \n","##### EPOCH 3090 #####\n","train loss :  2972.66943359375\n","test loss :  749.75732421875  _______ Metric :  \n","##### EPOCH 3091 #####\n","train loss :  2898.64013671875\n","test loss :  749.7500610351562  _______ Metric :  \n","##### EPOCH 3092 #####\n","train loss :  2950.20849609375\n","test loss :  749.7442016601562  _______ Metric :  \n","##### EPOCH 3093 #####\n","train loss :  2923.71435546875\n","test loss :  749.7417602539062  _______ Metric :  \n","##### EPOCH 3094 #####\n","train loss :  2919.09326171875\n","test loss :  749.7417602539062  _______ Metric :  \n","##### EPOCH 3095 #####\n","train loss :  2945.32958984375\n","test loss :  749.7290649414062  _______ Metric :  \n","##### EPOCH 3096 #####\n","train loss :  2921.35107421875\n","test loss :  749.7212524414062  _______ Metric :  \n","##### EPOCH 3097 #####\n","train loss :  2949.04052734375\n","test loss :  749.7149047851562  _______ Metric :  \n","##### EPOCH 3098 #####\n","train loss :  2943.33935546875\n","test loss :  749.6997680664062  _______ Metric :  \n","##### EPOCH 3099 #####\n","train loss :  2932.37841796875\n","test loss :  749.6880493164062  _______ Metric :  \n","##### EPOCH 3100 #####\n","train loss :  2967.85498046875\n","test loss :  749.6807250976562  _______ Metric :  \n","##### EPOCH 3101 #####\n","train loss :  2944.48583984375\n","test loss :  749.6734008789062  _______ Metric :  \n","##### EPOCH 3102 #####\n","train loss :  2921.80224609375\n","test loss :  749.6670532226562  _______ Metric :  \n","##### EPOCH 3103 #####\n","train loss :  2906.14794921875\n","test loss :  749.6616821289062  _______ Metric :  \n","##### EPOCH 3104 #####\n","train loss :  2910.35302734375\n","test loss :  749.6593017578125  _______ Metric :  \n","##### EPOCH 3105 #####\n","train loss :  2893.36474609375\n","test loss :  749.6500244140625  _______ Metric :  \n","##### EPOCH 3106 #####\n","train loss :  2958.02880859375\n","test loss :  749.6446533203125  _______ Metric :  \n","##### EPOCH 3107 #####\n","train loss :  2924.54052734375\n","test loss :  749.6436767578125  _______ Metric :  \n","##### EPOCH 3108 #####\n","train loss :  2943.19677734375\n","test loss :  749.6407470703125  _______ Metric :  \n","##### EPOCH 3109 #####\n","train loss :  2922.79638671875\n","test loss :  749.6378173828125  _______ Metric :  \n","##### EPOCH 3110 #####\n","train loss :  2924.22216796875\n","test loss :  749.6358642578125  _______ Metric :  \n","##### EPOCH 3111 #####\n","train loss :  2939.12451171875\n","test loss :  749.6280517578125  _______ Metric :  \n","##### EPOCH 3112 #####\n","train loss :  2916.08935546875\n","test loss :  749.6226806640625  _______ Metric :  \n","##### EPOCH 3113 #####\n","train loss :  2911.76318359375\n","test loss :  749.6192626953125  _______ Metric :  \n","##### EPOCH 3114 #####\n","train loss :  2947.69677734375\n","test loss :  749.6153564453125  _______ Metric :  \n","##### EPOCH 3115 #####\n","train loss :  2956.22021484375\n","test loss :  749.6114501953125  _______ Metric :  \n","##### EPOCH 3116 #####\n","train loss :  2915.47802734375\n","test loss :  749.6051025390625  _______ Metric :  \n","##### EPOCH 3117 #####\n","train loss :  2918.84716796875\n","test loss :  749.6016845703125  _______ Metric :  \n","##### EPOCH 3118 #####\n","train loss :  2949.44873046875\n","test loss :  749.5977783203125  _______ Metric :  \n","##### EPOCH 3119 #####\n","train loss :  2939.77294921875\n","test loss :  749.5958251953125  _______ Metric :  \n","##### EPOCH 3120 #####\n","train loss :  2920.48193359375\n","test loss :  749.5889892578125  _______ Metric :  \n","##### EPOCH 3121 #####\n","train loss :  2991.83154296875\n","test loss :  749.5880126953125  _______ Metric :  \n","##### EPOCH 3122 #####\n","train loss :  2909.25537109375\n","test loss :  749.5821533203125  _______ Metric :  \n","##### EPOCH 3123 #####\n","train loss :  2921.75927734375\n","test loss :  749.5792236328125  _______ Metric :  \n","##### EPOCH 3124 #####\n","train loss :  2965.37451171875\n","test loss :  749.5772705078125  _______ Metric :  \n","##### EPOCH 3125 #####\n","train loss :  2964.20654296875\n","test loss :  749.5758056640625  _______ Metric :  \n","##### EPOCH 3126 #####\n","train loss :  2970.48779296875\n","test loss :  749.5733642578125  _______ Metric :  \n","##### EPOCH 3127 #####\n","train loss :  2955.02685546875\n","test loss :  749.5753173828125  _______ Metric :  \n","##### EPOCH 3128 #####\n","train loss :  2982.86474609375\n","test loss :  749.5831298828125  _______ Metric :  \n","##### EPOCH 3129 #####\n","train loss :  2939.42724609375\n","test loss :  749.5870361328125  _______ Metric :  \n","##### EPOCH 3130 #####\n","train loss :  2955.67333984375\n","test loss :  749.5919189453125  _______ Metric :  \n","##### EPOCH 3131 #####\n","train loss :  2950.52685546875\n","test loss :  749.5968017578125  _______ Metric :  \n","##### EPOCH 3132 #####\n","train loss :  2932.39404296875\n","test loss :  749.6041259765625  _______ Metric :  \n","##### EPOCH 3133 #####\n","train loss :  2912.58544921875\n","test loss :  749.6119384765625  _______ Metric :  \n","##### EPOCH 3134 #####\n","train loss :  2973.91162109375\n","test loss :  749.6226806640625  _______ Metric :  \n","##### EPOCH 3135 #####\n","train loss :  2945.71826171875\n","test loss :  749.6260986328125  _______ Metric :  \n","##### EPOCH 3136 #####\n","train loss :  2932.05419921875\n","test loss :  749.6339111328125  _______ Metric :  \n","##### EPOCH 3137 #####\n","train loss :  2931.48583984375\n","test loss :  749.6280517578125  _______ Metric :  \n","##### EPOCH 3138 #####\n","train loss :  2929.74560546875\n","test loss :  749.6300048828125  _______ Metric :  \n","##### EPOCH 3139 #####\n","train loss :  2923.48583984375\n","test loss :  749.6339111328125  _______ Metric :  \n","##### EPOCH 3140 #####\n","train loss :  2923.59716796875\n","test loss :  749.6309814453125  _______ Metric :  \n","##### EPOCH 3141 #####\n","train loss :  2919.63818359375\n","test loss :  749.6285400390625  _______ Metric :  \n","##### EPOCH 3142 #####\n","train loss :  2931.64794921875\n","test loss :  749.6236572265625  _______ Metric :  \n","##### EPOCH 3143 #####\n","train loss :  2920.77294921875\n","test loss :  749.6192626953125  _______ Metric :  \n","##### EPOCH 3144 #####\n","train loss :  2908.70458984375\n","test loss :  749.6212158203125  _______ Metric :  \n","##### EPOCH 3145 #####\n","train loss :  2936.53857421875\n","test loss :  749.6148681640625  _______ Metric :  \n","##### EPOCH 3146 #####\n","train loss :  2922.39013671875\n","test loss :  749.6100463867188  _______ Metric :  \n","##### EPOCH 3147 #####\n","train loss :  2933.72412109375\n","test loss :  749.6061401367188  _______ Metric :  \n","##### EPOCH 3148 #####\n","train loss :  2955.26318359375\n","test loss :  749.6110229492188  _______ Metric :  \n","##### EPOCH 3149 #####\n","train loss :  2909.06982421875\n","test loss :  749.6124877929688  _______ Metric :  \n","##### EPOCH 3150 #####\n","train loss :  2919.00537109375\n","test loss :  749.6188354492188  _______ Metric :  \n","##### EPOCH 3151 #####\n","train loss :  2941.89404296875\n","test loss :  749.6178588867188  _______ Metric :  \n","##### EPOCH 3152 #####\n","train loss :  2973.66748046875\n","test loss :  749.6144409179688  _______ Metric :  \n","##### EPOCH 3153 #####\n","train loss :  2948.70263671875\n","test loss :  749.6198120117188  _______ Metric :  \n","##### EPOCH 3154 #####\n","train loss :  2928.57177734375\n","test loss :  749.6261596679688  _______ Metric :  \n","##### EPOCH 3155 #####\n","train loss :  2948.46435546875\n","test loss :  749.6305541992188  _______ Metric :  \n","##### EPOCH 3156 #####\n","train loss :  2914.97802734375\n","test loss :  749.6276245117188  _______ Metric :  \n","##### EPOCH 3157 #####\n","train loss :  2941.27099609375\n","test loss :  749.6198120117188  _______ Metric :  \n","##### EPOCH 3158 #####\n","train loss :  2910.88427734375\n","test loss :  749.6178588867188  _______ Metric :  \n","##### EPOCH 3159 #####\n","train loss :  2942.33349609375\n","test loss :  749.6139526367188  _______ Metric :  \n","##### EPOCH 3160 #####\n","train loss :  2943.16943359375\n","test loss :  749.6193237304688  _______ Metric :  \n","##### EPOCH 3161 #####\n","train loss :  2911.40576171875\n","test loss :  749.6212768554688  _______ Metric :  \n","##### EPOCH 3162 #####\n","train loss :  2932.28466796875\n","test loss :  749.6261596679688  _______ Metric :  \n","##### EPOCH 3163 #####\n","train loss :  2925.46630859375\n","test loss :  749.6271362304688  _______ Metric :  \n","##### EPOCH 3164 #####\n","train loss :  2974.40380859375\n","test loss :  749.6325073242188  _______ Metric :  \n","##### EPOCH 3165 #####\n","train loss :  2947.31005859375\n","test loss :  749.6344604492188  _______ Metric :  \n","##### EPOCH 3166 #####\n","train loss :  2959.05419921875\n","test loss :  749.6305541992188  _______ Metric :  \n","##### EPOCH 3167 #####\n","train loss :  2959.01123046875\n","test loss :  749.6212768554688  _______ Metric :  \n","##### EPOCH 3168 #####\n","train loss :  2964.56201171875\n","test loss :  749.6095581054688  _______ Metric :  \n","##### EPOCH 3169 #####\n","train loss :  2882.59912109375\n","test loss :  749.6051635742188  _______ Metric :  \n","##### EPOCH 3170 #####\n","train loss :  2948.64794921875\n","test loss :  749.5988159179688  _______ Metric :  \n","##### EPOCH 3171 #####\n","train loss :  2916.85693359375\n","test loss :  749.5944213867188  _______ Metric :  \n","##### EPOCH 3172 #####\n","train loss :  2912.31982421875\n","test loss :  749.5914916992188  _______ Metric :  \n","##### EPOCH 3173 #####\n","train loss :  2959.90771484375\n","test loss :  749.5905151367188  _______ Metric :  \n","##### EPOCH 3174 #####\n","train loss :  2922.01904296875\n","test loss :  749.5890502929688  _______ Metric :  \n","##### EPOCH 3175 #####\n","train loss :  2934.23779296875\n","test loss :  749.5846557617188  _______ Metric :  \n","##### EPOCH 3176 #####\n","train loss :  2935.22216796875\n","test loss :  749.5856323242188  _______ Metric :  \n","##### EPOCH 3177 #####\n","train loss :  2949.62060546875\n","test loss :  749.5900268554688  _______ Metric :  \n","##### EPOCH 3178 #####\n","train loss :  2938.86279296875\n","test loss :  749.5895385742188  _______ Metric :  \n","##### EPOCH 3179 #####\n","train loss :  2918.73974609375\n","test loss :  749.5919799804688  _______ Metric :  \n","##### EPOCH 3180 #####\n","train loss :  2921.60302734375\n","test loss :  749.5944213867188  _______ Metric :  \n","##### EPOCH 3181 #####\n","train loss :  2927.78662109375\n","test loss :  749.5973510742188  _______ Metric :  \n","##### EPOCH 3182 #####\n","train loss :  2947.21240234375\n","test loss :  749.6012573242188  _______ Metric :  \n","##### EPOCH 3183 #####\n","train loss :  2956.24755859375\n","test loss :  749.5993041992188  _______ Metric :  \n","##### EPOCH 3184 #####\n","train loss :  2924.86083984375\n","test loss :  749.6007690429688  _______ Metric :  \n","##### EPOCH 3185 #####\n","train loss :  2917.37646484375\n","test loss :  749.6061401367188  _______ Metric :  \n","##### EPOCH 3186 #####\n","train loss :  2937.03857421875\n","test loss :  749.5997924804688  _______ Metric :  \n","##### EPOCH 3187 #####\n","train loss :  2918.88818359375\n","test loss :  749.5958862304688  _______ Metric :  \n","##### EPOCH 3188 #####\n","train loss :  2936.04248046875\n","test loss :  749.5949096679688  _______ Metric :  \n","##### EPOCH 3189 #####\n","train loss :  2914.84521484375\n","test loss :  749.5895385742188  _______ Metric :  \n","##### EPOCH 3190 #####\n","train loss :  2919.04638671875\n","test loss :  749.5831909179688  _______ Metric :  \n","##### EPOCH 3191 #####\n","train loss :  2921.69091796875\n","test loss :  749.5783081054688  _______ Metric :  \n","##### EPOCH 3192 #####\n","train loss :  2974.70458984375\n","test loss :  749.5724487304688  _______ Metric :  \n","##### EPOCH 3193 #####\n","train loss :  2888.53076171875\n","test loss :  749.5685424804688  _______ Metric :  \n","##### EPOCH 3194 #####\n","train loss :  2955.44873046875\n","test loss :  749.5631713867188  _______ Metric :  \n","##### EPOCH 3195 #####\n","train loss :  2910.27880859375\n","test loss :  749.5631713867188  _______ Metric :  \n","##### EPOCH 3196 #####\n","train loss :  2919.85107421875\n","test loss :  749.5661010742188  _______ Metric :  \n","##### EPOCH 3197 #####\n","train loss :  2928.41943359375\n","test loss :  749.5621948242188  _______ Metric :  \n","##### EPOCH 3198 #####\n","train loss :  2943.84521484375\n","test loss :  749.5651245117188  _______ Metric :  \n","##### EPOCH 3199 #####\n","train loss :  2915.82177734375\n","test loss :  749.5656127929688  _______ Metric :  \n","##### EPOCH 3200 #####\n","train loss :  2940.56591796875\n","test loss :  749.5685424804688  _______ Metric :  \n","##### EPOCH 3201 #####\n","train loss :  2937.32568359375\n","test loss :  749.5748901367188  _______ Metric :  \n","##### EPOCH 3202 #####\n","train loss :  2903.62841796875\n","test loss :  749.5783081054688  _______ Metric :  \n","##### EPOCH 3203 #####\n","train loss :  2955.99560546875\n","test loss :  749.5817260742188  _______ Metric :  \n","##### EPOCH 3204 #####\n","train loss :  2922.90771484375\n","test loss :  749.5870971679688  _______ Metric :  \n","##### EPOCH 3205 #####\n","train loss :  2932.64404296875\n","test loss :  749.5851440429688  _______ Metric :  \n","##### EPOCH 3206 #####\n","train loss :  2950.90185546875\n","test loss :  749.5802612304688  _______ Metric :  \n","##### EPOCH 3207 #####\n","train loss :  2942.13623046875\n","test loss :  749.5768432617188  _______ Metric :  \n","##### EPOCH 3208 #####\n","train loss :  2916.83154296875\n","test loss :  749.5773315429688  _______ Metric :  \n","##### EPOCH 3209 #####\n","train loss :  2890.00732421875\n","test loss :  749.5724487304688  _______ Metric :  \n","##### EPOCH 3210 #####\n","train loss :  2951.35302734375\n","test loss :  749.5724487304688  _______ Metric :  \n","##### EPOCH 3211 #####\n","train loss :  2974.19482421875\n","test loss :  749.5787963867188  _______ Metric :  \n","##### EPOCH 3212 #####\n","train loss :  2924.82958984375\n","test loss :  749.5797729492188  _______ Metric :  \n","##### EPOCH 3213 #####\n","train loss :  2906.01123046875\n","test loss :  749.5778198242188  _______ Metric :  \n","##### EPOCH 3214 #####\n","train loss :  2938.74755859375\n","test loss :  749.5792846679688  _______ Metric :  \n","##### EPOCH 3215 #####\n","train loss :  2919.22802734375\n","test loss :  749.5797729492188  _______ Metric :  \n","##### EPOCH 3216 #####\n","train loss :  2924.02880859375\n","test loss :  749.5817260742188  _______ Metric :  \n","##### EPOCH 3217 #####\n","train loss :  2865.60498046875\n","test loss :  749.5880737304688  _______ Metric :  \n","##### EPOCH 3218 #####\n","train loss :  2925.75146484375\n","test loss :  749.5978393554688  _______ Metric :  \n","##### EPOCH 3219 #####\n","train loss :  2941.97802734375\n","test loss :  749.5900268554688  _______ Metric :  \n","##### EPOCH 3220 #####\n","train loss :  2951.47998046875\n","test loss :  749.5968627929688  _______ Metric :  \n","##### EPOCH 3221 #####\n","train loss :  2914.02099609375\n","test loss :  749.5924682617188  _______ Metric :  \n","##### EPOCH 3222 #####\n","train loss :  2944.74560546875\n","test loss :  749.5890502929688  _______ Metric :  \n","##### EPOCH 3223 #####\n","train loss :  2910.24755859375\n","test loss :  749.5958862304688  _______ Metric :  \n","##### EPOCH 3224 #####\n","train loss :  2971.18896484375\n","test loss :  749.5997924804688  _______ Metric :  \n","##### EPOCH 3225 #####\n","train loss :  2918.64794921875\n","test loss :  749.6080932617188  _______ Metric :  \n","##### EPOCH 3226 #####\n","train loss :  2938.83740234375\n","test loss :  749.6183471679688  _______ Metric :  \n","##### EPOCH 3227 #####\n","train loss :  2937.46044921875\n","test loss :  749.6276245117188  _______ Metric :  \n","##### EPOCH 3228 #####\n","train loss :  2963.51513671875\n","test loss :  749.6329956054688  _______ Metric :  \n","##### EPOCH 3229 #####\n","train loss :  2879.384521484375\n","test loss :  749.6403198242188  _______ Metric :  \n","##### EPOCH 3230 #####\n","train loss :  2927.781005859375\n","test loss :  749.6447143554688  _______ Metric :  \n","##### EPOCH 3231 #####\n","train loss :  2909.443115234375\n","test loss :  749.6393432617188  _______ Metric :  \n","##### EPOCH 3232 #####\n","train loss :  2918.157958984375\n","test loss :  749.6388549804688  _______ Metric :  \n","##### EPOCH 3233 #####\n","train loss :  2930.634521484375\n","test loss :  749.6383666992188  _______ Metric :  \n","##### EPOCH 3234 #####\n","train loss :  2914.839599609375\n","test loss :  749.6412963867188  _______ Metric :  \n","##### EPOCH 3235 #####\n","train loss :  2954.761474609375\n","test loss :  749.6349487304688  _______ Metric :  \n","##### EPOCH 3236 #####\n","train loss :  2934.050537109375\n","test loss :  749.6325073242188  _______ Metric :  \n","##### EPOCH 3237 #####\n","train loss :  2946.046630859375\n","test loss :  749.6222534179688  _______ Metric :  \n","##### EPOCH 3238 #####\n","train loss :  2914.888427734375\n","test loss :  749.6246948242188  _______ Metric :  \n","##### EPOCH 3239 #####\n","train loss :  2956.429443359375\n","test loss :  749.6203002929688  _______ Metric :  \n","##### EPOCH 3240 #####\n","train loss :  2922.976318359375\n","test loss :  749.6036987304688  _______ Metric :  \n","##### EPOCH 3241 #####\n","train loss :  2919.195068359375\n","test loss :  749.5958862304688  _______ Metric :  \n","##### EPOCH 3242 #####\n","train loss :  2907.843505859375\n","test loss :  749.6012573242188  _______ Metric :  \n","##### EPOCH 3243 #####\n","train loss :  2936.355224609375\n","test loss :  749.5973510742188  _______ Metric :  \n","##### EPOCH 3244 #####\n","train loss :  2942.503662109375\n","test loss :  749.5988159179688  _______ Metric :  \n","##### EPOCH 3245 #####\n","train loss :  2966.708740234375\n","test loss :  749.6071166992188  _______ Metric :  \n","##### EPOCH 3246 #####\n","train loss :  2909.634521484375\n","test loss :  749.6085815429688  _______ Metric :  \n","##### EPOCH 3247 #####\n","train loss :  2904.290771484375\n","test loss :  749.6159057617188  _______ Metric :  \n","##### EPOCH 3248 #####\n","train loss :  2890.126708984375\n","test loss :  749.6271362304688  _______ Metric :  \n","##### EPOCH 3249 #####\n","train loss :  2899.786865234375\n","test loss :  749.632568359375  _______ Metric :  \n","##### EPOCH 3250 #####\n","train loss :  2942.853271484375\n","test loss :  749.629150390625  _______ Metric :  \n","##### EPOCH 3251 #####\n","train loss :  2914.040771484375\n","test loss :  749.631103515625  _______ Metric :  \n","##### EPOCH 3252 #####\n","train loss :  2943.667724609375\n","test loss :  749.633056640625  _______ Metric :  \n","##### EPOCH 3253 #####\n","train loss :  2963.605224609375\n","test loss :  749.636474609375  _______ Metric :  \n","##### EPOCH 3254 #####\n","train loss :  2902.191162109375\n","test loss :  749.643798828125  _______ Metric :  \n","##### EPOCH 3255 #####\n","train loss :  2921.579833984375\n","test loss :  749.639892578125  _______ Metric :  \n","##### EPOCH 3256 #####\n","train loss :  2911.855224609375\n","test loss :  749.643310546875  _______ Metric :  \n","##### EPOCH 3257 #####\n","train loss :  2954.689208984375\n","test loss :  749.649658203125  _______ Metric :  \n","##### EPOCH 3258 #####\n","train loss :  2935.782958984375\n","test loss :  749.644287109375  _______ Metric :  \n","##### EPOCH 3259 #####\n","train loss :  2930.122802734375\n","test loss :  749.635986328125  _______ Metric :  \n","##### EPOCH 3260 #####\n","train loss :  2911.114990234375\n","test loss :  749.624755859375  _______ Metric :  \n","##### EPOCH 3261 #####\n","train loss :  2921.130615234375\n","test loss :  749.621337890625  _______ Metric :  \n","##### EPOCH 3262 #####\n","train loss :  2931.864990234375\n","test loss :  749.616943359375  _______ Metric :  \n","##### EPOCH 3263 #####\n","train loss :  2932.28515625\n","test loss :  749.610595703125  _______ Metric :  \n","##### EPOCH 3264 #####\n","train loss :  2928.04296875\n","test loss :  749.605712890625  _______ Metric :  \n","##### EPOCH 3265 #####\n","train loss :  2912.494140625\n","test loss :  749.602294921875  _______ Metric :  \n","##### EPOCH 3266 #####\n","train loss :  2942.96484375\n","test loss :  749.595458984375  _______ Metric :  \n","##### EPOCH 3267 #####\n","train loss :  2931.13671875\n","test loss :  749.586669921875  _______ Metric :  \n","##### EPOCH 3268 #####\n","train loss :  2957.21875\n","test loss :  749.580810546875  _______ Metric :  \n","##### EPOCH 3269 #####\n","train loss :  2948.771484375\n","test loss :  749.574462890625  _______ Metric :  \n","##### EPOCH 3270 #####\n","train loss :  2914.34375\n","test loss :  749.571533203125  _______ Metric :  \n","##### EPOCH 3271 #####\n","train loss :  2960.28515625\n","test loss :  749.573486328125  _______ Metric :  \n","##### EPOCH 3272 #####\n","train loss :  2941.98046875\n","test loss :  749.567138671875  _______ Metric :  \n","##### EPOCH 3273 #####\n","train loss :  2927.62109375\n","test loss :  749.5637817382812  _______ Metric :  \n","##### EPOCH 3274 #####\n","train loss :  2908.69921875\n","test loss :  749.5647583007812  _______ Metric :  \n","##### EPOCH 3275 #####\n","train loss :  2966.39453125\n","test loss :  749.5691528320312  _______ Metric :  \n","##### EPOCH 3276 #####\n","train loss :  2946.3046875\n","test loss :  749.5667114257812  _______ Metric :  \n","##### EPOCH 3277 #####\n","train loss :  2959.162109375\n","test loss :  749.5662231445312  _______ Metric :  \n","##### EPOCH 3278 #####\n","train loss :  2945.712890625\n","test loss :  749.5598754882812  _______ Metric :  \n","##### EPOCH 3279 #####\n","train loss :  2953.751953125\n","test loss :  749.5584106445312  _______ Metric :  \n","##### EPOCH 3280 #####\n","train loss :  2911.369140625\n","test loss :  749.5564575195312  _______ Metric :  \n","##### EPOCH 3281 #####\n","train loss :  2906.494140625\n","test loss :  749.5471801757812  _______ Metric :  \n","##### EPOCH 3282 #####\n","train loss :  2937.369140625\n","test loss :  749.5525512695312  _______ Metric :  \n","##### EPOCH 3283 #####\n","train loss :  2941.126953125\n","test loss :  749.5579223632812  _______ Metric :  \n","##### EPOCH 3284 #####\n","train loss :  2940.95703125\n","test loss :  749.5657348632812  _______ Metric :  \n","##### EPOCH 3285 #####\n","train loss :  2965.86328125\n","test loss :  749.5652465820312  _______ Metric :  \n","##### EPOCH 3286 #####\n","train loss :  2938.482421875\n","test loss :  749.5681762695312  _______ Metric :  \n","##### EPOCH 3287 #####\n","train loss :  2922.4296875\n","test loss :  749.5662231445312  _______ Metric :  \n","##### EPOCH 3288 #####\n","train loss :  2947.796875\n","test loss :  749.5608520507812  _______ Metric :  \n","##### EPOCH 3289 #####\n","train loss :  2926.60546875\n","test loss :  749.5603637695312  _______ Metric :  \n","##### EPOCH 3290 #####\n","train loss :  2948.208984375\n","test loss :  749.5545043945312  _______ Metric :  \n","##### EPOCH 3291 #####\n","train loss :  2926.96484375\n","test loss :  749.5457153320312  _______ Metric :  \n","##### EPOCH 3292 #####\n","train loss :  2939.708984375\n","test loss :  749.5462036132812  _______ Metric :  \n","##### EPOCH 3293 #####\n","train loss :  2903.556640625\n","test loss :  749.5403442382812  _______ Metric :  \n","##### EPOCH 3294 #####\n","train loss :  2932.8046875\n","test loss :  749.5354614257812  _______ Metric :  \n","##### EPOCH 3295 #####\n","train loss :  2927.705078125\n","test loss :  749.5310668945312  _______ Metric :  \n","##### EPOCH 3296 #####\n","train loss :  2936.01171875\n","test loss :  749.5261840820312  _______ Metric :  \n","##### EPOCH 3297 #####\n","train loss :  2954.66796875\n","test loss :  749.5203247070312  _______ Metric :  \n","##### EPOCH 3298 #####\n","train loss :  2900.25\n","test loss :  749.5105590820312  _______ Metric :  \n","##### EPOCH 3299 #####\n","train loss :  2925.7578125\n","test loss :  749.5012817382812  _______ Metric :  \n","##### EPOCH 3300 #####\n","train loss :  2939.791015625\n","test loss :  749.4915161132812  _______ Metric :  \n","##### EPOCH 3301 #####\n","train loss :  2939.57421875\n","test loss :  749.4783325195312  _______ Metric :  \n","##### EPOCH 3302 #####\n","train loss :  2927.73046875\n","test loss :  749.4719848632812  _______ Metric :  \n","##### EPOCH 3303 #####\n","train loss :  2961.982421875\n","test loss :  749.4695434570312  _______ Metric :  \n","##### EPOCH 3304 #####\n","train loss :  2901.35546875\n","test loss :  749.4680786132812  _______ Metric :  \n","##### EPOCH 3305 #####\n","train loss :  2942.55078125\n","test loss :  749.4695434570312  _______ Metric :  \n","##### EPOCH 3306 #####\n","train loss :  2919.19140625\n","test loss :  749.4705200195312  _______ Metric :  \n","##### EPOCH 3307 #####\n","train loss :  2920.619140625\n","test loss :  749.4719848632812  _______ Metric :  \n","##### EPOCH 3308 #####\n","train loss :  2932.4375\n","test loss :  749.4700317382812  _______ Metric :  \n","##### EPOCH 3309 #####\n","train loss :  2902.76953125\n","test loss :  749.4661254882812  _______ Metric :  \n","##### EPOCH 3310 #####\n","train loss :  2989.587890625\n","test loss :  749.4675903320312  _______ Metric :  \n","##### EPOCH 3311 #####\n","train loss :  2912.294921875\n","test loss :  749.4597778320312  _______ Metric :  \n","##### EPOCH 3312 #####\n","train loss :  2946.498046875\n","test loss :  749.4490356445312  _______ Metric :  \n","##### EPOCH 3313 #####\n","train loss :  2922.955078125\n","test loss :  749.4470825195312  _______ Metric :  \n","##### EPOCH 3314 #####\n","train loss :  2943.697265625\n","test loss :  749.4363403320312  _______ Metric :  \n","##### EPOCH 3315 #####\n","train loss :  2932.8515625\n","test loss :  749.4280395507812  _______ Metric :  \n","##### EPOCH 3316 #####\n","train loss :  2893.955078125\n","test loss :  749.4138793945312  _______ Metric :  \n","##### EPOCH 3317 #####\n","train loss :  2942.58203125\n","test loss :  749.3982543945312  _______ Metric :  \n","##### EPOCH 3318 #####\n","train loss :  2959.0234375\n","test loss :  749.3884887695312  _______ Metric :  \n","##### EPOCH 3319 #####\n","train loss :  2951.638671875\n","test loss :  749.3743286132812  _______ Metric :  \n","##### EPOCH 3320 #####\n","train loss :  2915.810546875\n","test loss :  749.3611450195312  _______ Metric :  \n","##### EPOCH 3321 #####\n","train loss :  2909.146484375\n","test loss :  749.3528442382812  _______ Metric :  \n","##### EPOCH 3322 #####\n","train loss :  2952.68359375\n","test loss :  749.3445434570312  _______ Metric :  \n","##### EPOCH 3323 #####\n","train loss :  2894.599609375\n","test loss :  749.3421020507812  _______ Metric :  \n","##### EPOCH 3324 #####\n","train loss :  2907.056640625\n","test loss :  749.3381958007812  _______ Metric :  \n","##### EPOCH 3325 #####\n","train loss :  2898.056640625\n","test loss :  749.3342895507812  _______ Metric :  \n","##### EPOCH 3326 #####\n","train loss :  2972.939453125\n","test loss :  749.3308715820312  _______ Metric :  \n","##### EPOCH 3327 #####\n","train loss :  2990.046875\n","test loss :  749.3284301757812  _______ Metric :  \n","##### EPOCH 3328 #####\n","train loss :  2947.271484375\n","test loss :  749.3269653320312  _______ Metric :  \n","##### EPOCH 3329 #####\n","train loss :  2902.1640625\n","test loss :  749.3176879882812  _______ Metric :  \n","##### EPOCH 3330 #####\n","train loss :  2977.12109375\n","test loss :  749.3118286132812  _______ Metric :  \n","##### EPOCH 3331 #####\n","train loss :  2951.154296875\n","test loss :  749.3128051757812  _______ Metric :  \n","##### EPOCH 3332 #####\n","train loss :  2929.587890625\n","test loss :  749.3123168945312  _______ Metric :  \n","##### EPOCH 3333 #####\n","train loss :  2958.16015625\n","test loss :  749.3064575195312  _______ Metric :  \n","##### EPOCH 3334 #####\n","train loss :  2948.27734375\n","test loss :  749.2976684570312  _______ Metric :  \n","##### EPOCH 3335 #####\n","train loss :  2959.41015625\n","test loss :  749.2952270507812  _______ Metric :  \n","##### EPOCH 3336 #####\n","train loss :  2926.638671875\n","test loss :  749.2927856445312  _______ Metric :  \n","##### EPOCH 3337 #####\n","train loss :  2921.974609375\n","test loss :  749.2879028320312  _______ Metric :  \n","##### EPOCH 3338 #####\n","train loss :  2963.55859375\n","test loss :  749.2888793945312  _______ Metric :  \n","##### EPOCH 3339 #####\n","train loss :  2910.900390625\n","test loss :  749.2908325195312  _______ Metric :  \n","##### EPOCH 3340 #####\n","train loss :  2935.30078125\n","test loss :  749.2922973632812  _______ Metric :  \n","##### EPOCH 3341 #####\n","train loss :  2928.0390625\n","test loss :  749.2879028320312  _______ Metric :  \n","##### EPOCH 3342 #####\n","train loss :  2915.224609375\n","test loss :  749.2879028320312  _______ Metric :  \n","##### EPOCH 3343 #####\n","train loss :  2949.0078125\n","test loss :  749.2732543945312  _______ Metric :  \n","##### EPOCH 3344 #####\n","train loss :  2938.822265625\n","test loss :  749.2639770507812  _______ Metric :  \n","##### EPOCH 3345 #####\n","train loss :  2931.0390625\n","test loss :  749.2449340820312  _______ Metric :  \n","##### EPOCH 3346 #####\n","train loss :  2913.001953125\n","test loss :  749.2341918945312  _______ Metric :  \n","##### EPOCH 3347 #####\n","train loss :  2928.74609375\n","test loss :  749.2229614257812  _______ Metric :  \n","##### EPOCH 3348 #####\n","train loss :  2945.841796875\n","test loss :  749.2146606445312  _______ Metric :  \n","##### EPOCH 3349 #####\n","train loss :  2931.0625\n","test loss :  749.2102661132812  _______ Metric :  \n","##### EPOCH 3350 #####\n","train loss :  2922.888671875\n","test loss :  749.1970825195312  _______ Metric :  \n","##### EPOCH 3351 #####\n","train loss :  2954.79296875\n","test loss :  749.1921997070312  _______ Metric :  \n","##### EPOCH 3352 #####\n","train loss :  2950.435546875\n","test loss :  749.1755981445312  _______ Metric :  \n","##### EPOCH 3353 #####\n","train loss :  2951.107421875\n","test loss :  749.1682739257812  _______ Metric :  \n","##### EPOCH 3354 #####\n","train loss :  2927.513671875\n","test loss :  749.1580200195312  _______ Metric :  \n","##### EPOCH 3355 #####\n","train loss :  2964.384765625\n","test loss :  749.1458129882812  _______ Metric :  \n","##### EPOCH 3356 #####\n","train loss :  2913.4296875\n","test loss :  749.1365356445312  _______ Metric :  \n","##### EPOCH 3357 #####\n","train loss :  2925.443359375\n","test loss :  749.1316528320312  _______ Metric :  \n","##### EPOCH 3358 #####\n","train loss :  2956.6796875\n","test loss :  749.1316528320312  _______ Metric :  \n","##### EPOCH 3359 #####\n","train loss :  2956.66015625\n","test loss :  749.1267700195312  _______ Metric :  \n","##### EPOCH 3360 #####\n","train loss :  2948.306640625\n","test loss :  749.1248168945312  _______ Metric :  \n","##### EPOCH 3361 #####\n","train loss :  2936.470703125\n","test loss :  749.1174926757812  _______ Metric :  \n","##### EPOCH 3362 #####\n","train loss :  2939.462890625\n","test loss :  749.1116333007812  _______ Metric :  \n","##### EPOCH 3363 #####\n","train loss :  2934.451171875\n","test loss :  749.1062622070312  _______ Metric :  \n","##### EPOCH 3364 #####\n","train loss :  2940.6796875\n","test loss :  749.0906372070312  _______ Metric :  \n","##### EPOCH 3365 #####\n","train loss :  2894.1484375\n","test loss :  749.0857543945312  _______ Metric :  \n","##### EPOCH 3366 #####\n","train loss :  2935.919921875\n","test loss :  749.0833129882812  _______ Metric :  \n","##### EPOCH 3367 #####\n","train loss :  2939.4453125\n","test loss :  749.0759887695312  _______ Metric :  \n","##### EPOCH 3368 #####\n","train loss :  2965.794921875\n","test loss :  749.0725708007812  _______ Metric :  \n","##### EPOCH 3369 #####\n","train loss :  2926.259765625\n","test loss :  749.0681762695312  _______ Metric :  \n","##### EPOCH 3370 #####\n","train loss :  2903.83203125\n","test loss :  749.0676879882812  _______ Metric :  \n","##### EPOCH 3371 #####\n","train loss :  2954.48046875\n","test loss :  749.0623168945312  _______ Metric :  \n","##### EPOCH 3372 #####\n","train loss :  2925.33203125\n","test loss :  749.0545043945312  _______ Metric :  \n","##### EPOCH 3373 #####\n","train loss :  2945.513671875\n","test loss :  749.0598754882812  _______ Metric :  \n","##### EPOCH 3374 #####\n","train loss :  2978.271484375\n","test loss :  749.0691528320312  _______ Metric :  \n","##### EPOCH 3375 #####\n","train loss :  2954.48046875\n","test loss :  749.0720825195312  _______ Metric :  \n","##### EPOCH 3376 #####\n","train loss :  2938.501953125\n","test loss :  749.0784301757812  _______ Metric :  \n","##### EPOCH 3377 #####\n","train loss :  2939.06640625\n","test loss :  749.0808715820312  _______ Metric :  \n","##### EPOCH 3378 #####\n","train loss :  2953.5078125\n","test loss :  749.0930786132812  _______ Metric :  \n","##### EPOCH 3379 #####\n","train loss :  2956.623046875\n","test loss :  749.0945434570312  _______ Metric :  \n","##### EPOCH 3380 #####\n","train loss :  2949.87109375\n","test loss :  749.1013793945312  _______ Metric :  \n","##### EPOCH 3381 #####\n","train loss :  2896.568359375\n","test loss :  749.1116333007812  _______ Metric :  \n","##### EPOCH 3382 #####\n","train loss :  2898.08203125\n","test loss :  749.1243286132812  _______ Metric :  \n","##### EPOCH 3383 #####\n","train loss :  2931.7109375\n","test loss :  749.1394653320312  _______ Metric :  \n","##### EPOCH 3384 #####\n","train loss :  2954.935546875\n","test loss :  749.1458129882812  _______ Metric :  \n","##### EPOCH 3385 #####\n","train loss :  2925.037109375\n","test loss :  749.1526489257812  _______ Metric :  \n","##### EPOCH 3386 #####\n","train loss :  2920.044921875\n","test loss :  749.1702270507812  _______ Metric :  \n","##### EPOCH 3387 #####\n","train loss :  2901.884765625\n","test loss :  749.1829223632812  _______ Metric :  \n","##### EPOCH 3388 #####\n","train loss :  2916.048828125\n","test loss :  749.1995239257812  _______ Metric :  \n","##### EPOCH 3389 #####\n","train loss :  2926.009765625\n","test loss :  749.2102661132812  _______ Metric :  \n","##### EPOCH 3390 #####\n","train loss :  2908.265625\n","test loss :  749.2224731445312  _______ Metric :  \n","##### EPOCH 3391 #####\n","train loss :  2928.693359375\n","test loss :  749.2351684570312  _______ Metric :  \n","##### EPOCH 3392 #####\n","train loss :  2965.1015625\n","test loss :  749.2459106445312  _______ Metric :  \n","##### EPOCH 3393 #####\n","train loss :  2937.5859375\n","test loss :  749.2517700195312  _______ Metric :  \n","##### EPOCH 3394 #####\n","train loss :  2950.548828125\n","test loss :  749.2590942382812  _______ Metric :  \n","##### EPOCH 3395 #####\n","train loss :  2965.140625\n","test loss :  749.2644653320312  _______ Metric :  \n","##### EPOCH 3396 #####\n","train loss :  2953.201171875\n","test loss :  749.2639770507812  _______ Metric :  \n","##### EPOCH 3397 #####\n","train loss :  2930.6953125\n","test loss :  749.2620239257812  _______ Metric :  \n","##### EPOCH 3398 #####\n","train loss :  2905.3828125\n","test loss :  749.2605590820312  _______ Metric :  \n","##### EPOCH 3399 #####\n","train loss :  2911.8515625\n","test loss :  749.2600708007812  _______ Metric :  \n","##### EPOCH 3400 #####\n","train loss :  2936.703125\n","test loss :  749.2644653320312  _______ Metric :  \n","##### EPOCH 3401 #####\n","train loss :  2911.125\n","test loss :  749.2688598632812  _______ Metric :  \n","##### EPOCH 3402 #####\n","train loss :  2912.16015625\n","test loss :  749.2630004882812  _______ Metric :  \n","##### EPOCH 3403 #####\n","train loss :  2938.1875\n","test loss :  749.2503051757812  _______ Metric :  \n","##### EPOCH 3404 #####\n","train loss :  2927.46875\n","test loss :  749.2463989257812  _______ Metric :  \n","##### EPOCH 3405 #####\n","train loss :  2936.38671875\n","test loss :  749.2390747070312  _______ Metric :  \n","##### EPOCH 3406 #####\n","train loss :  2937.638671875\n","test loss :  749.2283325195312  _______ Metric :  \n","##### EPOCH 3407 #####\n","train loss :  2930.0703125\n","test loss :  749.2229614257812  _______ Metric :  \n","##### EPOCH 3408 #####\n","train loss :  2938.380859375\n","test loss :  749.2180786132812  _______ Metric :  \n","##### EPOCH 3409 #####\n","train loss :  2923.59375\n","test loss :  749.2136840820312  _______ Metric :  \n","##### EPOCH 3410 #####\n","train loss :  2959.041015625\n","test loss :  749.2136840820312  _______ Metric :  \n","##### EPOCH 3411 #####\n","train loss :  2928.2734375\n","test loss :  749.2108154296875  _______ Metric :  \n","##### EPOCH 3412 #####\n","train loss :  2886.84375\n","test loss :  749.2069091796875  _______ Metric :  \n","##### EPOCH 3413 #####\n","train loss :  2937.904296875\n","test loss :  749.2064208984375  _______ Metric :  \n","##### EPOCH 3414 #####\n","train loss :  2940.423828125\n","test loss :  749.2025146484375  _______ Metric :  \n","##### EPOCH 3415 #####\n","train loss :  2918.611328125\n","test loss :  749.2030029296875  _______ Metric :  \n","##### EPOCH 3416 #####\n","train loss :  2957.19921875\n","test loss :  749.2064208984375  _______ Metric :  \n","##### EPOCH 3417 #####\n","train loss :  2911.033203125\n","test loss :  749.2122802734375  _______ Metric :  \n","##### EPOCH 3418 #####\n","train loss :  2938.548828125\n","test loss :  749.2142333984375  _______ Metric :  \n","##### EPOCH 3419 #####\n","train loss :  2942.705078125\n","test loss :  749.2196044921875  _______ Metric :  \n","##### EPOCH 3420 #####\n","train loss :  2917.0234375\n","test loss :  749.2127685546875  _______ Metric :  \n","##### EPOCH 3421 #####\n","train loss :  2931.07421875\n","test loss :  749.2147216796875  _______ Metric :  \n","##### EPOCH 3422 #####\n","train loss :  2896.76171875\n","test loss :  749.2225341796875  _______ Metric :  \n","##### EPOCH 3423 #####\n","train loss :  2918.12890625\n","test loss :  749.2196044921875  _______ Metric :  \n","##### EPOCH 3424 #####\n","train loss :  2943.7578125\n","test loss :  749.2220458984375  _______ Metric :  \n","##### EPOCH 3425 #####\n","train loss :  2904.00390625\n","test loss :  749.2215576171875  _______ Metric :  \n","##### EPOCH 3426 #####\n","train loss :  2896.9375\n","test loss :  749.2215576171875  _______ Metric :  \n","##### EPOCH 3427 #####\n","train loss :  2931.947265625\n","test loss :  749.2249755859375  _______ Metric :  \n","##### EPOCH 3428 #####\n","train loss :  2921.783203125\n","test loss :  749.2210693359375  _______ Metric :  \n","##### EPOCH 3429 #####\n","train loss :  2915.509765625\n","test loss :  749.2200927734375  _______ Metric :  \n","##### EPOCH 3430 #####\n","train loss :  2910.767578125\n","test loss :  749.2171630859375  _______ Metric :  \n","##### EPOCH 3431 #####\n","train loss :  2907.232421875\n","test loss :  749.2117919921875  _______ Metric :  \n","##### EPOCH 3432 #####\n","train loss :  2899.134765625\n","test loss :  749.2093505859375  _______ Metric :  \n","##### EPOCH 3433 #####\n","train loss :  2905.732421875\n","test loss :  749.2064208984375  _______ Metric :  \n","##### EPOCH 3434 #####\n","train loss :  2886.572265625\n","test loss :  749.2025146484375  _______ Metric :  \n","##### EPOCH 3435 #####\n","train loss :  2938.1171875\n","test loss :  749.1942138671875  _______ Metric :  \n","##### EPOCH 3436 #####\n","train loss :  2931.353759765625\n","test loss :  749.1864013671875  _______ Metric :  \n","##### EPOCH 3437 #####\n","train loss :  2934.090087890625\n","test loss :  749.1864624023438  _______ Metric :  \n","##### EPOCH 3438 #####\n","train loss :  2919.845947265625\n","test loss :  749.1879272460938  _______ Metric :  \n","##### EPOCH 3439 #####\n","train loss :  2967.787353515625\n","test loss :  749.1928100585938  _______ Metric :  \n","##### EPOCH 3440 #####\n","train loss :  2909.041259765625\n","test loss :  749.1967163085938  _______ Metric :  \n","##### EPOCH 3441 #####\n","train loss :  2926.670166015625\n","test loss :  749.2045288085938  _______ Metric :  \n","##### EPOCH 3442 #####\n","train loss :  2952.347900390625\n","test loss :  749.2035522460938  _______ Metric :  \n","##### EPOCH 3443 #####\n","train loss :  2944.402587890625\n","test loss :  749.1976928710938  _______ Metric :  \n","##### EPOCH 3444 #####\n","train loss :  2943.722900390625\n","test loss :  749.1923217773438  _______ Metric :  \n","##### EPOCH 3445 #####\n","train loss :  2900.34228515625\n","test loss :  749.1854858398438  _______ Metric :  \n","##### EPOCH 3446 #####\n","train loss :  2949.80517578125\n","test loss :  749.1825561523438  _______ Metric :  \n","##### EPOCH 3447 #####\n","train loss :  2936.11962890625\n","test loss :  749.1781616210938  _______ Metric :  \n","##### EPOCH 3448 #####\n","train loss :  2914.92041015625\n","test loss :  749.1786499023438  _______ Metric :  \n","##### EPOCH 3449 #####\n","train loss :  2925.66064453125\n","test loss :  749.1874389648438  _______ Metric :  \n","##### EPOCH 3450 #####\n","train loss :  2907.22314453125\n","test loss :  749.1928100585938  _______ Metric :  \n","##### EPOCH 3451 #####\n","train loss :  2954.25048828125\n","test loss :  749.1859741210938  _______ Metric :  \n","##### EPOCH 3452 #####\n","train loss :  2917.44384765625\n","test loss :  749.1732788085938  _______ Metric :  \n","##### EPOCH 3453 #####\n","train loss :  2949.08642578125\n","test loss :  749.1669311523438  _______ Metric :  \n","##### EPOCH 3454 #####\n","train loss :  2933.59228515625\n","test loss :  749.1620483398438  _______ Metric :  \n","##### EPOCH 3455 #####\n","train loss :  2914.09814453125\n","test loss :  749.1610717773438  _______ Metric :  \n","##### EPOCH 3456 #####\n","train loss :  2893.24853515625\n","test loss :  749.1557006835938  _______ Metric :  \n","##### EPOCH 3457 #####\n","train loss :  2958.47900390625\n","test loss :  749.1464233398438  _______ Metric :  \n","##### EPOCH 3458 #####\n","train loss :  2963.74072265625\n","test loss :  749.1415405273438  _______ Metric :  \n","##### EPOCH 3459 #####\n","train loss :  2923.89697265625\n","test loss :  749.1307983398438  _______ Metric :  \n","##### EPOCH 3460 #####\n","train loss :  2896.93603515625\n","test loss :  749.1249389648438  _______ Metric :  \n","##### EPOCH 3461 #####\n","train loss :  2915.38134765625\n","test loss :  749.1161499023438  _______ Metric :  \n","##### EPOCH 3462 #####\n","train loss :  2947.81298828125\n","test loss :  749.1093139648438  _______ Metric :  \n","##### EPOCH 3463 #####\n","train loss :  2948.78369140625\n","test loss :  749.1093139648438  _______ Metric :  \n","##### EPOCH 3464 #####\n","train loss :  2912.71337890625\n","test loss :  749.1073608398438  _______ Metric :  \n","##### EPOCH 3465 #####\n","train loss :  2948.79150390625\n","test loss :  749.1029663085938  _______ Metric :  \n","##### EPOCH 3466 #####\n","train loss :  2920.72314453125\n","test loss :  749.1058959960938  _______ Metric :  \n","##### EPOCH 3467 #####\n","train loss :  2965.97509765625\n","test loss :  749.1058959960938  _______ Metric :  \n","##### EPOCH 3468 #####\n","train loss :  2940.64111328125\n","test loss :  749.1137084960938  _______ Metric :  \n","##### EPOCH 3469 #####\n","train loss :  2967.43603515625\n","test loss :  749.1122436523438  _______ Metric :  \n","##### EPOCH 3470 #####\n","train loss :  2929.35205078125\n","test loss :  749.1162109375  _______ Metric :  \n","##### EPOCH 3471 #####\n","train loss :  2921.30712890625\n","test loss :  749.126953125  _______ Metric :  \n","##### EPOCH 3472 #####\n","train loss :  2909.31884765625\n","test loss :  749.1318359375  _______ Metric :  \n","##### EPOCH 3473 #####\n","train loss :  2911.80517578125\n","test loss :  749.14697265625  _______ Metric :  \n","##### EPOCH 3474 #####\n","train loss :  2975.63525390625\n","test loss :  749.1611328125  _______ Metric :  \n","##### EPOCH 3475 #####\n","train loss :  2940.64111328125\n","test loss :  749.16943359375  _______ Metric :  \n","##### EPOCH 3476 #####\n","train loss :  2941.65478515625\n","test loss :  749.17333984375  _______ Metric :  \n","##### EPOCH 3477 #####\n","train loss :  2925.81298828125\n","test loss :  749.1806640625  _______ Metric :  \n","##### EPOCH 3478 #####\n","train loss :  2918.93798828125\n","test loss :  749.18359375  _______ Metric :  \n","##### EPOCH 3479 #####\n","train loss :  2951.53369140625\n","test loss :  749.17529296875  _______ Metric :  \n","##### EPOCH 3480 #####\n","train loss :  2905.47119140625\n","test loss :  749.16796875  _______ Metric :  \n","##### EPOCH 3481 #####\n","train loss :  2893.38916015625\n","test loss :  749.16162109375  _______ Metric :  \n","##### EPOCH 3482 #####\n","train loss :  2925.41845703125\n","test loss :  749.15576171875  _______ Metric :  \n","##### EPOCH 3483 #####\n","train loss :  2904.93017578125\n","test loss :  749.1484375  _______ Metric :  \n","##### EPOCH 3484 #####\n","train loss :  2915.41259765625\n","test loss :  749.14306640625  _______ Metric :  \n","##### EPOCH 3485 #####\n","train loss :  2933.19580078125\n","test loss :  749.13330078125  _______ Metric :  \n","##### EPOCH 3486 #####\n","train loss :  2926.40283203125\n","test loss :  749.12939453125  _______ Metric :  \n","##### EPOCH 3487 #####\n","train loss :  2944.10205078125\n","test loss :  749.1220703125  _______ Metric :  \n","##### EPOCH 3488 #####\n","train loss :  2931.02392578125\n","test loss :  749.1142578125  _______ Metric :  \n","##### EPOCH 3489 #####\n","train loss :  2908.85986328125\n","test loss :  749.11083984375  _______ Metric :  \n","##### EPOCH 3490 #####\n","train loss :  2950.78173828125\n","test loss :  749.10400390625  _______ Metric :  \n","##### EPOCH 3491 #####\n","train loss :  2950.99072265625\n","test loss :  749.09326171875  _______ Metric :  \n","##### EPOCH 3492 #####\n","train loss :  2886.11572265625\n","test loss :  749.0859375  _______ Metric :  \n","##### EPOCH 3493 #####\n","train loss :  2933.49072265625\n","test loss :  749.07958984375  _______ Metric :  \n","##### EPOCH 3494 #####\n","train loss :  2942.72314453125\n","test loss :  749.0732421875  _______ Metric :  \n","##### EPOCH 3495 #####\n","train loss :  2974.11376953125\n","test loss :  749.0703125  _______ Metric :  \n","##### EPOCH 3496 #####\n","train loss :  2967.02001953125\n","test loss :  749.06201171875  _______ Metric :  \n","##### EPOCH 3497 #####\n","train loss :  2898.14111328125\n","test loss :  749.0537109375  _______ Metric :  \n","##### EPOCH 3498 #####\n","train loss :  2947.89111328125\n","test loss :  749.04541015625  _______ Metric :  \n","##### EPOCH 3499 #####\n","train loss :  2923.75634765625\n","test loss :  749.0361328125  _______ Metric :  \n","##### EPOCH 3500 #####\n","train loss :  2972.90087890625\n","test loss :  749.03515625  _______ Metric :  \n","##### EPOCH 3501 #####\n","train loss :  2910.89501953125\n","test loss :  749.029296875  _______ Metric :  \n","##### EPOCH 3502 #####\n","train loss :  2911.99853515625\n","test loss :  749.0234375  _______ Metric :  \n","##### EPOCH 3503 #####\n","train loss :  2908.24267578125\n","test loss :  749.02001953125  _______ Metric :  \n","##### EPOCH 3504 #####\n","train loss :  2956.66259765625\n","test loss :  749.0205078125  _______ Metric :  \n","##### EPOCH 3505 #####\n","train loss :  2944.47900390625\n","test loss :  749.0166015625  _______ Metric :  \n","##### EPOCH 3506 #####\n","train loss :  2939.71337890625\n","test loss :  749.01611328125  _______ Metric :  \n","##### EPOCH 3507 #####\n","train loss :  2955.33251953125\n","test loss :  749.01904296875  _______ Metric :  \n","##### EPOCH 3508 #####\n","train loss :  2953.45361328125\n","test loss :  749.0166015625  _______ Metric :  \n","##### EPOCH 3509 #####\n","train loss :  2935.39501953125\n","test loss :  749.01611328125  _______ Metric :  \n","##### EPOCH 3510 #####\n","train loss :  2917.55517578125\n","test loss :  749.0112915039062  _______ Metric :  \n","##### EPOCH 3511 #####\n","train loss :  2924.05126953125\n","test loss :  749.0093383789062  _______ Metric :  \n","##### EPOCH 3512 #####\n","train loss :  2922.46728515625\n","test loss :  749.0103149414062  _______ Metric :  \n","##### EPOCH 3513 #####\n","train loss :  2916.52978515625\n","test loss :  749.0152587890625  _______ Metric :  \n","##### EPOCH 3514 #####\n","train loss :  2927.12548828125\n","test loss :  749.0201416015625  _______ Metric :  \n","##### EPOCH 3515 #####\n","train loss :  2941.21533203125\n","test loss :  749.0294189453125  _______ Metric :  \n","##### EPOCH 3516 #####\n","train loss :  2941.27392578125\n","test loss :  749.0299072265625  _______ Metric :  \n","##### EPOCH 3517 #####\n","train loss :  2946.86181640625\n","test loss :  749.0333251953125  _______ Metric :  \n","##### EPOCH 3518 #####\n","train loss :  2887.80908203125\n","test loss :  749.0406494140625  _______ Metric :  \n","##### EPOCH 3519 #####\n","train loss :  2990.06689453125\n","test loss :  749.0430908203125  _______ Metric :  \n","##### EPOCH 3520 #####\n","train loss :  2926.02001953125\n","test loss :  749.0474853515625  _______ Metric :  \n","##### EPOCH 3521 #####\n","train loss :  2905.99267578125\n","test loss :  749.0499267578125  _______ Metric :  \n","##### EPOCH 3522 #####\n","train loss :  2946.40478515625\n","test loss :  749.0548095703125  _______ Metric :  \n","##### EPOCH 3523 #####\n","train loss :  2911.62548828125\n","test loss :  749.0513916015625  _______ Metric :  \n","##### EPOCH 3524 #####\n","train loss :  2921.09619140625\n","test loss :  749.0504150390625  _______ Metric :  \n","##### EPOCH 3525 #####\n","train loss :  2915.85205078125\n","test loss :  749.0411376953125  _______ Metric :  \n","##### EPOCH 3526 #####\n","train loss :  2911.45361328125\n","test loss :  749.0416259765625  _______ Metric :  \n","##### EPOCH 3527 #####\n","train loss :  2902.06298828125\n","test loss :  749.0469970703125  _______ Metric :  \n","##### EPOCH 3528 #####\n","train loss :  2983.74462890625\n","test loss :  749.0426025390625  _______ Metric :  \n","##### EPOCH 3529 #####\n","train loss :  2946.06103515625\n","test loss :  749.0421142578125  _______ Metric :  \n","##### EPOCH 3530 #####\n","train loss :  2946.61572265625\n","test loss :  749.0367431640625  _______ Metric :  \n","##### EPOCH 3531 #####\n","train loss :  2881.40673828125\n","test loss :  749.0313720703125  _______ Metric :  \n","##### EPOCH 3532 #####\n","train loss :  2943.13134765625\n","test loss :  749.0328369140625  _______ Metric :  \n","##### EPOCH 3533 #####\n","train loss :  2936.64501953125\n","test loss :  749.0250244140625  _______ Metric :  \n","##### EPOCH 3534 #####\n","train loss :  2934.10009765625\n","test loss :  749.0196533203125  _______ Metric :  \n","##### EPOCH 3535 #####\n","train loss :  2897.56884765625\n","test loss :  749.0128173828125  _______ Metric :  \n","##### EPOCH 3536 #####\n","train loss :  2936.94384765625\n","test loss :  749.0059814453125  _______ Metric :  \n","##### EPOCH 3537 #####\n","train loss :  2963.99072265625\n","test loss :  748.9962158203125  _______ Metric :  \n","##### EPOCH 3538 #####\n","train loss :  2940.21337890625\n","test loss :  748.9893798828125  _______ Metric :  \n","##### EPOCH 3539 #####\n","train loss :  2950.81884765625\n","test loss :  748.9830322265625  _______ Metric :  \n","##### EPOCH 3540 #####\n","train loss :  2936.94775390625\n","test loss :  748.9801025390625  _______ Metric :  \n","##### EPOCH 3541 #####\n","train loss :  2909.31103515625\n","test loss :  748.9844970703125  _______ Metric :  \n","##### EPOCH 3542 #####\n","train loss :  2931.99072265625\n","test loss :  748.9776611328125  _______ Metric :  \n","##### EPOCH 3543 #####\n","train loss :  2915.01611328125\n","test loss :  748.9722900390625  _______ Metric :  \n","##### EPOCH 3544 #####\n","train loss :  2921.64697265625\n","test loss :  748.9698486328125  _______ Metric :  \n","##### EPOCH 3545 #####\n","train loss :  2948.66064453125\n","test loss :  748.9644775390625  _______ Metric :  \n","##### EPOCH 3546 #####\n","train loss :  2953.19384765625\n","test loss :  748.9610595703125  _______ Metric :  \n","##### EPOCH 3547 #####\n","train loss :  2969.71337890625\n","test loss :  748.9561767578125  _______ Metric :  \n","##### EPOCH 3548 #####\n","train loss :  2913.27587890625\n","test loss :  748.9512939453125  _______ Metric :  \n","##### EPOCH 3549 #####\n","train loss :  2982.75634765625\n","test loss :  748.9483642578125  _______ Metric :  \n","##### EPOCH 3550 #####\n","train loss :  2930.18798828125\n","test loss :  748.9468994140625  _______ Metric :  \n","##### EPOCH 3551 #####\n","train loss :  2959.91650390625\n","test loss :  748.9400634765625  _______ Metric :  \n","##### EPOCH 3552 #####\n","train loss :  2944.52392578125\n","test loss :  748.9420166015625  _______ Metric :  \n","##### EPOCH 3553 #####\n","train loss :  2927.60986328125\n","test loss :  748.9410400390625  _______ Metric :  \n","##### EPOCH 3554 #####\n","train loss :  2964.74462890625\n","test loss :  748.9410400390625  _______ Metric :  \n","##### EPOCH 3555 #####\n","train loss :  2930.42822265625\n","test loss :  748.9395751953125  _______ Metric :  \n","##### EPOCH 3556 #####\n","train loss :  2930.57666015625\n","test loss :  748.9444580078125  _______ Metric :  \n","##### EPOCH 3557 #####\n","train loss :  2894.00634765625\n","test loss :  748.9468994140625  _______ Metric :  \n","##### EPOCH 3558 #####\n","train loss :  2968.70556640625\n","test loss :  748.9468994140625  _______ Metric :  \n","##### EPOCH 3559 #####\n","train loss :  2930.05322265625\n","test loss :  748.9493408203125  _______ Metric :  \n","##### EPOCH 3560 #####\n","train loss :  2930.74267578125\n","test loss :  748.9542236328125  _______ Metric :  \n","##### EPOCH 3561 #####\n","train loss :  2945.43603515625\n","test loss :  748.9576416015625  _______ Metric :  \n","##### EPOCH 3562 #####\n","train loss :  2940.16259765625\n","test loss :  748.9547119140625  _______ Metric :  \n","##### EPOCH 3563 #####\n","train loss :  2918.60595703125\n","test loss :  748.9512939453125  _______ Metric :  \n","##### EPOCH 3564 #####\n","train loss :  2931.31884765625\n","test loss :  748.9512939453125  _______ Metric :  \n","##### EPOCH 3565 #####\n","train loss :  2924.75048828125\n","test loss :  748.9478759765625  _______ Metric :  \n","##### EPOCH 3566 #####\n","train loss :  2965.38330078125\n","test loss :  748.9439697265625  _______ Metric :  \n","##### EPOCH 3567 #####\n","train loss :  2953.40283203125\n","test loss :  748.9332275390625  _______ Metric :  \n","##### EPOCH 3568 #####\n","train loss :  2917.70361328125\n","test loss :  748.9259033203125  _______ Metric :  \n","##### EPOCH 3569 #####\n","train loss :  2936.02001953125\n","test loss :  748.9156494140625  _______ Metric :  \n","##### EPOCH 3570 #####\n","train loss :  2920.70751953125\n","test loss :  748.9093017578125  _______ Metric :  \n","##### EPOCH 3571 #####\n","train loss :  2918.30322265625\n","test loss :  748.9010009765625  _______ Metric :  \n","##### EPOCH 3572 #####\n","train loss :  2954.04541015625\n","test loss :  748.8873291015625  _______ Metric :  \n","##### EPOCH 3573 #####\n","train loss :  2926.08251953125\n","test loss :  748.8751220703125  _______ Metric :  \n","##### EPOCH 3574 #####\n","train loss :  2932.93408203125\n","test loss :  748.8721923828125  _______ Metric :  \n","##### EPOCH 3575 #####\n","train loss :  2954.29541015625\n","test loss :  748.8643798828125  _______ Metric :  \n","##### EPOCH 3576 #####\n","train loss :  2953.23876953125\n","test loss :  748.8507080078125  _______ Metric :  \n","##### EPOCH 3577 #####\n","train loss :  2921.27197265625\n","test loss :  748.8453369140625  _______ Metric :  \n","##### EPOCH 3578 #####\n","train loss :  2959.24267578125\n","test loss :  748.8409423828125  _______ Metric :  \n","##### EPOCH 3579 #####\n","train loss :  2950.37353515625\n","test loss :  748.8389892578125  _______ Metric :  \n","##### EPOCH 3580 #####\n","train loss :  2907.16455078125\n","test loss :  748.8345947265625  _______ Metric :  \n","##### EPOCH 3581 #####\n","train loss :  2910.07666015625\n","test loss :  748.8302001953125  _______ Metric :  \n","##### EPOCH 3582 #####\n","train loss :  2935.23095703125\n","test loss :  748.8258056640625  _______ Metric :  \n","##### EPOCH 3583 #####\n","train loss :  2911.46533203125\n","test loss :  748.8282470703125  _______ Metric :  \n","##### EPOCH 3584 #####\n","train loss :  2933.38720703125\n","test loss :  748.8282470703125  _______ Metric :  \n","##### EPOCH 3585 #####\n","train loss :  2937.70751953125\n","test loss :  748.8267822265625  _______ Metric :  \n","##### EPOCH 3586 #####\n","train loss :  2920.96728515625\n","test loss :  748.8233642578125  _______ Metric :  \n","##### EPOCH 3587 #####\n","train loss :  2882.19775390625\n","test loss :  748.8238525390625  _______ Metric :  \n","##### EPOCH 3588 #####\n","train loss :  2932.39892578125\n","test loss :  748.8253173828125  _______ Metric :  \n","##### EPOCH 3589 #####\n","train loss :  2925.14892578125\n","test loss :  748.8126220703125  _______ Metric :  \n","##### EPOCH 3590 #####\n","train loss :  2937.16845703125\n","test loss :  748.8131103515625  _______ Metric :  \n","##### EPOCH 3591 #####\n","train loss :  2917.61572265625\n","test loss :  748.8062744140625  _______ Metric :  \n","##### EPOCH 3592 #####\n","train loss :  2895.95556640625\n","test loss :  748.8106689453125  _______ Metric :  \n","##### EPOCH 3593 #####\n","train loss :  2934.19970703125\n","test loss :  748.8048095703125  _______ Metric :  \n","##### EPOCH 3594 #####\n","train loss :  2868.19384765625\n","test loss :  748.8033447265625  _______ Metric :  \n","##### EPOCH 3595 #####\n","train loss :  2910.94384765625\n","test loss :  748.8038330078125  _______ Metric :  \n","##### EPOCH 3596 #####\n","train loss :  2926.15869140625\n","test loss :  748.8009033203125  _______ Metric :  \n","##### EPOCH 3597 #####\n","train loss :  2966.32861328125\n","test loss :  748.7980346679688  _______ Metric :  \n","##### EPOCH 3598 #####\n","train loss :  2975.18408203125\n","test loss :  748.8009643554688  _______ Metric :  \n","##### EPOCH 3599 #####\n","train loss :  2917.30126953125\n","test loss :  748.8038940429688  _______ Metric :  \n","##### EPOCH 3600 #####\n","train loss :  2949.63720703125\n","test loss :  748.8092651367188  _______ Metric :  \n","##### EPOCH 3601 #####\n","train loss :  2951.71923828125\n","test loss :  748.8244018554688  _______ Metric :  \n","##### EPOCH 3602 #####\n","train loss :  2890.51416015625\n","test loss :  748.8385620117188  _______ Metric :  \n","##### EPOCH 3603 #####\n","train loss :  2956.17041015625\n","test loss :  748.8532104492188  _______ Metric :  \n","##### EPOCH 3604 #####\n","train loss :  2919.42041015625\n","test loss :  748.8776245117188  _______ Metric :  \n","##### EPOCH 3605 #####\n","train loss :  2908.27587890625\n","test loss :  748.8927612304688  _______ Metric :  \n","##### EPOCH 3606 #####\n","train loss :  2917.01611328125\n","test loss :  748.9039916992188  _______ Metric :  \n","##### EPOCH 3607 #####\n","train loss :  2938.78759765625\n","test loss :  748.9093627929688  _______ Metric :  \n","##### EPOCH 3608 #####\n","train loss :  2881.81103515625\n","test loss :  748.9157104492188  _______ Metric :  \n","##### EPOCH 3609 #####\n","train loss :  2938.55908203125\n","test loss :  748.9186401367188  _______ Metric :  \n","##### EPOCH 3610 #####\n","train loss :  2914.41650390625\n","test loss :  748.9166870117188  _______ Metric :  \n","##### EPOCH 3611 #####\n","train loss :  2908.60595703125\n","test loss :  748.9103393554688  _______ Metric :  \n","##### EPOCH 3612 #####\n","train loss :  2982.25830078125\n","test loss :  748.9005737304688  _______ Metric :  \n","##### EPOCH 3613 #####\n","train loss :  2932.19580078125\n","test loss :  748.9015502929688  _______ Metric :  \n","##### EPOCH 3614 #####\n","train loss :  2934.13134765625\n","test loss :  748.8932495117188  _______ Metric :  \n","##### EPOCH 3615 #####\n","train loss :  2930.28759765625\n","test loss :  748.8956909179688  _______ Metric :  \n","##### EPOCH 3616 #####\n","train loss :  2944.23486328125\n","test loss :  748.8937377929688  _______ Metric :  \n","##### EPOCH 3617 #####\n","train loss :  2921.27587890625\n","test loss :  748.8917846679688  _______ Metric :  \n","##### EPOCH 3618 #####\n","train loss :  2947.56298828125\n","test loss :  748.8898315429688  _______ Metric :  \n","##### EPOCH 3619 #####\n","train loss :  2980.203857421875\n","test loss :  748.8844604492188  _______ Metric :  \n","##### EPOCH 3620 #####\n","train loss :  2926.006591796875\n","test loss :  748.8746948242188  _______ Metric :  \n","##### EPOCH 3621 #####\n","train loss :  2911.617919921875\n","test loss :  748.8707885742188  _______ Metric :  \n","##### EPOCH 3622 #####\n","train loss :  2931.606201171875\n","test loss :  748.8590698242188  _______ Metric :  \n","##### EPOCH 3623 #####\n","train loss :  2946.293701171875\n","test loss :  748.8424682617188  _______ Metric :  \n","##### EPOCH 3624 #####\n","train loss :  2944.227294921875\n","test loss :  748.8366088867188  _______ Metric :  \n","##### EPOCH 3625 #####\n","train loss :  2948.783935546875\n","test loss :  748.8239135742188  _______ Metric :  \n","##### EPOCH 3626 #####\n","train loss :  2913.764404296875\n","test loss :  748.8175659179688  _______ Metric :  \n","##### EPOCH 3627 #####\n","train loss :  2892.276123046875\n","test loss :  748.8019409179688  _______ Metric :  \n","##### EPOCH 3628 #####\n","train loss :  2927.914794921875\n","test loss :  748.7960815429688  _______ Metric :  \n","##### EPOCH 3629 #####\n","train loss :  2892.877685546875\n","test loss :  748.7828979492188  _______ Metric :  \n","##### EPOCH 3630 #####\n","train loss :  2919.918701171875\n","test loss :  748.7765502929688  _______ Metric :  \n","##### EPOCH 3631 #####\n","train loss :  2916.039794921875\n","test loss :  748.7687377929688  _______ Metric :  \n","##### EPOCH 3632 #####\n","train loss :  2908.268310546875\n","test loss :  748.7619018554688  _______ Metric :  \n","##### EPOCH 3633 #####\n","train loss :  2929.301513671875\n","test loss :  748.7511596679688  _______ Metric :  \n","##### EPOCH 3634 #####\n","train loss :  2924.703857421875\n","test loss :  748.7501831054688  _______ Metric :  \n","##### EPOCH 3635 #####\n","train loss :  2944.682373046875\n","test loss :  748.7443237304688  _______ Metric :  \n","##### EPOCH 3636 #####\n","train loss :  2950.653076171875\n","test loss :  748.7389526367188  _______ Metric :  \n","##### EPOCH 3637 #####\n","train loss :  2930.076904296875\n","test loss :  748.7360229492188  _______ Metric :  \n","##### EPOCH 3638 #####\n","train loss :  2933.235107421875\n","test loss :  748.7267456054688  _______ Metric :  \n","##### EPOCH 3639 #####\n","train loss :  2919.992919921875\n","test loss :  748.7267456054688  _______ Metric :  \n","##### EPOCH 3640 #####\n","train loss :  2933.244873046875\n","test loss :  748.7286987304688  _______ Metric :  \n","##### EPOCH 3641 #####\n","train loss :  2958.207763671875\n","test loss :  748.7306518554688  _______ Metric :  \n","##### EPOCH 3642 #####\n","train loss :  2944.256591796875\n","test loss :  748.7340698242188  _______ Metric :  \n","##### EPOCH 3643 #####\n","train loss :  2929.502685546875\n","test loss :  748.7365112304688  _______ Metric :  \n","##### EPOCH 3644 #####\n","train loss :  2923.942138671875\n","test loss :  748.7306518554688  _______ Metric :  \n","##### EPOCH 3645 #####\n","train loss :  2925.621826171875\n","test loss :  748.7252807617188  _______ Metric :  \n","##### EPOCH 3646 #####\n","train loss :  2924.369873046875\n","test loss :  748.7238159179688  _______ Metric :  \n","##### EPOCH 3647 #####\n","train loss :  2950.516357421875\n","test loss :  748.723876953125  _______ Metric :  \n","##### EPOCH 3648 #####\n","train loss :  2953.494873046875\n","test loss :  748.722412109375  _______ Metric :  \n","##### EPOCH 3649 #####\n","train loss :  2927.637451171875\n","test loss :  748.726806640625  _______ Metric :  \n","##### EPOCH 3650 #####\n","train loss :  2936.045654296875\n","test loss :  748.732666015625  _______ Metric :  \n","##### EPOCH 3651 #####\n","train loss :  2925.865966796875\n","test loss :  748.741455078125  _______ Metric :  \n","##### EPOCH 3652 #####\n","train loss :  2952.373779296875\n","test loss :  748.745361328125  _______ Metric :  \n","##### EPOCH 3653 #####\n","train loss :  2944.123779296875\n","test loss :  748.752685546875  _______ Metric :  \n","##### EPOCH 3654 #####\n","train loss :  2947.317138671875\n","test loss :  748.756591796875  _______ Metric :  \n","##### EPOCH 3655 #####\n","train loss :  2949.487060546875\n","test loss :  748.761962890625  _______ Metric :  \n","##### EPOCH 3656 #####\n","train loss :  2945.983154296875\n","test loss :  748.769287109375  _______ Metric :  \n","##### EPOCH 3657 #####\n","train loss :  2931.992919921875\n","test loss :  748.770263671875  _______ Metric :  \n","##### EPOCH 3658 #####\n","train loss :  2958.449951171875\n","test loss :  748.766357421875  _______ Metric :  \n","##### EPOCH 3659 #####\n","train loss :  2965.096435546875\n","test loss :  748.768310546875  _______ Metric :  \n","##### EPOCH 3660 #####\n","train loss :  2907.024169921875\n","test loss :  748.763916015625  _______ Metric :  \n","##### EPOCH 3661 #####\n","train loss :  2934.356201171875\n","test loss :  748.764404296875  _______ Metric :  \n","##### EPOCH 3662 #####\n","train loss :  2924.155029296875\n","test loss :  748.766845703125  _______ Metric :  \n","##### EPOCH 3663 #####\n","train loss :  2953.633544921875\n","test loss :  748.768798828125  _______ Metric :  \n","##### EPOCH 3664 #####\n","train loss :  2969.662841796875\n","test loss :  748.768798828125  _______ Metric :  \n","##### EPOCH 3665 #####\n","train loss :  2931.207763671875\n","test loss :  748.770263671875  _______ Metric :  \n","##### EPOCH 3666 #####\n","train loss :  2952.293701171875\n","test loss :  748.767822265625  _______ Metric :  \n","##### EPOCH 3667 #####\n","train loss :  2906.676513671875\n","test loss :  748.771728515625  _______ Metric :  \n","##### EPOCH 3668 #####\n","train loss :  2923.334716796875\n","test loss :  748.769775390625  _______ Metric :  \n","##### EPOCH 3669 #####\n","train loss :  2914.227294921875\n","test loss :  748.767822265625  _______ Metric :  \n","##### EPOCH 3670 #####\n","train loss :  2954.629638671875\n","test loss :  748.758544921875  _______ Metric :  \n","##### EPOCH 3671 #####\n","train loss :  2960.088623046875\n","test loss :  748.750244140625  _______ Metric :  \n","##### EPOCH 3672 #####\n","train loss :  2898.350341796875\n","test loss :  748.747314453125  _______ Metric :  \n","##### EPOCH 3673 #####\n","train loss :  2905.670654296875\n","test loss :  748.742431640625  _______ Metric :  \n","##### EPOCH 3674 #####\n","train loss :  2929.963623046875\n","test loss :  748.734619140625  _______ Metric :  \n","##### EPOCH 3675 #####\n","train loss :  2937.668701171875\n","test loss :  748.722412109375  _______ Metric :  \n","##### EPOCH 3676 #####\n","train loss :  2945.5126953125\n","test loss :  748.718017578125  _______ Metric :  \n","##### EPOCH 3677 #####\n","train loss :  2943.0146484375\n","test loss :  748.711181640625  _______ Metric :  \n","##### EPOCH 3678 #####\n","train loss :  2960.7958984375\n","test loss :  748.703857421875  _______ Metric :  \n","##### EPOCH 3679 #####\n","train loss :  2950.1533203125\n","test loss :  748.701416015625  _______ Metric :  \n","##### EPOCH 3680 #####\n","train loss :  2941.8017578125\n","test loss :  748.700439453125  _______ Metric :  \n","##### EPOCH 3681 #####\n","train loss :  2914.9833984375\n","test loss :  748.702392578125  _______ Metric :  \n","##### EPOCH 3682 #####\n","train loss :  2907.7861328125\n","test loss :  748.709716796875  _______ Metric :  \n","##### EPOCH 3683 #####\n","train loss :  2929.4443359375\n","test loss :  748.706298828125  _______ Metric :  \n","##### EPOCH 3684 #####\n","train loss :  2933.0693359375\n","test loss :  748.7078247070312  _______ Metric :  \n","##### EPOCH 3685 #####\n","train loss :  2910.7568359375\n","test loss :  748.7117309570312  _______ Metric :  \n","##### EPOCH 3686 #####\n","train loss :  2948.9853515625\n","test loss :  748.7166137695312  _______ Metric :  \n","##### EPOCH 3687 #####\n","train loss :  2963.7607421875\n","test loss :  748.7239379882812  _______ Metric :  \n","##### EPOCH 3688 #####\n","train loss :  2952.5400390625\n","test loss :  748.7263793945312  _______ Metric :  \n","##### EPOCH 3689 #####\n","train loss :  2929.0791015625\n","test loss :  748.7293090820312  _______ Metric :  \n","##### EPOCH 3690 #####\n","train loss :  2936.3388671875\n","test loss :  748.7376098632812  _______ Metric :  \n","##### EPOCH 3691 #####\n","train loss :  2968.0791015625\n","test loss :  748.7463989257812  _______ Metric :  \n","##### EPOCH 3692 #####\n","train loss :  2903.3193359375\n","test loss :  748.7517700195312  _______ Metric :  \n","##### EPOCH 3693 #####\n","train loss :  2920.4951171875\n","test loss :  748.7630004882812  _______ Metric :  \n","##### EPOCH 3694 #####\n","train loss :  2932.3583984375\n","test loss :  748.7703247070312  _______ Metric :  \n","##### EPOCH 3695 #####\n","train loss :  2913.8115234375\n","test loss :  748.7805786132812  _______ Metric :  \n","##### EPOCH 3696 #####\n","train loss :  2928.2548828125\n","test loss :  748.7766723632812  _______ Metric :  \n","##### EPOCH 3697 #####\n","train loss :  2962.5654296875\n","test loss :  748.7805786132812  _______ Metric :  \n","##### EPOCH 3698 #####\n","train loss :  2922.5537109375\n","test loss :  748.7835083007812  _______ Metric :  \n","##### EPOCH 3699 #####\n","train loss :  2948.8173828125\n","test loss :  748.7756958007812  _______ Metric :  \n","##### EPOCH 3700 #####\n","train loss :  2939.9541015625\n","test loss :  748.7742309570312  _______ Metric :  \n","##### EPOCH 3701 #####\n","train loss :  2914.4013671875\n","test loss :  748.7781372070312  _______ Metric :  \n","##### EPOCH 3702 #####\n","train loss :  2931.4697265625\n","test loss :  748.7854614257812  _______ Metric :  \n","##### EPOCH 3703 #####\n","train loss :  2905.7822265625\n","test loss :  748.7883911132812  _______ Metric :  \n","##### EPOCH 3704 #####\n","train loss :  2929.0107421875\n","test loss :  748.7839965820312  _______ Metric :  \n","##### EPOCH 3705 #####\n","train loss :  2923.2412109375\n","test loss :  748.7839965820312  _______ Metric :  \n","##### EPOCH 3706 #####\n","train loss :  2960.0048828125\n","test loss :  748.7864379882812  _______ Metric :  \n","##### EPOCH 3707 #####\n","train loss :  2918.2333984375\n","test loss :  748.7879028320312  _______ Metric :  \n","##### EPOCH 3708 #####\n","train loss :  2982.4677734375\n","test loss :  748.7947387695312  _______ Metric :  \n","##### EPOCH 3709 #####\n","train loss :  2942.9501953125\n","test loss :  748.7991333007812  _______ Metric :  \n","##### EPOCH 3710 #####\n","train loss :  2934.4326171875\n","test loss :  748.8025512695312  _______ Metric :  \n","##### EPOCH 3711 #####\n","train loss :  2989.5380859375\n","test loss :  748.8020629882812  _______ Metric :  \n","##### EPOCH 3712 #####\n","train loss :  2920.4833984375\n","test loss :  748.7893676757812  _______ Metric :  \n","##### EPOCH 3713 #####\n","train loss :  2949.0205078125\n","test loss :  748.7815551757812  _______ Metric :  \n","##### EPOCH 3714 #####\n","train loss :  2913.6181640625\n","test loss :  748.7649536132812  _______ Metric :  \n","##### EPOCH 3715 #####\n","train loss :  2944.9541015625\n","test loss :  748.7522583007812  _______ Metric :  \n","##### EPOCH 3716 #####\n","train loss :  2904.6494140625\n","test loss :  748.7337036132812  _______ Metric :  \n","##### EPOCH 3717 #####\n","train loss :  2962.8193359375\n","test loss :  748.7214965820312  _______ Metric :  \n","##### EPOCH 3718 #####\n","train loss :  2900.5693359375\n","test loss :  748.7122192382812  _______ Metric :  \n","##### EPOCH 3719 #####\n","train loss :  2929.2001953125\n","test loss :  748.7048950195312  _______ Metric :  \n","##### EPOCH 3720 #####\n","train loss :  2944.7666015625\n","test loss :  748.7000122070312  _______ Metric :  \n","##### EPOCH 3721 #####\n","train loss :  2990.9716796875\n","test loss :  748.6946411132812  _______ Metric :  \n","##### EPOCH 3722 #####\n","train loss :  2954.0009765625\n","test loss :  748.6946411132812  _______ Metric :  \n","##### EPOCH 3723 #####\n","train loss :  2934.9931640625\n","test loss :  748.6970825195312  _______ Metric :  \n","##### EPOCH 3724 #####\n","train loss :  2939.4931640625\n","test loss :  748.6956176757812  _______ Metric :  \n","##### EPOCH 3725 #####\n","train loss :  2957.8251953125\n","test loss :  748.6985473632812  _______ Metric :  \n","##### EPOCH 3726 #####\n","train loss :  2916.1728515625\n","test loss :  748.7029418945312  _______ Metric :  \n","##### EPOCH 3727 #####\n","train loss :  2966.2509765625\n","test loss :  748.7058715820312  _______ Metric :  \n","##### EPOCH 3728 #####\n","train loss :  2939.2978515625\n","test loss :  748.7068481445312  _______ Metric :  \n","##### EPOCH 3729 #####\n","train loss :  2920.3486328125\n","test loss :  748.7039184570312  _______ Metric :  \n","##### EPOCH 3730 #####\n","train loss :  2953.4013671875\n","test loss :  748.6995239257812  _______ Metric :  \n","##### EPOCH 3731 #####\n","train loss :  2928.7138671875\n","test loss :  748.6941528320312  _______ Metric :  \n","##### EPOCH 3732 #####\n","train loss :  2921.3994140625\n","test loss :  748.6809692382812  _______ Metric :  \n","##### EPOCH 3733 #####\n","train loss :  2943.7216796875\n","test loss :  748.6741333007812  _______ Metric :  \n","##### EPOCH 3734 #####\n","train loss :  2906.8251953125\n","test loss :  748.6668090820312  _______ Metric :  \n","##### EPOCH 3735 #####\n","train loss :  2876.7333984375\n","test loss :  748.6619262695312  _______ Metric :  \n","##### EPOCH 3736 #####\n","train loss :  2919.0654296875\n","test loss :  748.6467895507812  _______ Metric :  \n","##### EPOCH 3737 #####\n","train loss :  2949.0888671875\n","test loss :  748.6375122070312  _______ Metric :  \n","##### EPOCH 3738 #####\n","train loss :  2918.9130859375\n","test loss :  748.6233520507812  _______ Metric :  \n","##### EPOCH 3739 #####\n","train loss :  2951.6240234375\n","test loss :  748.6091918945312  _______ Metric :  \n","##### EPOCH 3740 #####\n","train loss :  2917.2255859375\n","test loss :  748.6008911132812  _______ Metric :  \n","##### EPOCH 3741 #####\n","train loss :  2923.8369140625\n","test loss :  748.5989379882812  _______ Metric :  \n","##### EPOCH 3742 #####\n","train loss :  2870.8388671875\n","test loss :  748.6057739257812  _______ Metric :  \n","##### EPOCH 3743 #####\n","train loss :  2942.7529296875\n","test loss :  748.6047973632812  _______ Metric :  \n","##### EPOCH 3744 #####\n","train loss :  2947.7138671875\n","test loss :  748.5979614257812  _______ Metric :  \n","##### EPOCH 3745 #####\n","train loss :  2951.0869140625\n","test loss :  748.5945434570312  _______ Metric :  \n","##### EPOCH 3746 #####\n","train loss :  2937.5458984375\n","test loss :  748.5901489257812  _______ Metric :  \n","##### EPOCH 3747 #####\n","train loss :  2897.2451171875\n","test loss :  748.5950317382812  _______ Metric :  \n","##### EPOCH 3748 #####\n","train loss :  2927.1435546875\n","test loss :  748.5969848632812  _______ Metric :  \n","##### EPOCH 3749 #####\n","train loss :  2960.8349609375\n","test loss :  748.6033325195312  _______ Metric :  \n","##### EPOCH 3750 #####\n","train loss :  2915.2939453125\n","test loss :  748.6038208007812  _______ Metric :  \n","##### EPOCH 3751 #####\n","train loss :  2947.1806640625\n","test loss :  748.6028442382812  _______ Metric :  \n","##### EPOCH 3752 #####\n","train loss :  2943.4638671875\n","test loss :  748.6057739257812  _______ Metric :  \n","##### EPOCH 3753 #####\n","train loss :  2942.9560546875\n","test loss :  748.6047973632812  _______ Metric :  \n","##### EPOCH 3754 #####\n","train loss :  2917.4052734375\n","test loss :  748.6043090820312  _______ Metric :  \n","##### EPOCH 3755 #####\n","train loss :  2935.3720703125\n","test loss :  748.6091918945312  _______ Metric :  \n","##### EPOCH 3756 #####\n","train loss :  2935.3173828125\n","test loss :  748.6130981445312  _______ Metric :  \n","##### EPOCH 3757 #####\n","train loss :  2914.5810546875\n","test loss :  748.6126098632812  _______ Metric :  \n","##### EPOCH 3758 #####\n","train loss :  2925.8447265625\n","test loss :  748.6126098632812  _______ Metric :  \n","##### EPOCH 3759 #####\n","train loss :  2926.2294921875\n","test loss :  748.6047973632812  _______ Metric :  \n","##### EPOCH 3760 #####\n","train loss :  2956.9228515625\n","test loss :  748.6008911132812  _______ Metric :  \n","##### EPOCH 3761 #####\n","train loss :  2948.5966796875\n","test loss :  748.5857543945312  _______ Metric :  \n","##### EPOCH 3762 #####\n","train loss :  2975.6591796875\n","test loss :  748.5720825195312  _______ Metric :  \n","##### EPOCH 3763 #####\n","train loss :  2946.0126953125\n","test loss :  748.5608520507812  _______ Metric :  \n","##### EPOCH 3764 #####\n","train loss :  2970.7333984375\n","test loss :  748.5462036132812  _______ Metric :  \n","##### EPOCH 3765 #####\n","train loss :  2929.9755859375\n","test loss :  748.5325317382812  _______ Metric :  \n","##### EPOCH 3766 #####\n","train loss :  2942.5205078125\n","test loss :  748.5252075195312  _______ Metric :  \n","##### EPOCH 3767 #####\n","train loss :  2917.1923828125\n","test loss :  748.5149536132812  _______ Metric :  \n","##### EPOCH 3768 #####\n","train loss :  2912.2900390625\n","test loss :  748.5042114257812  _______ Metric :  \n","##### EPOCH 3769 #####\n","train loss :  2932.4833984375\n","test loss :  748.4910278320312  _______ Metric :  \n","##### EPOCH 3770 #####\n","train loss :  2927.4443359375\n","test loss :  748.4783325195312  _______ Metric :  \n","##### EPOCH 3771 #####\n","train loss :  2920.0751953125\n","test loss :  748.4729614257812  _______ Metric :  \n","##### EPOCH 3772 #####\n","train loss :  2924.0419921875\n","test loss :  748.4666137695312  _______ Metric :  \n","##### EPOCH 3773 #####\n","train loss :  2912.3212890625\n","test loss :  748.4607543945312  _______ Metric :  \n","##### EPOCH 3774 #####\n","train loss :  2938.6611328125\n","test loss :  748.4461059570312  _______ Metric :  \n","##### EPOCH 3775 #####\n","train loss :  2941.7158203125\n","test loss :  748.4343872070312  _______ Metric :  \n","##### EPOCH 3776 #####\n","train loss :  2982.4384765625\n","test loss :  748.4251098632812  _______ Metric :  \n","##### EPOCH 3777 #####\n","train loss :  2949.7119140625\n","test loss :  748.4163208007812  _______ Metric :  \n","##### EPOCH 3778 #####\n","train loss :  2925.4990234375\n","test loss :  748.4148559570312  _______ Metric :  \n","##### EPOCH 3779 #####\n","train loss :  2945.6259765625\n","test loss :  748.4060668945312  _______ Metric :  \n","##### EPOCH 3780 #####\n","train loss :  2893.1572265625\n","test loss :  748.4026489257812  _______ Metric :  \n","##### EPOCH 3781 #####\n","train loss :  2903.7099609375\n","test loss :  748.4006958007812  _______ Metric :  \n","##### EPOCH 3782 #####\n","train loss :  2880.7685546875\n","test loss :  748.3977661132812  _______ Metric :  \n","##### EPOCH 3783 #####\n","train loss :  2952.2080078125\n","test loss :  748.3997192382812  _______ Metric :  \n","##### EPOCH 3784 #####\n","train loss :  2909.6181640625\n","test loss :  748.3938598632812  _______ Metric :  \n","##### EPOCH 3785 #####\n","train loss :  2929.4560546875\n","test loss :  748.3928833007812  _______ Metric :  \n","##### EPOCH 3786 #####\n","train loss :  2928.2490234375\n","test loss :  748.3967895507812  _______ Metric :  \n","##### EPOCH 3787 #####\n","train loss :  2942.6474609375\n","test loss :  748.3997192382812  _______ Metric :  \n","##### EPOCH 3788 #####\n","train loss :  2961.3681640625\n","test loss :  748.4031372070312  _______ Metric :  \n","##### EPOCH 3789 #####\n","train loss :  2893.8662109375\n","test loss :  748.3997192382812  _______ Metric :  \n","##### EPOCH 3790 #####\n","train loss :  2919.4697265625\n","test loss :  748.4041137695312  _______ Metric :  \n","##### EPOCH 3791 #####\n","train loss :  2940.2138671875\n","test loss :  748.4089965820312  _______ Metric :  \n","##### EPOCH 3792 #####\n","train loss :  2951.1064453125\n","test loss :  748.4177856445312  _______ Metric :  \n","##### EPOCH 3793 #####\n","train loss :  2920.0693359375\n","test loss :  748.4251098632812  _______ Metric :  \n","##### EPOCH 3794 #####\n","train loss :  2936.0166015625\n","test loss :  748.4392700195312  _______ Metric :  \n","##### EPOCH 3795 #####\n","train loss :  2920.2998046875\n","test loss :  748.4509887695312  _______ Metric :  \n","##### EPOCH 3796 #####\n","train loss :  2917.8583984375\n","test loss :  748.4714965820312  _______ Metric :  \n","##### EPOCH 3797 #####\n","train loss :  2957.8681640625\n","test loss :  748.4837036132812  _______ Metric :  \n","##### EPOCH 3798 #####\n","train loss :  2997.4443359375\n","test loss :  748.4881591796875  _______ Metric :  \n","##### EPOCH 3799 #####\n","train loss :  2897.1865234375\n","test loss :  748.4989013671875  _______ Metric :  \n","##### EPOCH 3800 #####\n","train loss :  2962.8173828125\n","test loss :  748.5062255859375  _______ Metric :  \n","##### EPOCH 3801 #####\n","train loss :  2927.4736328125\n","test loss :  748.5037841796875  _______ Metric :  \n","##### EPOCH 3802 #####\n","train loss :  2906.9853515625\n","test loss :  748.5115966796875  _______ Metric :  \n","##### EPOCH 3803 #####\n","train loss :  2921.2783203125\n","test loss :  748.5174560546875  _______ Metric :  \n","##### EPOCH 3804 #####\n","train loss :  2898.4990234375\n","test loss :  748.5286865234375  _______ Metric :  \n","##### EPOCH 3805 #####\n","train loss :  2950.9326171875\n","test loss :  748.5330810546875  _______ Metric :  \n","##### EPOCH 3806 #####\n","train loss :  2899.6474609375\n","test loss :  748.5389404296875  _______ Metric :  \n","##### EPOCH 3807 #####\n","train loss :  2924.6689453125\n","test loss :  748.5452880859375  _______ Metric :  \n","##### EPOCH 3808 #####\n","train loss :  2896.9111328125\n","test loss :  748.5501708984375  _______ Metric :  \n","##### EPOCH 3809 #####\n","train loss :  2951.0185546875\n","test loss :  748.5462646484375  _______ Metric :  \n","##### EPOCH 3810 #####\n","train loss :  2940.1630859375\n","test loss :  748.5457763671875  _______ Metric :  \n","##### EPOCH 3811 #####\n","train loss :  2898.6533203125\n","test loss :  748.5447998046875  _______ Metric :  \n","##### EPOCH 3812 #####\n","train loss :  2915.9287109375\n","test loss :  748.5467529296875  _______ Metric :  \n","##### EPOCH 3813 #####\n","train loss :  2968.0537109375\n","test loss :  748.5521240234375  _______ Metric :  \n","##### EPOCH 3814 #####\n","train loss :  2934.3759765625\n","test loss :  748.5570068359375  _______ Metric :  \n","##### EPOCH 3815 #####\n","train loss :  2924.5908203125\n","test loss :  748.5599365234375  _______ Metric :  \n","##### EPOCH 3816 #####\n","train loss :  2907.8564453125\n","test loss :  748.5633544921875  _______ Metric :  \n","##### EPOCH 3817 #####\n","train loss :  2915.2392578125\n","test loss :  748.5643310546875  _______ Metric :  \n","##### EPOCH 3818 #####\n","train loss :  2937.5615234375\n","test loss :  748.5653076171875  _______ Metric :  \n","##### EPOCH 3819 #####\n","train loss :  2938.1279296875\n","test loss :  748.5614013671875  _______ Metric :  \n","##### EPOCH 3820 #####\n","train loss :  2907.7119140625\n","test loss :  748.5657958984375  _______ Metric :  \n","##### EPOCH 3821 #####\n","train loss :  2953.4755859375\n","test loss :  748.5701904296875  _______ Metric :  \n","##### EPOCH 3822 #####\n","train loss :  2941.1240234375\n","test loss :  748.5780029296875  _______ Metric :  \n","##### EPOCH 3823 #####\n","train loss :  2907.4482421875\n","test loss :  748.5848388671875  _______ Metric :  \n","##### EPOCH 3824 #####\n","train loss :  2965.2158203125\n","test loss :  748.5932006835938  _______ Metric :  \n","##### EPOCH 3825 #####\n","train loss :  2949.3193359375\n","test loss :  748.5941772460938  _______ Metric :  \n","##### EPOCH 3826 #####\n","train loss :  2933.4833984375\n","test loss :  748.6044311523438  _______ Metric :  \n","##### EPOCH 3827 #####\n","train loss :  2935.8330078125\n","test loss :  748.6068725585938  _______ Metric :  \n","##### EPOCH 3828 #####\n","train loss :  2922.3056640625\n","test loss :  748.6054077148438  _______ Metric :  \n","##### EPOCH 3829 #####\n","train loss :  2942.4599609375\n","test loss :  748.6034545898438  _______ Metric :  \n","##### EPOCH 3830 #####\n","train loss :  2927.6044921875\n","test loss :  748.5990600585938  _______ Metric :  \n","##### EPOCH 3831 #####\n","train loss :  2918.4462890625\n","test loss :  748.5975952148438  _______ Metric :  \n","##### EPOCH 3832 #####\n","train loss :  2916.5966796875\n","test loss :  748.5951538085938  _______ Metric :  \n","##### EPOCH 3833 #####\n","train loss :  2933.9677734375\n","test loss :  748.5878295898438  _______ Metric :  \n","##### EPOCH 3834 #####\n","train loss :  2919.8271484375\n","test loss :  748.5834350585938  _______ Metric :  \n","##### EPOCH 3835 #####\n","train loss :  2923.9501953125\n","test loss :  748.5780639648438  _______ Metric :  \n","##### EPOCH 3836 #####\n","train loss :  2932.2490234375\n","test loss :  748.5770874023438  _______ Metric :  \n","##### EPOCH 3837 #####\n","train loss :  2943.1787109375\n","test loss :  748.5839233398438  _______ Metric :  \n","##### EPOCH 3838 #####\n","train loss :  2940.4404296875\n","test loss :  748.5834350585938  _______ Metric :  \n","##### EPOCH 3839 #####\n","train loss :  2938.0830078125\n","test loss :  748.5795288085938  _______ Metric :  \n","##### EPOCH 3840 #####\n","train loss :  2954.7529296875\n","test loss :  748.5800170898438  _______ Metric :  \n","##### EPOCH 3841 #####\n","train loss :  2940.2529296875\n","test loss :  748.5687866210938  _______ Metric :  \n","##### EPOCH 3842 #####\n","train loss :  2899.1689453125\n","test loss :  748.5629272460938  _______ Metric :  \n","##### EPOCH 3843 #####\n","train loss :  2934.9326171875\n","test loss :  748.5556030273438  _______ Metric :  \n","##### EPOCH 3844 #####\n","train loss :  2931.1845703125\n","test loss :  748.5551147460938  _______ Metric :  \n","##### EPOCH 3845 #####\n","train loss :  2902.2255859375\n","test loss :  748.5595092773438  _______ Metric :  \n","##### EPOCH 3846 #####\n","train loss :  2918.0478515625\n","test loss :  748.5531616210938  _______ Metric :  \n","##### EPOCH 3847 #####\n","train loss :  2900.4228515625\n","test loss :  748.5497436523438  _______ Metric :  \n","##### EPOCH 3848 #####\n","train loss :  2935.7861328125\n","test loss :  748.5438842773438  _______ Metric :  \n","##### EPOCH 3849 #####\n","train loss :  2875.1181640625\n","test loss :  748.5424194335938  _______ Metric :  \n","##### EPOCH 3850 #####\n","train loss :  2918.5224609375\n","test loss :  748.5453491210938  _______ Metric :  \n","##### EPOCH 3851 #####\n","train loss :  2923.7705078125\n","test loss :  748.5546264648438  _______ Metric :  \n","##### EPOCH 3852 #####\n","train loss :  2944.6572265625\n","test loss :  748.5580444335938  _______ Metric :  \n","##### EPOCH 3853 #####\n","train loss :  2913.5634765625\n","test loss :  748.5668334960938  _______ Metric :  \n","##### EPOCH 3854 #####\n","train loss :  2964.8271484375\n","test loss :  748.5736694335938  _______ Metric :  \n","##### EPOCH 3855 #####\n","train loss :  2938.3056640625\n","test loss :  748.5761108398438  _______ Metric :  \n","##### EPOCH 3856 #####\n","train loss :  2933.2587890625\n","test loss :  748.5873413085938  _______ Metric :  \n","##### EPOCH 3857 #####\n","train loss :  2928.7744140625\n","test loss :  748.5868530273438  _______ Metric :  \n","##### EPOCH 3858 #####\n","train loss :  2876.7333984375\n","test loss :  748.5888061523438  _______ Metric :  \n","##### EPOCH 3859 #####\n","train loss :  2967.3740234375\n","test loss :  748.5858764648438  _______ Metric :  \n","##### EPOCH 3860 #####\n","train loss :  2911.0029296875\n","test loss :  748.5868530273438  _______ Metric :  \n","##### EPOCH 3861 #####\n","train loss :  2911.6708984375\n","test loss :  748.5883178710938  _______ Metric :  \n","##### EPOCH 3862 #####\n","train loss :  2919.2080078125\n","test loss :  748.5951538085938  _______ Metric :  \n","##### EPOCH 3863 #####\n","train loss :  2968.4794921875\n","test loss :  748.5922241210938  _______ Metric :  \n","##### EPOCH 3864 #####\n","train loss :  2933.0048828125\n","test loss :  748.5883178710938  _______ Metric :  \n","##### EPOCH 3865 #####\n","train loss :  2946.4716796875\n","test loss :  748.5888061523438  _______ Metric :  \n","##### EPOCH 3866 #####\n","train loss :  2980.8134765625\n","test loss :  748.5824584960938  _______ Metric :  \n","##### EPOCH 3867 #####\n","train loss :  2938.5986328125\n","test loss :  748.5746459960938  _______ Metric :  \n","##### EPOCH 3868 #####\n","train loss :  2956.0712890625\n","test loss :  748.5663452148438  _______ Metric :  \n","##### EPOCH 3869 #####\n","train loss :  2930.9150390625\n","test loss :  748.5614624023438  _______ Metric :  \n","##### EPOCH 3870 #####\n","train loss :  2964.0400390625\n","test loss :  748.5590209960938  _______ Metric :  \n","##### EPOCH 3871 #####\n","train loss :  2898.2470703125\n","test loss :  748.5521850585938  _______ Metric :  \n","##### EPOCH 3872 #####\n","train loss :  2947.3662109375\n","test loss :  748.5536499023438  _______ Metric :  \n","##### EPOCH 3873 #####\n","train loss :  2929.7060546875\n","test loss :  748.5492553710938  _______ Metric :  \n","##### EPOCH 3874 #####\n","train loss :  2935.7431640625\n","test loss :  748.5487670898438  _______ Metric :  \n","##### EPOCH 3875 #####\n","train loss :  2938.6806640625\n","test loss :  748.5502319335938  _______ Metric :  \n","##### EPOCH 3876 #####\n","train loss :  2924.9423828125\n","test loss :  748.5477905273438  _______ Metric :  \n","##### EPOCH 3877 #####\n","train loss :  2955.9501953125\n","test loss :  748.5492553710938  _______ Metric :  \n","##### EPOCH 3878 #####\n","train loss :  2931.6611328125\n","test loss :  748.5477905273438  _______ Metric :  \n","##### EPOCH 3879 #####\n","train loss :  2917.9072265625\n","test loss :  748.5463256835938  _______ Metric :  \n","##### EPOCH 3880 #####\n","train loss :  2905.9521484375\n","test loss :  748.55419921875  _______ Metric :  \n","##### EPOCH 3881 #####\n","train loss :  2967.8779296875\n","test loss :  748.56005859375  _______ Metric :  \n","##### EPOCH 3882 #####\n","train loss :  2885.6611328125\n","test loss :  748.56982421875  _______ Metric :  \n","##### EPOCH 3883 #####\n","train loss :  2922.0107421875\n","test loss :  748.5703125  _______ Metric :  \n","##### EPOCH 3884 #####\n","train loss :  2935.1044921875\n","test loss :  748.57275390625  _______ Metric :  \n","##### EPOCH 3885 #####\n","train loss :  2971.4794921875\n","test loss :  748.572265625  _______ Metric :  \n","##### EPOCH 3886 #####\n","train loss :  2913.7783203125\n","test loss :  748.57470703125  _______ Metric :  \n","##### EPOCH 3887 #####\n","train loss :  2937.3857421875\n","test loss :  748.57861328125  _______ Metric :  \n","##### EPOCH 3888 #####\n","train loss :  2946.1455078125\n","test loss :  748.5791015625  _______ Metric :  \n","##### EPOCH 3889 #####\n","train loss :  2913.6376953125\n","test loss :  748.57958984375  _______ Metric :  \n","##### EPOCH 3890 #####\n","train loss :  2968.1904296875\n","test loss :  748.5849609375  _______ Metric :  \n","##### EPOCH 3891 #####\n","train loss :  2917.4150390625\n","test loss :  748.5908203125  _______ Metric :  \n","##### EPOCH 3892 #####\n","train loss :  2930.0244140625\n","test loss :  748.595703125  _______ Metric :  \n","##### EPOCH 3893 #####\n","train loss :  2933.3564453125\n","test loss :  748.6025390625  _______ Metric :  \n","##### EPOCH 3894 #####\n","train loss :  2912.0107421875\n","test loss :  748.61474609375  _______ Metric :  \n","##### EPOCH 3895 #####\n","train loss :  2935.9541015625\n","test loss :  748.62353515625  _______ Metric :  \n","##### EPOCH 3896 #####\n","train loss :  2962.3740234375\n","test loss :  748.6201171875  _______ Metric :  \n","##### EPOCH 3897 #####\n","train loss :  2935.5419921875\n","test loss :  748.6201171875  _______ Metric :  \n","##### EPOCH 3898 #####\n","train loss :  2910.4443359375\n","test loss :  748.62158203125  _______ Metric :  \n","##### EPOCH 3899 #####\n","train loss :  2915.2197265625\n","test loss :  748.623046875  _______ Metric :  \n","##### EPOCH 3900 #####\n","train loss :  2926.6669921875\n","test loss :  748.6181640625  _______ Metric :  \n","##### EPOCH 3901 #####\n","train loss :  2927.8193359375\n","test loss :  748.61962890625  _______ Metric :  \n","##### EPOCH 3902 #####\n","train loss :  2908.1533203125\n","test loss :  748.62158203125  _______ Metric :  \n","##### EPOCH 3903 #####\n","train loss :  2931.5556640625\n","test loss :  748.62451171875  _______ Metric :  \n","##### EPOCH 3904 #####\n","train loss :  2954.6494140625\n","test loss :  748.623046875  _______ Metric :  \n","##### EPOCH 3905 #####\n","train loss :  2929.3251953125\n","test loss :  748.6181640625  _______ Metric :  \n","##### EPOCH 3906 #####\n","train loss :  2933.5966796875\n","test loss :  748.61083984375  _______ Metric :  \n","##### EPOCH 3907 #####\n","train loss :  2921.4716796875\n","test loss :  748.61083984375  _______ Metric :  \n","##### EPOCH 3908 #####\n","train loss :  2924.2763671875\n","test loss :  748.60888671875  _______ Metric :  \n","##### EPOCH 3909 #####\n","train loss :  2925.3095703125\n","test loss :  748.6025390625  _______ Metric :  \n","##### EPOCH 3910 #####\n","train loss :  2933.7529296875\n","test loss :  748.59716796875  _______ Metric :  \n","##### EPOCH 3911 #####\n","train loss :  2911.5751953125\n","test loss :  748.59765625  _______ Metric :  \n","##### EPOCH 3912 #####\n","train loss :  2937.1611328125\n","test loss :  748.59326171875  _______ Metric :  \n","##### EPOCH 3913 #####\n","train loss :  2908.8466796875\n","test loss :  748.5966796875  _______ Metric :  \n","##### EPOCH 3914 #####\n","train loss :  2897.1044921875\n","test loss :  748.5947265625  _______ Metric :  \n","##### EPOCH 3915 #####\n","train loss :  2935.8388671875\n","test loss :  748.59912109375  _______ Metric :  \n","##### EPOCH 3916 #####\n","train loss :  2945.7353515625\n","test loss :  748.60302734375  _______ Metric :  \n","##### EPOCH 3917 #####\n","train loss :  2884.0576171875\n","test loss :  748.611328125  _______ Metric :  \n","##### EPOCH 3918 #####\n","train loss :  2907.7626953125\n","test loss :  748.61474609375  _______ Metric :  \n","##### EPOCH 3919 #####\n","train loss :  2954.2880859375\n","test loss :  748.611328125  _______ Metric :  \n","##### EPOCH 3920 #####\n","train loss :  2942.9833984375\n","test loss :  748.61572265625  _______ Metric :  \n","##### EPOCH 3921 #####\n","train loss :  2949.2255859375\n","test loss :  748.61767578125  _______ Metric :  \n","##### EPOCH 3922 #####\n","train loss :  2875.8134765625\n","test loss :  748.6171875  _______ Metric :  \n","##### EPOCH 3923 #####\n","train loss :  2927.7001953125\n","test loss :  748.6123046875  _______ Metric :  \n","##### EPOCH 3924 #####\n","train loss :  2946.9541015625\n","test loss :  748.60595703125  _______ Metric :  \n","##### EPOCH 3925 #####\n","train loss :  2917.3427734375\n","test loss :  748.609375  _______ Metric :  \n","##### EPOCH 3926 #####\n","train loss :  2923.0029296875\n","test loss :  748.6030883789062  _______ Metric :  \n","##### EPOCH 3927 #####\n","train loss :  2941.4326171875\n","test loss :  748.5903930664062  _______ Metric :  \n","##### EPOCH 3928 #####\n","train loss :  2928.2138671875\n","test loss :  748.5845336914062  _______ Metric :  \n","##### EPOCH 3929 #####\n","train loss :  2948.6748046875\n","test loss :  748.5762329101562  _______ Metric :  \n","##### EPOCH 3930 #####\n","train loss :  2935.5361328125\n","test loss :  748.5654907226562  _______ Metric :  \n","##### EPOCH 3931 #####\n","train loss :  2893.5830078125\n","test loss :  748.5498657226562  _______ Metric :  \n","##### EPOCH 3932 #####\n","train loss :  2930.5576171875\n","test loss :  748.5396118164062  _______ Metric :  \n","##### EPOCH 3933 #####\n","train loss :  2915.8798828125\n","test loss :  748.5303344726562  _______ Metric :  \n","##### EPOCH 3934 #####\n","train loss :  2933.7275390625\n","test loss :  748.5186157226562  _______ Metric :  \n","##### EPOCH 3935 #####\n","train loss :  2946.8369140625\n","test loss :  748.5117797851562  _______ Metric :  \n","##### EPOCH 3936 #####\n","train loss :  2932.3251953125\n","test loss :  748.5073852539062  _______ Metric :  \n","##### EPOCH 3937 #####\n","train loss :  2943.3427734375\n","test loss :  748.4995727539062  _______ Metric :  \n","##### EPOCH 3938 #####\n","train loss :  2904.0751953125\n","test loss :  748.4893188476562  _______ Metric :  \n","##### EPOCH 3939 #####\n","train loss :  2930.1396484375\n","test loss :  748.4878540039062  _______ Metric :  \n","##### EPOCH 3940 #####\n","train loss :  2894.8525390625\n","test loss :  748.4917602539062  _______ Metric :  \n","##### EPOCH 3941 #####\n","train loss :  2950.2373046875\n","test loss :  748.4932250976562  _______ Metric :  \n","##### EPOCH 3942 #####\n","train loss :  2894.3037109375\n","test loss :  748.4946899414062  _______ Metric :  \n","##### EPOCH 3943 #####\n","train loss :  2931.4775390625\n","test loss :  748.4956665039062  _______ Metric :  \n","##### EPOCH 3944 #####\n","train loss :  2973.6923828125\n","test loss :  748.4956665039062  _______ Metric :  \n","##### EPOCH 3945 #####\n","train loss :  2956.2001953125\n","test loss :  748.4937133789062  _______ Metric :  \n","##### EPOCH 3946 #####\n","train loss :  2898.6376953125\n","test loss :  748.4913330078125  _______ Metric :  \n","##### EPOCH 3947 #####\n","train loss :  2934.5556640625\n","test loss :  748.4903564453125  _______ Metric :  \n","##### EPOCH 3948 #####\n","train loss :  2948.9970703125\n","test loss :  748.4962158203125  _______ Metric :  \n","##### EPOCH 3949 #####\n","train loss :  2952.9326171875\n","test loss :  748.4932861328125  _______ Metric :  \n","##### EPOCH 3950 #####\n","train loss :  2918.4853515625\n","test loss :  748.4927978515625  _______ Metric :  \n","##### EPOCH 3951 #####\n","train loss :  2958.3857421875\n","test loss :  748.4874267578125  _______ Metric :  \n","##### EPOCH 3952 #####\n","train loss :  2928.6513671875\n","test loss :  748.4888916015625  _______ Metric :  \n","##### EPOCH 3953 #####\n","train loss :  2930.8388671875\n","test loss :  748.4860229492188  _______ Metric :  \n","##### EPOCH 3954 #####\n","train loss :  2883.9892578125\n","test loss :  748.4835815429688  _______ Metric :  \n","##### EPOCH 3955 #####\n","train loss :  2966.3291015625\n","test loss :  748.4826049804688  _______ Metric :  \n","##### EPOCH 3956 #####\n","train loss :  2956.8681640625\n","test loss :  748.4767456054688  _______ Metric :  \n","##### EPOCH 3957 #####\n","train loss :  2907.1279296875\n","test loss :  748.4791870117188  _______ Metric :  \n","##### EPOCH 3958 #####\n","train loss :  2940.0634765625\n","test loss :  748.4830932617188  _______ Metric :  \n","##### EPOCH 3959 #####\n","train loss :  2940.1533203125\n","test loss :  748.4757690429688  _______ Metric :  \n","##### EPOCH 3960 #####\n","train loss :  2874.9013671875\n","test loss :  748.4796752929688  _______ Metric :  \n","##### EPOCH 3961 #####\n","train loss :  2946.1064453125\n","test loss :  748.4723510742188  _______ Metric :  \n","##### EPOCH 3962 #####\n","train loss :  2945.3544921875\n","test loss :  748.4664916992188  _______ Metric :  \n","##### EPOCH 3963 #####\n","train loss :  2926.0927734375\n","test loss :  748.4611206054688  _______ Metric :  \n","##### EPOCH 3964 #####\n","train loss :  2923.4404296875\n","test loss :  748.4596557617188  _______ Metric :  \n","##### EPOCH 3965 #####\n","train loss :  2940.3427734375\n","test loss :  748.4616088867188  _______ Metric :  \n","##### EPOCH 3966 #####\n","train loss :  2975.7919921875\n","test loss :  748.4625854492188  _______ Metric :  \n","##### EPOCH 3967 #####\n","train loss :  2930.5576171875\n","test loss :  748.4625854492188  _______ Metric :  \n","##### EPOCH 3968 #####\n","train loss :  2978.5947265625\n","test loss :  748.4650268554688  _______ Metric :  \n","##### EPOCH 3969 #####\n","train loss :  2918.6220703125\n","test loss :  748.4664916992188  _______ Metric :  \n","##### EPOCH 3970 #####\n","train loss :  2928.8349609375\n","test loss :  748.4625854492188  _______ Metric :  \n","##### EPOCH 3971 #####\n","train loss :  2907.5673828125\n","test loss :  748.4596557617188  _______ Metric :  \n","##### EPOCH 3972 #####\n","train loss :  2905.3154296875\n","test loss :  748.4494018554688  _______ Metric :  \n","##### EPOCH 3973 #####\n","train loss :  2895.9326171875\n","test loss :  748.4411010742188  _______ Metric :  \n","##### EPOCH 3974 #####\n","train loss :  2941.8173828125\n","test loss :  748.4386596679688  _______ Metric :  \n","##### EPOCH 3975 #####\n","train loss :  2944.1044921875\n","test loss :  748.4284057617188  _______ Metric :  \n","##### EPOCH 3976 #####\n","train loss :  2911.8388671875\n","test loss :  748.4191284179688  _______ Metric :  \n","##### EPOCH 3977 #####\n","train loss :  2938.6103515625\n","test loss :  748.4118041992188  _______ Metric :  \n","##### EPOCH 3978 #####\n","train loss :  2889.9814453125\n","test loss :  748.3956909179688  _______ Metric :  \n","##### EPOCH 3979 #####\n","train loss :  2933.2412109375\n","test loss :  748.3737182617188  _______ Metric :  \n","##### EPOCH 3980 #####\n","train loss :  2912.2333984375\n","test loss :  748.3619995117188  _______ Metric :  \n","##### EPOCH 3981 #####\n","train loss :  2960.3857421875\n","test loss :  748.3478393554688  _______ Metric :  \n","##### EPOCH 3982 #####\n","train loss :  2950.6650390625\n","test loss :  748.3322143554688  _______ Metric :  \n","##### EPOCH 3983 #####\n","train loss :  2922.7353515625\n","test loss :  748.3185424804688  _______ Metric :  \n","##### EPOCH 3984 #####\n","train loss :  2921.7001953125\n","test loss :  748.3097534179688  _______ Metric :  \n","##### EPOCH 3985 #####\n","train loss :  2973.5302734375\n","test loss :  748.3014526367188  _______ Metric :  \n","##### EPOCH 3986 #####\n","train loss :  2929.7216796875\n","test loss :  748.2965698242188  _______ Metric :  \n","##### EPOCH 3987 #####\n","train loss :  2934.5830078125\n","test loss :  748.2926635742188  _______ Metric :  \n","##### EPOCH 3988 #####\n","train loss :  2931.9111328125\n","test loss :  748.2863159179688  _______ Metric :  \n","##### EPOCH 3989 #####\n","train loss :  2956.9443359375\n","test loss :  748.2775268554688  _______ Metric :  \n","##### EPOCH 3990 #####\n","train loss :  2955.0341796875\n","test loss :  748.2750854492188  _______ Metric :  \n","##### EPOCH 3991 #####\n","train loss :  2921.7451171875\n","test loss :  748.2731323242188  _______ Metric :  \n","##### EPOCH 3992 #####\n","train loss :  2904.2197265625\n","test loss :  748.2682495117188  _______ Metric :  \n","##### EPOCH 3993 #####\n","train loss :  2950.6279296875\n","test loss :  748.2623901367188  _______ Metric :  \n","##### EPOCH 3994 #####\n","train loss :  2965.4501953125\n","test loss :  748.2619018554688  _______ Metric :  \n","##### EPOCH 3995 #####\n","train loss :  2899.8076171875\n","test loss :  748.2555541992188  _______ Metric :  \n","##### EPOCH 3996 #####\n","train loss :  2895.1630859375\n","test loss :  748.2516479492188  _______ Metric :  \n","##### EPOCH 3997 #####\n","train loss :  2898.6572265625\n","test loss :  748.2536010742188  _______ Metric :  \n","##### EPOCH 3998 #####\n","train loss :  2952.3720703125\n","test loss :  748.2570190429688  _______ Metric :  \n","##### EPOCH 3999 #####\n","train loss :  2904.1474609375\n","test loss :  748.2536010742188  _______ Metric :  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"izGV1vwuxOol","executionInfo":{"status":"ok","timestamp":1601472748022,"user_tz":-60,"elapsed":1435,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}},"outputId":"24ac8862-1644-4370-a55e-2f176a97ccb5","colab":{"base_uri":"https://localhost:8080/","height":283}},"source":["fig, ax = plt.subplots(figsize=(8, 4))\n","plt.plot(l_mtlr.losses['Epoch'], l_mtlr.losses['Train'], color='red', label='Train', lw=2)\n","plt.plot(l_mtlr.losses['Epoch'], l_mtlr.losses['Test'], color='blue', label='Test', lw=2)\n","\n","# Show everything\n","title = \"LOSSES\"\n","plt.legend(fontsize=12)\n","plt.title(title, fontsize=15)\n","plt.ylim(0, 1.05)\n","plt.show()\n","# the probability that an individual within the population will survive longer than time t. "],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"8JZ3lUIcdHvG","executionInfo":{"status":"ok","timestamp":1601476816851,"user_tz":-60,"elapsed":891,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}},"outputId":"4a4b3df7-e668-4421-f63d-968ebdbc2036","colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["data_test.loc[(data_test['Churn_Yes']==1) & (data_test['tenure']>=65)].index.values"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  86,  353,  361,  365,  386,  775,  840,  996, 1265, 1365, 1465,\n","       1534, 1544, 1632, 1708, 1726, 1756, 1774, 1821, 2017, 2023, 2106])"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"code","metadata":{"id":"9wsI4tkiyYUF","executionInfo":{"status":"error","timestamp":1602526530594,"user_tz":-60,"elapsed":1170,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}},"outputId":"77e40e6a-b74d-45f0-dfa8-5df543c68bd3","colab":{"base_uri":"https://localhost:8080/","height":244}},"source":["k = 86\n","t = T_test[k]\n","_, _, l_predicted = l_mtlr.predict(X_test.iloc[[k]].values)\n","pys_predicted = lmtlr.predict_survival(X_test.iloc[[k]].values).flatten()\n","nmtlr_predicted = n_mtlr.predict_survival(X_test.iloc[[k]].values).flatten()\n","\n","fig, ax = plt.subplots(figsize=(8, 4))\n","plt.plot(l_mtlr.times, l_predicted.flatten(), color='red', label='custome', lw=2)\n","plt.plot(lmtlr.times, pys_predicted, color='blue', label='pysurvival', lw=2)\n","plt.plot(n_mtlr.times, nmtlr_predicted, color='green', label='pysurvival', lw=2)\n","\n","n_mtlr\n","plt.axvline(x=t, color='black', ls ='--')\n","ax.annotate('T={:.1f}'.format(t), xy=(t, 0.5), xytext=(t, 0.5), fontsize=12)\n","\n","# Show everything\n","title = \"Comparing Survival functions between Actual and Predicted\"\n","plt.legend(fontsize=12)\n","plt.title(title, fontsize=15)\n","plt.ylim(0, 1.05)\n","plt.show()\n","# the probability that an individual within the population will survive longer than time t. "],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-9e3aa7f45bd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m86\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml_mtlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpys_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlmtlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_survival\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnmtlr_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_mtlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_survival\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'T_test' is not defined"]}]},{"cell_type":"code","metadata":{"id":"oxZ4zR5sOrwb","executionInfo":{"status":"ok","timestamp":1602334421494,"user_tz":-60,"elapsed":991,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}},"outputId":"84a84690-693a-4720-a566-57d52a022fda","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["l_mtlr.c_index(X_train.values, T_train, E_train), l_mtlr.c_index(X_test.values, T_test, E_test)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.9513072651921582, 0.9396528113873663)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"NXeDp32uSAgS","executionInfo":{"status":"ok","timestamp":1601490671694,"user_tz":-60,"elapsed":1213,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}},"outputId":"44c2c5c8-ae27-40b5-a950-7124af33a35e","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["l = [5,6,9,8,7]\n","l[-1]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"9qicLZvpeLtK","executionInfo":{"status":"ok","timestamp":1602334425984,"user_tz":-60,"elapsed":1307,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}},"outputId":"690bc477-f699-4060-ccaa-1d0fa6f262f4","colab":{"base_uri":"https://localhost:8080/","height":283}},"source":["brier_res, ibs, figure = l_mtlr.b_index(X_train.values, T_train, E_train, X_test.values, T_test, E_test, plot=True)\n","figure.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"Izv29beIlP2n","executionInfo":{"status":"ok","timestamp":1602451800284,"user_tz":-60,"elapsed":656,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}},"outputId":"8c3ee721-e07f-4fd6-f1d3-aa49ac1d8189","colab":{"base_uri":"https://localhost:8080/","height":17}},"source":["from google.colab import files\n","times = pd.DataFrame(l_mtlr.times)\n","times.to_csv('times.csv')\n","files.download('times.csv')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_84d518ab-1e3e-43b6-8869-58ae9ab58db2\", \"times.csv\", 1524)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"1not7-Rdk5Im","executionInfo":{"status":"ok","timestamp":1602334853391,"user_tz":-60,"elapsed":950,"user":{"displayName":"Youcef Moualek","photoUrl":"","userId":"10747212200399101970"}},"outputId":"ffdb05db-32c1-4555-8457-51e431af129c","colab":{"base_uri":"https://localhost:8080/","height":17}},"source":["from google.colab import files\n","data_test.to_csv('telecom_data_test.csv')\n","files.download('telecom_data_test.csv')\n","\n","_, _, surv = l_mtlr.predict(X_test.values)\n","surv = pd.DataFrame(surv)\n","surv.to_csv('telecom_surv_pred.csv')\n","files.download('telecom_surv_pred.csv')\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_3c578fd4-ef12-4e3a-be02-b0fa33183478\", \"telecom_data_test.csv\", 203096)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_e0ed7020-949b-47e3-aa3b-c8aeb49c9a82\", \"telecom_surv_pred.csv\", 3055803)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]}]}