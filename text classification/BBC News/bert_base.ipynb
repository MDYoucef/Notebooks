{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyObRq2ePtrJdMjup+t2YizP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!pip -q install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AK6Px0FAT7sU","executionInfo":{"status":"ok","timestamp":1680702540329,"user_tz":-60,"elapsed":20105,"user":{"displayName":"Youcef Moualek","userId":"10747212200399101970"}},"outputId":"482e9342-21ef-402c-c0b0-2c8d364e931e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"Ic2cap_z8ujP","executionInfo":{"status":"ok","timestamp":1680713334452,"user_tz":-60,"elapsed":14293,"user":{"displayName":"Youcef Moualek","userId":"10747212200399101970"}},"outputId":"c580353c-ada3-4a4b-8709-b47147453e9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["'torch.cuda.set_device(0)\\ntorch.backends.cudnn.benchmark = True'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, TensorDataset\n","import torch.optim as opt\n","from transformers import BertTokenizer, BertModel\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix, auc, roc_curve\n","from copy import copy, deepcopy\n","import zipfile\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","'''torch.cuda.set_device(0)\n","torch.backends.cudnn.benchmark = True'''"]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/text classification/BBC News/bbc-text.csv')\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"YrDwpNyzZ4Ko","executionInfo":{"status":"ok","timestamp":1680713362502,"user_tz":-60,"elapsed":1042,"user":{"displayName":"Youcef Moualek","userId":"10747212200399101970"}},"outputId":"98b6d0c6-3140-4091-9970-c3ffbd1c41a7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           category                                               text\n","0              tech  tv future in the hands of viewers with home th...\n","1          business  worldcom boss  left books alone  former worldc...\n","2             sport  tigers wary of farrell  gamble  leicester say ...\n","3             sport  yeading face newcastle in fa cup premiership s...\n","4     entertainment  ocean s twelve raids box office ocean s twelve...\n","...             ...                                                ...\n","2220       business  cars pull down us retail figures us retail sal...\n","2221       politics  kilroy unveils immigration policy ex-chatshow ...\n","2222  entertainment  rem announce new glasgow concert us band rem h...\n","2223       politics  how political squabbles snowball it s become c...\n","2224          sport  souness delight at euro progress boss graeme s...\n","\n","[2225 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-b36a750b-c586-496f-b5a4-6c1c0074ab58\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>category</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>tech</td>\n","      <td>tv future in the hands of viewers with home th...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>business</td>\n","      <td>worldcom boss  left books alone  former worldc...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sport</td>\n","      <td>tigers wary of farrell  gamble  leicester say ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>sport</td>\n","      <td>yeading face newcastle in fa cup premiership s...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>entertainment</td>\n","      <td>ocean s twelve raids box office ocean s twelve...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2220</th>\n","      <td>business</td>\n","      <td>cars pull down us retail figures us retail sal...</td>\n","    </tr>\n","    <tr>\n","      <th>2221</th>\n","      <td>politics</td>\n","      <td>kilroy unveils immigration policy ex-chatshow ...</td>\n","    </tr>\n","    <tr>\n","      <th>2222</th>\n","      <td>entertainment</td>\n","      <td>rem announce new glasgow concert us band rem h...</td>\n","    </tr>\n","    <tr>\n","      <th>2223</th>\n","      <td>politics</td>\n","      <td>how political squabbles snowball it s become c...</td>\n","    </tr>\n","    <tr>\n","      <th>2224</th>\n","      <td>sport</td>\n","      <td>souness delight at euro progress boss graeme s...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2225 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b36a750b-c586-496f-b5a4-6c1c0074ab58')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b36a750b-c586-496f-b5a4-6c1c0074ab58 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b36a750b-c586-496f-b5a4-6c1c0074ab58');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["df['category'].unique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CfLXWjRyaYGx","executionInfo":{"status":"ok","timestamp":1680532674699,"user_tz":-60,"elapsed":10,"user":{"displayName":"Youcef Moualek","userId":"10747212200399101970"}},"outputId":"713f8716-ba4c-4e8a-d1ad-523a1a16ee26"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['tech', 'business', 'sport', 'entertainment', 'politics'],\n","      dtype=object)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n","\n","'''example_text = ['I will watch Memento tonight']\n","bert_input = tokenizer(example_text,padding='max_length', max_length = 10, truncation=True, return_tensors=\"pt\")\n","tokenizer.decode(bert_input.input_ids[1])'''\n","text_column, out_column = 'text', 'category'\n","labels = dict(zip(df[out_column].unique(), range(df[out_column].nunique())))\n","df.replace({out_column: labels}, inplace=True)\n","df_train, df_valid, df_test = np.split(df.sample(frac=1, random_state=42),  [int(.8*len(df)), int(.9*len(df))])\n","df_train.shape, df_valid.shape, df_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jIRg9grmanTN","executionInfo":{"status":"ok","timestamp":1680713367298,"user_tz":-60,"elapsed":971,"user":{"displayName":"Youcef Moualek","userId":"10747212200399101970"}},"outputId":"e653f6c7-3e2e-4f51-efec-81e5e0c2f8b1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1780, 2), (222, 2), (223, 2))"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["df_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"aNvuA6flXSB7","executionInfo":{"status":"ok","timestamp":1680713370637,"user_tz":-60,"elapsed":15,"user":{"displayName":"Youcef Moualek","userId":"10747212200399101970"}},"outputId":"a32076e3-555a-4e7b-b6ee-8d16fd0f5b66"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      category                                               text\n","414          4  brown and blair face new rift claims for the u...\n","420          1  small firms  hit by rising costs  rising fuel ...\n","1644         3  spirit awards hail sideways the comedy sideway...\n","416          0  microsoft releases patches microsoft has warne...\n","1232         2  arsenal through on penalties arsenal win 4-2 o...\n","...        ...                                                ...\n","801          2  ireland 19-13 england ireland consigned englan...\n","1774         0  warning over tsunami aid website net users are...\n","512          0  digital guru floats sub-$100 pc nicholas negro...\n","633          3  gallery unveils interactive tree a christmas t...\n","1789         3  us tv special for tsunami relief a us televisi...\n","\n","[1780 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-df62816e-5d35-45d3-8cb7-beb7658a20b7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>category</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>414</th>\n","      <td>4</td>\n","      <td>brown and blair face new rift claims for the u...</td>\n","    </tr>\n","    <tr>\n","      <th>420</th>\n","      <td>1</td>\n","      <td>small firms  hit by rising costs  rising fuel ...</td>\n","    </tr>\n","    <tr>\n","      <th>1644</th>\n","      <td>3</td>\n","      <td>spirit awards hail sideways the comedy sideway...</td>\n","    </tr>\n","    <tr>\n","      <th>416</th>\n","      <td>0</td>\n","      <td>microsoft releases patches microsoft has warne...</td>\n","    </tr>\n","    <tr>\n","      <th>1232</th>\n","      <td>2</td>\n","      <td>arsenal through on penalties arsenal win 4-2 o...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>801</th>\n","      <td>2</td>\n","      <td>ireland 19-13 england ireland consigned englan...</td>\n","    </tr>\n","    <tr>\n","      <th>1774</th>\n","      <td>0</td>\n","      <td>warning over tsunami aid website net users are...</td>\n","    </tr>\n","    <tr>\n","      <th>512</th>\n","      <td>0</td>\n","      <td>digital guru floats sub-$100 pc nicholas negro...</td>\n","    </tr>\n","    <tr>\n","      <th>633</th>\n","      <td>3</td>\n","      <td>gallery unveils interactive tree a christmas t...</td>\n","    </tr>\n","    <tr>\n","      <th>1789</th>\n","      <td>3</td>\n","      <td>us tv special for tsunami relief a us televisi...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1780 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df62816e-5d35-45d3-8cb7-beb7658a20b7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-df62816e-5d35-45d3-8cb7-beb7658a20b7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-df62816e-5d35-45d3-8cb7-beb7658a20b7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","class BertLoader(Dataset):\n","    def __init__(self, encoded_data, labels):\n","        self.labels = labels\n","        self.encoded_data = encoded_data\n","\n","    def classes(self):\n","        return self.labels\n"," \n","    def __len__(self):\n","        return len(self.encoded_data['input_ids'])\n"," \n","    def __getitem__(self, idx):\n","        return self.encoded_data['input_ids'][idx], self.encoded_data['attention_mask'][idx], self.labels[idx] if self.labels is not None else None\n","\n","class NNModel(nn.Module):\n","    def __init__(self, input_shape, units=None, factors=None, activ=True, norm=False, dropout=False, slops=None):\n","        super().__init__()\n","        self.input_shape = input_shape\n","        self.units = units\n","        self.factors = factors\n","        self.activ, self.norm = activ, norm\n","        self.network = nn.ModuleList()\n","        if self.factors:\n","            self.units = np.round(self.input_shape * np.asarray(self.factors)).astype(int)\n","        if self.units is not None:\n","            self.dropout = np.zeros_like(self.units) if not dropout else dropout\n","            self.slops = np.full(len(self.units), 1) if slops is None else slops\n","            for i, j, k in zip(self.units, self.dropout, self.slops):\n","                if i >= 1:\n","                    block = self.__build_block__(input_shape, i, p=j, slop=k)\n","                    self.network.extend(block)\n","                    input_shape = i\n","        self.output_shape = input_shape\n","        self.reset_parameters()\n","    \n","    def __build_block__(self, input_shape, units, p, slop):\n","        block = []\n","        block.append(nn.Linear(input_shape, units, bias=not self.norm))\n","        if self.norm:\n","            block.append(nn.BatchNorm1d(units))\n","            #block.append(nn.LayerNorm(units, eps=1e-5))\n","        if self.activ:\n","            #block.append(nn.LeakyReLU())\n","            block.append(nn.ELU(slop))\n","            #block.append(nn.GELU())\n","        if p > 0:\n","            block.append(nn.Dropout(p))\n","        return block\n"," \n","    def forward(self, x):\n","        for layer in self.network:\n","          tmp = layer(x)\n","          x = tmp\n","        return x\n"," \n","    def reset_parameters(self):\n","        for layer in self.network:\n","            if isinstance(layer, nn.Linear):\n","                nn.init.xavier_normal_(layer.weight)\n","                layer.bias.data.fill_(0.1)\n"," \n","\n","class BertClassifier(nn.Module):\n","    def __init__(self, mlp_units, mlp_dropout, nb_class):\n","        super(BertClassifier, self).__init__()\n","        self.bert = BertModel.from_pretrained('bert-base-cased')\n","        self.mlp = NNModel(768, units=mlp_units, factors=None, dropout=[mlp_dropout]*len(mlp_units)) if mlp_units is not None else None\n","        cls_units = self.mlp.output_shape if mlp_units is not None else 768\n","        self.classifier = nn.Linear(cls_units, nb_class)\n","\n","    def forward(self, input_id, mask):\n","        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n","        z = self.mlp(pooled_output) if self.mlp is not None else pooled_output\n","        pred = self.classifier(z)\n","        return z, pooled_output, pred\n","\n","class BaseBertClassifier:\n","    def __init__(self, model, tokenizer):\n","        self.model = model.to(device)\n","        self.losses = {'Epoch': [], 'Train': [], 'Test': [], 'BState': [], 'LState': [], 'LR': []}\n","        self.tokenizer = tokenizer\n"," \n","    def train_model(self, optim, train_loader, grad_clip, l2_reg):\n","          total_loss = 0\n","          self.model = self.model.train()\n","        #with autograd.detect_anomaly():\n","          for i, (ids, mask, Y) in enumerate(train_loader):\n","              ids, mask, Y = ids.to(device), mask.to(device), Y.to(device)\n","              #self.model.get_weight()\n","              optim.zero_grad()\n","              loss = self.loss_function(ids, mask, Y, l2_reg)\n","              loss.backward()\n","              torch.nn.utils.clip_grad_norm_(self.model.parameters(), grad_clip)\n","              optim.step()\n","              total_loss += loss.item()\n","          return total_loss/(i+1)\n","        \n"," \n","    def eval_model(self, test_loader):\n","        self.model = self.model.eval()\n","        total_loss = 0\n","        for i, (ids, mask, Y) in enumerate(test_loader):\n","            ids, mask, Y = ids.to(device), mask.to(device), Y.to(device)\n","            loss = self.loss_function(ids, mask, Y, l2_reg=0)\n","            total_loss += loss.item()\n","        return total_loss/(i+1)#np.abs(-100. - total_loss)\n"," \n","    def fit(self, X_train, Y_train, epoch, lr, opt_kwarg, batch_size=None,  grad_clip=100, momentum=0.9, X_test=None, Y_test=None, l2_reg=0, verbose=True, save=True):\n","        batch_size = len(Y_train) if batch_size is None else batch_size\n","        encoded_train = self.tokenizer.batch_encode_plus(X_train, add_special_tokens=True, return_attention_mask=True, pad_to_max_length=True, max_length=512, return_tensors='pt')\n","        train_load = DataLoader(BertLoader(encoded_train, Y_train), batch_size=batch_size, shuffle=True)  # DATALOADER obj\n","        if X_test is not None:\n","            encoded_test = self.tokenizer.batch_encode_plus(X_test, add_special_tokens=True, return_attention_mask=True, pad_to_max_length=True, max_length=512, return_tensors='pt')\n","            test_load = DataLoader(BertLoader(encoded_test, Y_test), batch_size=batch_size, shuffle=True)\n"," \n","        best_loss = 1e100\n","        optim = opt.Adam(self.model.parameters(), lr=lr)\n","        #optim = opt.SGD(self.model.parameters(), lr=lr, momentum=momentum, nesterov=True)\n","\n","        scheduler = None\n","        #scheduler = opt.lr_scheduler.CyclicLR(optim, **opt_kwarg)\n","        #scheduler = opt.lr_scheduler.ReduceLROnPlateau(optim, **opt_kwarg)\n","        #scheduler = opt.lr_scheduler.MultiStepLR(optim, milestones=[28, 120], gamma=0.1)\n","\n","        eval_score = ''\n","        for i in range(epoch):\n","            if verbose:\n","                print('##### EPOCH ' + str(i) + ' #####')\n","               \n","            train_loss = self.train_model(optim, train_load, grad_clip, l2_reg)\n","            self.losses['LState'] = deepcopy(self.model.state_dict())\n","    \n","            if verbose:\n","                print('train loss : ', train_loss)\n","            self.losses['Epoch'].append(i), self.losses['Train'].append(train_loss)\n","    \n","            if df_test is not None:\n","                valid_loss = self.eval_model(test_load)\n","\n","                if verbose:\n","                    print('test loss : ', valid_loss)\n","                self.losses['Test'].append(valid_loss)\n","    \n","                if scheduler is not None:\n","                    scheduler.step(valid_loss)\n","                    self.losses['LR'].append(optim.param_groups[0]['lr'])\n","                    '''scheduler.step()\n","                    self.losses['LR'].append(scheduler.get_last_lr()[0])'''\n","    \n","                if valid_loss < best_loss:\n","                    self.losses['BState'] = deepcopy(self.model.state_dict())\n","                    best_loss = valid_loss\n","                    print('===========SAVE===========')\n","\n","\n","class Multiclass(BaseBertClassifier):#multiclass classification\n","    def __init__(self, model, tokenizer):\n","        super(Multiclass, self).__init__(model, tokenizer,)\n","\n","    def loss_function(self, input_id, mask, Y, l2_reg):\n","        _, _, pred = self.model(input_id, mask)\n","        ce_loss = nn.CrossEntropyLoss()\n","        loss = ce_loss(pred, Y)\n","        return loss\n","\n","    def prdict(self, X, batch_size):\n","        self.model.eval()\n","        encoded_data = self.tokenizer.batch_encode_plus(X, add_special_tokens=True, return_attention_mask=True, pad_to_max_length=True, max_length=512, return_tensors='pt')\n","        data_load = DataLoader(TensorDataset(encoded_data['input_ids'],  encoded_data['attention_mask']),batch_size=batch_size)\n","        outputs = {'z': [], 'pooled_output': [], 'pred': []}\n","        for i, (ids, mask) in enumerate(data_load):\n","            ids, mask = ids.to(device), mask.to(device)\n","            z, pooled_output, pred = self.model(ids, mask)\n","            pred = nn.Softmax()(pred)\n","            z, pooled_output, pred = z.cpu().data.numpy(), pooled_output.cpu().data.numpy(), pred.cpu().data.numpy()\n","            outputs['z'].extend(z), outputs['pooled_output'].extend(pooled_output), outputs['pred'].extend(pred)\n","        return outputs\n","\n","def gradient_clipper(model: nn.Module, val: float) -> nn.Module:\n","    def process_grad(grad):\n","        grad[grad != grad] = 1e-10\n","        return torch.clamp(grad, -val, val)\n","    for parameter in model.parameters():\n","        parameter.register_hook(lambda grad: process_grad(grad))\n","    \n","    return model"],"metadata":{"id":"R-cfnzJfmVtS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epoch, lr, batch_size, d, mlp_d = 50000, 5e-5, 8, 0.000001, 1e-6\n","#cyclic_kwarg = {'base_lr': lr, 'max_lr': 1e-2, 'step_size_up':200, 'step_size_down':200}\n","plateau_kwarg = {'factor':0.5, 'patience':200, 'verbose':True, 'min_lr':1e-7, 'mode':'min'}\n","\n","model = BertClassifier(mlp_units=None, mlp_dropout=1e-6, nb_class=len(labels))\n","model = gradient_clipper(model, 10)\n","#nn_model.load_state_dict(best_state)\n","print(device)\n","print(model)\n","print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n","bert_mc = Multiclass(model, tokenizer)\n","bert_mc.fit(df_train[text_column].values, df_train[out_column].values, epoch, lr, plateau_kwarg, batch_size=batch_size, grad_clip=10, momentum=0.9,\n","        X_test=df_valid[text_column].values, Y_test=df_valid[out_column].values, l2_reg=0, verbose=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"AboTgaO5nPPf","executionInfo":{"status":"error","timestamp":1680714499024,"user_tz":-60,"elapsed":1109341,"user":{"displayName":"Youcef Moualek","userId":"10747212200399101970"}},"outputId":"7488ed5c-b9eb-43cc-ce99-0720d57a3185"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["cuda\n","BertClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",")\n","108314117\n"]},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["##### EPOCH 0 #####\n","train loss :  0.33954120386441994\n","test loss :  0.12012455471059573\n","===========SAVE===========\n","##### EPOCH 1 #####\n","train loss :  0.11365090809227907\n","test loss :  0.22097229595029994\n","##### EPOCH 2 #####\n","train loss :  0.07116246003670108\n","test loss :  0.08009558678272047\n","===========SAVE===========\n","##### EPOCH 3 #####\n","train loss :  0.03621406607813256\n","test loss :  0.07369448415452748\n","===========SAVE===========\n","##### EPOCH 4 #####\n","train loss :  0.023090836575574286\n","test loss :  0.0917876655834594\n","##### EPOCH 5 #####\n","train loss :  0.010507119596871076\n","test loss :  0.10657569291236411\n","##### EPOCH 6 #####\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-c448665e65fb>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mbert_mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMulticlass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m bert_mc.fit(df_train[text_column].values, df_train[out_column].values, epoch, lr, plateau_kwarg, batch_size=batch_size, grad_clip=10, momentum=0.9,\n\u001b[0m\u001b[1;32m     13\u001b[0m         X_test=df_valid[text_column].values, Y_test=df_valid[out_column].values, l2_reg=0, verbose=True)\n","\u001b[0;32m<ipython-input-8-92e956f6224f>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, Y_train, epoch, lr, opt_kwarg, batch_size, grad_clip, momentum, X_test, Y_test, l2_reg, verbose, save)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'##### EPOCH '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' #####'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_clip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LState'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-92e956f6224f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, optim, train_loader, grad_clip, l2_reg)\u001b[0m\n\u001b[1;32m     92\u001b[0m               \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m               \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m               \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m               \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_clip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m               \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","\n","best_state = deepcopy(bert_mc.losses['BState'])\n","bert_mc.model.load_state_dict(best_state)\n","print(np.min(bert_mc.losses['Test']))\n","\n","fig = make_subplots(rows=3, cols=1)\n","s = 0\n","fig.append_trace(go.Scatter(x=bert_mc.losses['Epoch'][s:], y=bert_mc.losses['Train'][s:],mode='lines',name='Train'), row=1, col=1)\n","fig.append_trace(go.Scatter(x=bert_mc.losses['Epoch'][s:], y=bert_mc.losses['Test'][s:],mode='lines',name='Test'), row=2, col=1)\n","fig.append_trace(go.Scatter(x=bert_mc.losses['Epoch'][s:], y=bert_mc.losses['LR'][s:],mode='lines',name='LR'), row=3, col=1)\n","fig.update_layout(height=1000, width=1500, title_text=\"Stacked Subplots\")\n","fig.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"cKiWo47Oi0zF","executionInfo":{"status":"ok","timestamp":1680714505088,"user_tz":-60,"elapsed":517,"user":{"displayName":"Youcef Moualek","userId":"10747212200399101970"}},"outputId":"ee40767e-b935-477b-c8cf-b7235f39ece3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.07369448415452748\n"]},{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"b4700018-24c9-4b4c-a7e4-6f766c47d6ce\" class=\"plotly-graph-div\" style=\"height:1000px; width:1500px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b4700018-24c9-4b4c-a7e4-6f766c47d6ce\")) {                    Plotly.newPlot(                        \"b4700018-24c9-4b4c-a7e4-6f766c47d6ce\",                        [{\"mode\":\"lines\",\"name\":\"Train\",\"x\":[0,1,2,3,4,5],\"y\":[0.33954120386441994,0.11365090809227907,0.07116246003670108,0.03621406607813256,0.023090836575574286,0.010507119596871076],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Test\",\"x\":[0,1,2,3,4,5],\"y\":[0.12012455471059573,0.22097229595029994,0.08009558678272047,0.07369448415452748,0.0917876655834594,0.10657569291236411],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"LR\",\"x\":[0,1,2,3,4,5],\"y\":[],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.7333333333333333,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.36666666666666664,0.6333333333333333]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,1.0]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.26666666666666666]},\"title\":{\"text\":\"Stacked Subplots\"},\"height\":1000,\"width\":1500},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('b4700018-24c9-4b4c-a7e4-6f766c47d6ce');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","source":["output = bert_mc.prdict(df_valid[text_column].values, 2)\n","pred = np.argmax(np.asarray(output['pred']), 1)\n","acc = accuracy_score(df_valid[out_column].values, pred)\n","acc, confusion_matrix(df_valid[out_column].values, pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rp_ngbpXh6Ml","executionInfo":{"status":"ok","timestamp":1680714544322,"user_tz":-60,"elapsed":9498,"user":{"displayName":"Youcef Moualek","userId":"10747212200399101970"}},"outputId":"79b86dc9-9ee2-4755-dd8d-dd2d04911850"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n","<ipython-input-8-92e956f6224f>:176: UserWarning:\n","\n","Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["(0.9819819819819819,\n"," array([[34,  0,  0,  1,  0],\n","        [ 2, 38,  0,  0,  0],\n","        [ 0,  0, 56,  0,  0],\n","        [ 0,  0,  0, 42,  0],\n","        [ 0,  1,  0,  0, 48]]))"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["output = bert_mc.prdict(df_test[text_column].values, 2)\n","pred = np.argmax(np.asarray(output['pred']), 1)\n","acc = accuracy_score(df_test[out_column].values, pred)\n","acc, confusion_matrix(df_test[out_column].values, pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"toZ06S9BZDy5","executionInfo":{"status":"ok","timestamp":1680714591180,"user_tz":-60,"elapsed":9679,"user":{"displayName":"Youcef Moualek","userId":"10747212200399101970"}},"outputId":"b0edf860-5700-4e4f-d487-b5ff0d917362"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning:\n","\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","\n","<ipython-input-8-92e956f6224f>:176: UserWarning:\n","\n","Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["(0.9820627802690582,\n"," array([[38,  1,  0,  1,  0],\n","        [ 1, 55,  0,  0,  1],\n","        [ 0,  0, 50,  0,  0],\n","        [ 0,  0,  0, 33,  0],\n","        [ 0,  0,  0,  0, 43]]))"]},"metadata":{},"execution_count":12}]}]}